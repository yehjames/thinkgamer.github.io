<!DOCTYPE html>
<html lang="en">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Thinkgamer的博客">
    <meta name="keyword"  content="Python,Django,爬虫,Hadoop,Maching Learning,数据挖掘,机器学习,云计算,大数据,深度学习,开发者,程序猿,程序媛,极客,编程,代码,开源,IT网站,Developer,Programmer,Coder,用户体验">
    <link rel="shortcut icon" href="/assets/img/favicon.ico">

    <title>
        
        梯度算法之批量梯度下降，随机梯度下降和小批量梯度下降 - Thinkgamer的博客 | Thinkgamer&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> All In CTR、DL、ML、RL、NLP、KG </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/assets/img/head.jpg" />
        </div>
        <div class="name">
            <i>Thinkgamer</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#批量梯度下降算法"><span class="toc-text">批量梯度下降算法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#随机梯度下降算法"><span class="toc-text">随机梯度下降算法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#小批量梯度下降算法"><span class="toc-text">小批量梯度下降算法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#补充"><span class="toc-text">补充</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sklearn中的SGD"><span class="toc-text">sklearn中的SGD</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> All In CTR、DL、ML、RL、NLP、KG </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        <div class="post-container">
    <div class="post-title">
        梯度算法之批量梯度下降，随机梯度下降和小批量梯度下降
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2017-12-14 14:40:43</span></span>
        
        <span class="attr">标签：/
            
            <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
            <span>/</span>
            
            
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span></span>
        </span>
    </div>
    <div class="post-content no-indent">
        <p>在机器学习领域，体梯度下降算法分为三种</p>
<ul>
<li>批量梯度下降算法（BGD，Batch gradient descent algorithm）</li>
<li>随机梯度下降算法（SGD，Stochastic gradient descent algorithm）</li>
<li>小批量梯度下降算法（MBGD，Mini-batch gradient descent algorithm）<a id="more"></a>
</li>
</ul>
<h1 id="批量梯度下降算法"><a href="#批量梯度下降算法" class="headerlink" title="批量梯度下降算法"></a>批量梯度下降算法</h1><p>BGD是最原始的梯度下降算法，每一次迭代使用全部的样本，即权重的迭代公式中(公式中用$\theta$代替$\theta_i$)，</p>
<script type="math/tex; mode=display">
\jmath (\theta _0,\theta _1,...,\theta _n)=\sum_{i=0}^{m}( h_\theta(x_0,x_1,...,x_n)-y_i )^2</script><script type="math/tex; mode=display">
\theta _i = \theta _i - \alpha \frac{\partial \jmath (\theta _1,\theta _2,...,\theta _n)}{\partial \theta _i}</script><script type="math/tex; mode=display">
公式(1)</script><p>这里的m代表所有的样本，表示从第一个样本遍历到最后一个样本。</p>
<p>特点：</p>
<ul>
<li>能达到全局最优解，易于并行实现</li>
<li>当样本数目很多时，训练过程缓慢</li>
</ul>
<h1 id="随机梯度下降算法"><a href="#随机梯度下降算法" class="headerlink" title="随机梯度下降算法"></a>随机梯度下降算法</h1><p>SGD的思想是更新每一个参数时都使用一个样本来进行更新，即公式（1）中m为1。每次更新参数都只使用一个样本，进行多次更新。这样在样本量很大的情况下，可能只用到其中的一部分样本就能得到最优解了。<br>但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。</p>
<p>特点：</p>
<ul>
<li>训练速度快</li>
<li>准确度下降，并不是最优解，不易于并行实现</li>
</ul>
<h1 id="小批量梯度下降算法"><a href="#小批量梯度下降算法" class="headerlink" title="小批量梯度下降算法"></a>小批量梯度下降算法</h1><p>MBGD的算法思想就是在更新每一参数时都使用一部分样本来进行更新，也就是公式（1）中的m的值大于1小于所有样本的数量。</p>
<p>相对于随机梯度下降，Mini-batch梯度下降降低了收敛波动性，即降低了参数更新的方差，使得更新更加稳定。相对于批量梯度下降，其提高了每次学习的速度。并且其不用担心内存瓶颈从而可以利用矩阵运算进行高效计算。一般而言每次更新随机选择[50,256]个样本进行学习，但是也要根据具体问题而选择，实践中可以进行多次试验，选择一个更新速度与更次次数都较适合的样本数。mini-batch梯度下降可以保证收敛性，常用于神经网络中。</p>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>在样本量较小的情况下，可以使用批量梯度下降算法，样本量较大的情况或者线上，可以使用随机梯度下降算法或者小批量梯度下降算法。</p>
<p>在机器学习中的无约束优化算法，除了梯度下降以外，还有前面提到的最小二乘法，此外还有牛顿法和拟牛顿法。</p>
<p>梯度下降法和最小二乘法相比，梯度下降法需要选择步长，而最小二乘法不需要。梯度下降法是迭代求解，最小二乘法是计算解析解。如果样本量不算很大，且存在解析解，最小二乘法比起梯度下降法要有优势，计算速度很快。但是如果样本量很大，用最小二乘法由于需要求一个超级大的逆矩阵，这时就很难或者很慢才能求解解析解了，使用迭代的梯度下降法比较有优势。</p>
<p>梯度下降法和牛顿法/拟牛顿法相比，两者都是迭代求解，不过梯度下降法是梯度求解，而牛顿法/拟牛顿法是用二阶的海森矩阵的逆矩阵或伪逆矩阵求解。相对而言，使用牛顿法/拟牛顿法收敛更快。但是每次迭代的时间比梯度下降法长。</p>
<h1 id="sklearn中的SGD"><a href="#sklearn中的SGD" class="headerlink" title="sklearn中的SGD"></a>sklearn中的SGD</h1><p>sklearn官网上查了一下，并没有找到BGD和MBGD的相关文档，只是看到可SGD的，感兴趣的可以直接去官网看英文文档，点击SGD查看：<a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html" target="_blank" rel="external">SGD</a>，这也有一个中文的 <a href="http://sklearn.lzjqsdd.com/modules/sgd.html" target="_blank" rel="external">SGD</a></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">In</span> [1]: <span class="keyword">from</span> sklearn.linear_model import SGDClassifier</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [2]: X = [[0., 0.], [1., 1.]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [3]: y = [0, 1]</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [4]: clf = SGDClassifier(<span class="attribute">loss</span>=<span class="string">"hinge"</span>, <span class="attribute">penalty</span>=<span class="string">"l2"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [5]: clf.fit(X, y)</span><br><span class="line">Out[5]: </span><br><span class="line">SGDClassifier(<span class="attribute">alpha</span>=0.0001, <span class="attribute">average</span>=<span class="literal">False</span>, <span class="attribute">class_weight</span>=None, <span class="attribute">epsilon</span>=0.1,</span><br><span class="line">       <span class="attribute">eta0</span>=0.0, <span class="attribute">fit_intercept</span>=<span class="literal">True</span>, <span class="attribute">l1_ratio</span>=0.15,</span><br><span class="line">       <span class="attribute">learning_rate</span>=<span class="string">'optimal'</span>, <span class="attribute">loss</span>=<span class="string">'hinge'</span>, <span class="attribute">n_iter</span>=5, <span class="attribute">n_jobs</span>=1,</span><br><span class="line">       <span class="attribute">penalty</span>=<span class="string">'l2'</span>, <span class="attribute">power_t</span>=0.5, <span class="attribute">random_state</span>=None, <span class="attribute">shuffle</span>=<span class="literal">True</span>,</span><br><span class="line">       <span class="attribute">verbose</span>=0, <span class="attribute">warm_start</span>=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [6]:  clf.predict([[2., 2.]])</span><br><span class="line">Out[6]: array([1])</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [7]: clf.coef_ </span><br><span class="line">Out[7]: array([[ 9.91080278,  9.91080278]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [8]: clf.intercept_ </span><br><span class="line">Out[8]: array([-9.97004991])</span><br></pre></td></tr></table></figure>
<p>参考：</p>
<ul>
<li><a href="https://www.cnblogs.com/pinard/p/5970503.html" target="_blank" rel="external">https://www.cnblogs.com/pinard/p/5970503.html</a></li>
<li><a href="http://blog.csdn.net/uestc_c2_403/article/details/74910107" target="_blank" rel="external">http://blog.csdn.net/uestc_c2_403/article/details/74910107</a></li>
</ul>
<hr>
<center>
【技术服务】，详情点击查看：
<a href="https://mp.weixin.qq.com/s/PtX9ukKRBmazAWARprGIAg" target="_blank" rel="external">https://mp.weixin.qq.com/s/PtX9ukKRBmazAWARprGIAg</a>
</center>

<hr>
<center>
<img src="https://img-blog.csdnimg.cn/20191108184219834.jpeg">
<br>
扫一扫 关注微信公众号！号主 专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！
</center>

<hr>
<center><img src="https://img-blog.csdnimg.cn/20191105121139935.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="80%"></center>

<center><img src="https://img-blog.csdnimg.cn/20191105121309716.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="80%"></center>
        
            <div class="donate-container">
    <div class="donate-button">
        <button id="donate-button">赞赏</button>
    </div>
    <div class="donate-img-container hide" id="donate-img-container">
        <img id="donate-img" src="" data-src="/assets/img/weixin.jpeg">
        <p> 你的支持是我进步的最大动力！ </p>
    </div>
</div>
        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>
    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        
        <li>
            <a target="_blank" href="https://www.zhihu.com/people/thinkgamer">
                            <span class="fa-stack fa-lg">
                                 <i class="iconfont icon-zhihu"></i>
                            </span>
            </a>
        </li>
        

        
        <li>
            <a target="_blank" href="http://weibo.com/5352480017">
                            <span class="fa-stack fa-lg">
                                  <i class="iconfont icon-weibo"></i>
                            </span>
            </a>
        </li>
        

        

        
        <li>
            <a target="_blank"  href="https://github.com/thinkgamer">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-github"></i>
                            </span>
            </a>
        </li>
        


        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://item.jd.com/12671716.html">处女作：推荐系统开发实战</a></span>
        <span>/</span>
        
        <span><a href="https://mp.weixin.qq.com/s/vkDfg3v5C7QPrLOTvTRH2w">搜索与推荐Wiki</a></span>
        <span>/</span>
        
        <span><a href="https://blog.csdn.net/gamer_gyt">CSDN博客</a></span>
        <span>/</span>
        
        <span><a href="https://mp.weixin.qq.com/s/PtX9ukKRBmazAWARprGIAg">商务合作</a></span>
        <span>/</span>
        
        <span><a href="https://www.a2data.cn/">牛人之A2Data</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        || Created By <a href="https://blog.csdn.net/gamer_gyt">Thinkgamer</a></p>
</footer><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
