<!DOCTYPE html>
<html lang="en">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Thinkgamer的博客">
    <meta name="keyword"  content="Python,Django,爬虫,Hadoop,Maching Learning,数据挖掘,机器学习,云计算,大数据,深度学习,开发者,程序猿,程序媛,极客,编程,代码,开源,IT网站,Developer,Programmer,Coder,用户体验">
    <link rel="shortcut icon" href="/assets/img/favicon.ico">

    <title>
        
        回归分析之线性回归（N元线性回归） - Thinkgamer的博客 | Thinkgamer&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> All In CTR、DL、ML、RL、NLP、KG </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/assets/img/head.jpg" />
        </div>
        <div class="name">
            <i>Thinkgamer</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一元线性回归"><span class="toc-text">一元线性回归</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#多元线性回归"><span class="toc-text">多元线性回归</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sklearn中的线性回归应用"><span class="toc-text">sklearn中的线性回归应用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#普通最小二乘回归"><span class="toc-text">普通最小二乘回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多项式回归：基函数扩展线性模型"><span class="toc-text">多项式回归：基函数扩展线性模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#线性回归的评测"><span class="toc-text">线性回归的评测</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> All In CTR、DL、ML、RL、NLP、KG </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        <div class="post-container">
    <div class="post-title">
        回归分析之线性回归（N元线性回归）
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2017-09-29 16:45:14</span></span>
        
        <span class="attr">标签：/
            
            <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
            <span>/</span>
            
            <a class="tag" href="/tags/#线性回归" title="线性回归">线性回归</a>
            <span>/</span>
            
            
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span></span>
        </span>
    </div>
    <div class="post-content no-indent">
        <p>在上一篇文章中我们介绍了 <a href="http://blog.csdn.net/gamer_gyt/article/details/78008144" target="_blank" rel="external"> 回归分析之理论篇</a>，在其中我们有聊到线性回归和非线性回归，包括广义线性回归，这一篇文章我们来聊下回归分析中的线性回归。</p>
<a id="more"></a>
<h1 id="一元线性回归"><a href="#一元线性回归" class="headerlink" title="一元线性回归"></a>一元线性回归</h1><p>预测房价：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>输入编号</th>
<th>平方米</th>
<th>价格</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>150</td>
<td>6450</td>
</tr>
<tr>
<td>2</td>
<td>200</td>
<td>7450</td>
</tr>
<tr>
<td>3</td>
<td>250</td>
<td>8450</td>
</tr>
<tr>
<td>4</td>
<td>300</td>
<td>9450</td>
</tr>
<tr>
<td>5</td>
<td>350</td>
<td>11450</td>
</tr>
<tr>
<td>6</td>
<td>400</td>
<td>15450</td>
</tr>
<tr>
<td>7</td>
<td>600</td>
<td>18450</td>
</tr>
</tbody>
</table>
</div>
<p>针对上边这种一元数据来讲，我们可以构建的一元线性回归函数为</p>
<script type="math/tex; mode=display">
H(x) = k*x + b</script><p>其中H(x)为平方米价格表，k是一元回归系数，b为常数。最小二乘法的公式：</p>
<script type="math/tex; mode=display">
k =\frac{ \sum_{1}^{n} (x_{i} - \bar{x} )(y_{i} - \bar{y}) } { \sum_{1}^{n}(x_{i}-\bar{x})^{2} }</script><p>自己使用python代码实现为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leastsq</span><span class="params">(x,y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    x,y分别是要拟合的数据的自变量列表和因变量列表</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    meanX = sum(x) * <span class="number">1.0</span> / len(x)      <span class="comment"># 求x的平均值</span></span><br><span class="line">    meanY = sum(y) * <span class="number">1.0</span> / len(y)     <span class="comment"># 求y的平均值</span></span><br><span class="line"></span><br><span class="line">    xSum = <span class="number">0.0</span></span><br><span class="line">    ySum = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x)):</span><br><span class="line">        xSum += (x[i] - meanX) * (y[i] - meanY)</span><br><span class="line">        ySum += (x[i] - meanX) ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    k = ySum/xSum</span><br><span class="line">    b = ySum - k * meanX</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> k,b</span><br></pre></td></tr></table></figure></p>
<p>使用python的scipy包进行计算:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">leastsq(func, x0, args=(), Dfun=<span class="keyword">None</span>, full_output=<span class="number">0</span>, col_deriv=<span class="number">0</span>, ftol=<span class="number">1.49012e-08</span>, xtol=<span class="number">1.49012e-08</span>, gtol=<span class="number">0.0</span>, maxfev=<span class="number">0</span>, epsfcn=<span class="keyword">None</span>, factor=<span class="number">100</span>, diag=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> leastsq</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(p, x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    定义想要拟合的函数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    k,b = p    <span class="comment"># 从参数p获得拟合的参数</span></span><br><span class="line">    <span class="keyword">return</span> k*x + b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">err</span><span class="params">(p, x, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> fun(p,x) - y</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义起始的参数 即从 y = 1*x+1 开始，其实这个值可以随便设，只不过会影响到找到最优解的时间</span></span><br><span class="line">p0 = [<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#将list类型转换为 numpy.ndarray 类型，最初我直接使用</span></span><br><span class="line"><span class="comment">#list 类型,结果 leastsq函数报错，后来在别的blog上看到了，原来要将类型转</span></span><br><span class="line"><span class="comment">#换为numpy的类型</span></span><br><span class="line"></span><br><span class="line">x1 = np.array([<span class="number">150</span>,<span class="number">200</span>,<span class="number">250</span>,<span class="number">300</span>,<span class="number">350</span>,<span class="number">400</span>,<span class="number">600</span>])</span><br><span class="line">y1 = np.array([<span class="number">6450</span>,<span class="number">7450</span>,<span class="number">8450</span>,<span class="number">9450</span>,<span class="number">11450</span>,<span class="number">15450</span>,<span class="number">18450</span>])</span><br><span class="line"></span><br><span class="line">xishu = leastsq(err, p0, args=(x1,y1))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> xishu[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<p>当然python的leastsq函数不仅仅局限于一元一次的应用，也可以应用到一元二次，二元二次，多元多次等，具体可以看下这篇博客：<a href="http://www.cnblogs.com/NanShan2016/p/5493429.html" target="_blank" rel="external">http://www.cnblogs.com/NanShan2016/p/5493429.html</a></p>
<h1 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h1><p>总之：我们可以用python leastsq函数解决几乎所有的线性回归的问题了，比如说</p>
<script type="math/tex; mode=display">y = a * x^2 + b * x + c</script><script type="math/tex; mode=display">y = a * x_1^2 + b * x_1 + c * x_2 + d</script><script type="math/tex; mode=display">y = a * x_1^3 + b * x_1^2 + c * x_1 + d</script><p>在使用时只需把参数列表和 fun 函数中的return 换一下，拿以下函数举例</p>
<script type="math/tex; mode=display">y = a * x_1^2 + b * x_1 + c * x_2 + d</script><p>对应的python 代码是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> leastsq</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(p, x1, x2)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    定义想要拟合的函数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    a,b,c,d = p    <span class="comment"># 从参数p获得拟合的参数</span></span><br><span class="line">    <span class="keyword">return</span> a * (x1**<span class="number">2</span>) + b * x1 + c * x2 + d</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">err</span><span class="params">(p, x1, x2, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> fun(p,x1,x2) - y</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义起始的参数 即从 y = 1*x+1 开始，其实这个值可以随便设，只不过会影响到找到最优解的时间</span></span><br><span class="line">p0 = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#将list类型转换为 numpy.ndarray 类型，最初我直接使用</span></span><br><span class="line"><span class="comment">#list 类型,结果 leastsq函数报错，后来在别的blog上看到了，原来要将类型转</span></span><br><span class="line"><span class="comment">#换为numpy的类型</span></span><br><span class="line"></span><br><span class="line">x1 = np.array([<span class="number">150</span>,<span class="number">200</span>,<span class="number">250</span>,<span class="number">300</span>,<span class="number">350</span>,<span class="number">400</span>,<span class="number">600</span>])    <span class="comment"># 面积</span></span><br><span class="line">x2 = np.array([<span class="number">4</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">12</span>,<span class="number">14</span>,<span class="number">15</span>])               <span class="comment"># 楼层</span></span><br><span class="line">y1 = np.array([<span class="number">6450</span>,<span class="number">7450</span>,<span class="number">8450</span>,<span class="number">9450</span>,<span class="number">11450</span>,<span class="number">15450</span>,<span class="number">18450</span>])   <span class="comment"># 价格/平方米</span></span><br><span class="line"></span><br><span class="line">xishu = leastsq(err, p0, args=(x1,x2,y1))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> xishu[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<h1 id="sklearn中的线性回归应用"><a href="#sklearn中的线性回归应用" class="headerlink" title="sklearn中的线性回归应用"></a>sklearn中的线性回归应用</h1><h2 id="普通最小二乘回归"><a href="#普通最小二乘回归" class="headerlink" title="普通最小二乘回归"></a>普通最小二乘回归</h2><p>这里我们使用的是sklearn中的linear_model来模拟<script type="math/tex">y=a * x_1 + b * x_2 + c</script></p>
<figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">In</span> [<span class="number">1</span>]: from sklearn.linear_model import <span class="symbol">LinearRegression</span></span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">2</span>]: linreg = <span class="symbol">LinearRegression</span>()</span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">3</span>]: linreg.fit([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">4</span>]: linreg.coef_</span><br><span class="line"><span class="symbol">Out</span>[<span class="number">4</span>]: array([ <span class="number">0.5</span>,  <span class="number">0.5</span>])</span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">5</span>]: linreg.intercept_</span><br><span class="line"><span class="symbol">Out</span>[<span class="number">5</span>]: <span class="number">1.1102230246251565e-16</span></span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">6</span>]: linreg.predict([<span class="number">4</span>,<span class="number">4</span>])</span><br><span class="line"><span class="symbol">Out</span>[<span class="number">6</span>]: array([ <span class="number">4.</span>])</span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">7</span>]: zip([<span class="string">"x1"</span>,<span class="string">"x2"</span>], linreg.coef_)</span><br><span class="line"><span class="symbol">Out</span>[<span class="number">7</span>]: [(<span class="string">'x1'</span>, <span class="number">0.5</span>), (<span class="string">'x2'</span>, <span class="number">0.49999999999999989</span>)]</span><br></pre></td></tr></table></figure>
<p>所以可得<script type="math/tex">y = 0.5 * x_1 + 0.5 * x_2 + 1.11e-16</script></p>
<p>linreg.coef_  为系数 a,b</p>
<p>linreg.intercept_ 为截距 c</p>
<p>缺点：因为系数矩阵x与它的转置矩阵相乘得到的矩阵不能求逆，导致最小二乘法得到的回归系数不稳定，方差很大。</p>
<h2 id="多项式回归：基函数扩展线性模型"><a href="#多项式回归：基函数扩展线性模型" class="headerlink" title="多项式回归：基函数扩展线性模型"></a>多项式回归：基函数扩展线性模型</h2><p>机器学习中一种常见的模式是使用线性模型训练数据的非线性函数。这种方法保持了一般快速的线性方法的性能，同时允许它们适应更广泛的数据范围。</p>
<p>例如，可以通过构造系数的多项式特征来扩展一个简单的线性回归。在标准线性回归的情况下，你可能有一个类似于二维数据的模型：</p>
<script type="math/tex; mode=display">
y(w,x) = w_{0} + w_{1} x_{1} + w_{2} x_{2}</script><p>如果我们想把抛物面拟合成数据而不是平面，我们可以结合二阶多项式的特征，使模型看起来像这样:</p>
<script type="math/tex; mode=display">
y(w,x) = w_{0} + w_{1} x_{1} + w_{2} x_{2} + w_{3} x_{1}x_{2} + w_{4} x_{1}^2 + w_{5} x_{2}^2</script><p>我们发现，这仍然是一个线性模型，想象着创建一个新变量：</p>
<script type="math/tex; mode=display">
z = [x_{1},x_{2},x_{1} x_{2},x_{1}^2,x_{2}^2]</script><p>可以把线性回归模型写成下边这种形式：</p>
<script type="math/tex; mode=display">
y(w,x) = w_{0} + w_{1} z_{1} + w_{2} z_{2} + w_{3} z_{3} + w_{4} z_{4} + w_{5} z_{5}</script><p>我们看到，所得的多项式回归与我们上面所考虑的线性模型相同（即模型在W中是线性的），可以用同样的方法来求解。通过考虑在用这些基函数建立的高维空间中的线性拟合，该模型具有灵活性，可以适应更广泛的数据范围。</p>
<p>使用如下代码，将二维数据进行二元转换,转换规则为：</p>
<script type="math/tex; mode=display">
[x_1, x_2] => [1, x_1, x_2, x_1^2, x_1 x_2, x_2^2]</script><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In <span class="comment">[15]</span>: from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line"></span><br><span class="line">In <span class="comment">[16]</span>: import numpy as np</span><br><span class="line"></span><br><span class="line">In <span class="comment">[17]</span>: X = np.arange(6).reshape(3,2)</span><br><span class="line"></span><br><span class="line">In <span class="comment">[18]</span>: X</span><br><span class="line">Out<span class="comment">[18]</span>: </span><br><span class="line">array(<span class="comment">[<span class="comment">[0, 1]</span>,</span></span><br><span class="line"><span class="comment">       <span class="comment">[2, 3]</span>,</span></span><br><span class="line"><span class="comment">       <span class="comment">[4, 5]</span>]</span>)</span><br><span class="line"></span><br><span class="line">In <span class="comment">[19]</span>: poly = PolynomialFeatures(degree=2)</span><br><span class="line"></span><br><span class="line">In <span class="comment">[20]</span>: poly.fit_transform(X)</span><br><span class="line">Out<span class="comment">[20]</span>: </span><br><span class="line">array(<span class="comment">[<span class="comment">[  1.,   0.,   1.,   0.,   0.,   1.]</span>,</span></span><br><span class="line"><span class="comment">       <span class="comment">[  1.,   2.,   3.,   4.,   6.,   9.]</span>,</span></span><br><span class="line"><span class="comment">       <span class="comment">[  1.,   4.,   5.,  16.,  20.,  25.]</span>]</span>)</span><br></pre></td></tr></table></figure>
<p>验证：<br><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">In</span> [<span class="number">38</span>]: from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">39</span>]: from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">40</span>]: from sklearn.pipeline import Pipeline</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">41</span>]: import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">42</span>]: </span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">42</span>]: model = Pipeline( [ (<span class="string">"poly"</span>,PolynomialFeatures(degree=<span class="number">3</span>)),(<span class="string">"linear"</span>,LinearRegression(fit_intercept=<span class="literal">False</span>)) ] )</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">43</span>]: model</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">43</span>]: Pipeline(steps=[(<span class="symbol">'poly</span>', PolynomialFeatures(degree=<span class="number">3</span>, include_bias=<span class="literal">True</span>, interaction_only=<span class="literal">False</span>)), (<span class="symbol">'linear</span>', LinearRegression(copy_X=<span class="literal">True</span>, fit_intercept=<span class="literal">False</span>, n_jobs=<span class="number">1</span>, normalize=<span class="literal">False</span>))])</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">44</span>]: x = np.arange(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">45</span>]: y = <span class="number">3</span> - <span class="number">2</span> * x + x ** <span class="number">2</span> - x ** <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">46</span>]: y</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">46</span>]: <span class="keyword">array</span>([  <span class="number">3</span>,   <span class="number">1</span>,  -<span class="number">5</span>, -<span class="number">21</span>, -<span class="number">53</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">47</span>]: model = model.fit(x[:,np.newaxis],y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">48</span>]: model.named_steps[<span class="symbol">'linear</span>'].coef_</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">48</span>]: <span class="keyword">array</span>([ <span class="number">3</span>., -<span class="number">2</span>.,  <span class="number">1</span>., -<span class="number">1</span>.])</span><br></pre></td></tr></table></figure></p>
<p>我们可以看出最后求出的参数和一元三次方程是一致的。</p>
<p>这里如果把degree改为2，y的方程也换一下，结果也是一致的<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">In</span> [<span class="number">51</span>]: from sklearn.linear_model import <span class="symbol">LinearRegression</span></span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">52</span>]: from sklearn.preprocessing import <span class="symbol">PolynomialFeatures</span></span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">53</span>]: from sklearn.pipeline import <span class="symbol">Pipeline</span></span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">54</span>]: import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">55</span>]: model = <span class="symbol">Pipeline</span>( [ (<span class="string">"poly"</span>,<span class="symbol">PolynomialFeatures</span>(degree=<span class="number">2</span>)),(<span class="string">"linear"</span>,<span class="symbol">LinearRegression</span>(fit_intercept=<span class="symbol">False</span>)) ] )</span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">56</span>]: x = np.arange(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">57</span>]: y = <span class="number">3</span> + <span class="number">2</span> * x + x ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">58</span>]: model = model.fit(x[:, np.newaxis], y)</span><br><span class="line"></span><br><span class="line"><span class="symbol">In</span> [<span class="number">59</span>]: model.named_steps[<span class="string">'linear'</span>].coef_</span><br><span class="line"><span class="symbol">Out</span>[<span class="number">59</span>]: array([ <span class="number">3.</span>, <span class="number">2.</span>,  <span class="number">1.</span>])</span><br></pre></td></tr></table></figure></p>
<h2 id="线性回归的评测"><a href="#线性回归的评测" class="headerlink" title="线性回归的评测"></a>线性回归的评测</h2><p>在<a href="http://note.youdao.com/" target="_blank" rel="external">上一篇文章</a>中我们聊到了回归模型的评测方法，解下来我们详细聊聊如何来评价一个回归模型的好坏。</p>
<p>这里我们定义预测值和真实值分别为：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">true = [<span class="number">10</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">pred = [<span class="number">9</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure></p>
<p>1: 平均绝对误差（Mean Absolute Error, MAE）</p>
<script type="math/tex; mode=display">
\frac{1}{N}(\sum_{1}^{n} |y_i - \bar{y}|)</script><p>2: 均方误差（Mean Squared Error, MSE）</p>
<script type="math/tex; mode=display">
\frac{1}{N}\sum_{1}^{n}(y_i - \bar{y})^2</script><p>3: 均方根误差（Root Mean Squared Error, RMSE）</p>
<script type="math/tex; mode=display">
\frac{1}{N} \sqrt{ \sum_{1}^{n}(y_i - \bar{y})^2 }</script><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">In</span> [<span class="number">80</span>]: <span class="keyword">from</span> sklearn import metrics</span><br><span class="line"></span><br><span class="line"><span class="built_in">In</span> [<span class="number">81</span>]: import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="built_in">In</span> [<span class="number">82</span>]: <span class="literal">true</span> = [<span class="number">10</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">In</span> [<span class="number">83</span>]: pred = [<span class="number">9</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">In</span> [<span class="number">84</span>]: print(<span class="string">"MAE: "</span>, metrics.mean_absolute_error(<span class="literal">true</span>,pred))</span><br><span class="line">(<span class="string">'MAE: '</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">In</span> [<span class="number">85</span>]: print(<span class="string">"MAE By Hand: "</span>, (<span class="number">1</span>+<span class="number">0</span>+<span class="number">2</span>+<span class="number">1</span>)/<span class="number">4</span>.)</span><br><span class="line">(<span class="string">'MAE By Hand: '</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">In</span> [<span class="number">86</span>]: print(<span class="string">"MSE: "</span>, metrics.mean_squared_error(<span class="literal">true</span>,pred))</span><br><span class="line">(<span class="string">'MSE: '</span>, <span class="number">1.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">In</span> [<span class="number">87</span>]: print(<span class="string">"MSE By Hand: "</span>, (<span class="number">1</span> ** <span class="number">2</span> + <span class="number">0</span> ** <span class="number">2</span> + <span class="number">2</span> ** <span class="number">2</span> + <span class="number">1</span> ** <span class="number">2</span> ) / <span class="number">4</span>.)</span><br><span class="line">(<span class="string">'MSE By Hand: '</span>, <span class="number">1.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">In</span> [<span class="number">88</span>]: print(<span class="string">"RMSE: "</span>, np.<span class="built_in">sqrt</span>(metrics.mean_squared_error(<span class="literal">true</span>,pred)))</span><br><span class="line">(<span class="string">'RMSE: '</span>, <span class="number">1.2247448713915889</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">In</span> [<span class="number">89</span>]: print(<span class="string">"RMSE By Hand: "</span>, np.<span class="built_in">sqrt</span>((<span class="number">1</span> ** <span class="number">2</span> + <span class="number">0</span> ** <span class="number">2</span> + <span class="number">2</span> ** <span class="number">2</span> + <span class="number">1</span> ** <span class="number">2</span> ) / <span class="number">4</span>.))</span><br><span class="line">(<span class="string">'RMSE By Hand: '</span>, <span class="number">1.2247448713915889</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>线性回归在现实中还是可以解决很多问题的，但是并不是万能的，后续我会继续整理逻辑回归，岭回归等相关回归的知识，如果你感觉有用，欢迎分享！</p>
<hr>
<center>
<img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
</center>
<center>打开微信扫一扫，关注微信公众号【搜索与推荐Wiki】 </center>

        
            <div class="donate-container">
    <div class="donate-button">
        <button id="donate-button">赞赏</button>
    </div>
    <div class="donate-img-container hide" id="donate-img-container">
        <img id="donate-img" src="" data-src="/assets/img/weixin.jpeg">
        <p> 你的支持是我进步的最大动力！ </p>
    </div>
</div>
        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>
    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        
        <li>
            <a target="_blank" href="https://www.zhihu.com/people/thinkgamer">
                            <span class="fa-stack fa-lg">
                                 <i class="iconfont icon-zhihu"></i>
                            </span>
            </a>
        </li>
        

        
        <li>
            <a target="_blank" href="http://weibo.com/5352480017">
                            <span class="fa-stack fa-lg">
                                  <i class="iconfont icon-weibo"></i>
                            </span>
            </a>
        </li>
        

        

        
        <li>
            <a target="_blank"  href="https://github.com/thinkgamer">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-github"></i>
                            </span>
            </a>
        </li>
        


        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://item.jd.com/12671716.html">处女作：推荐系统开发实战</a></span>
        <span>/</span>
        
        <span><a href="https://mp.weixin.qq.com/s/vkDfg3v5C7QPrLOTvTRH2w">搜索与推荐Wiki</a></span>
        <span>/</span>
        
        <span><a href="https://blog.csdn.net/gamer_gyt">CSDN博客</a></span>
        <span>/</span>
        
        <span><a href="https://mp.weixin.qq.com/s/PtX9ukKRBmazAWARprGIAg">商务合作</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        || Created By <a href="https://blog.csdn.net/gamer_gyt">Thinkgamer</a></p>
</footer>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
