<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>文艺与Code | Thinkgamer的博客</title>
  <icon>https://www.gravatar.com/avatar/1b9c8afc3fc1dc6be26316835c6f4fc4</icon>
  <subtitle>All In CTR、DL、ML、RL、NLP、KG</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://thinkgamer.cn/"/>
  <updated>2019-11-26T08:37:52.852Z</updated>
  <id>http://thinkgamer.cn/</id>
  
  <author>
    <name>Thinkgamer</name>
    <email>thinkgamer@163.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>常见的五种神经网络(4)-深度信念网络（上）篇</title>
    <link href="http://thinkgamer.cn/2019/11/26/TensorFlow/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E7%A7%8D%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(4)-%E6%B7%B1%E5%BA%A6%E4%BF%A1%E5%BF%B5%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8A%EF%BC%89%E7%AF%87/"/>
    <id>http://thinkgamer.cn/2019/11/26/TensorFlow/常见的五种神经网络(4)-深度信念网络（上）篇/</id>
    <published>2019-11-26T06:32:04.000Z</published>
    <updated>2019-11-26T08:37:52.852Z</updated>
    
    <content type="html"><![CDATA[<p>转载请注明出处：<a href="https://thinkgamer.blog.csdn.net/article/details/103231385" target="_blank" rel="external">https://thinkgamer.blog.csdn.net/article/details/103231385</a><br>博主微博：<a href="http://weibo.com/234654758" target="_blank" rel="external">http://weibo.com/234654758</a><br>Github：<a href="https://github.com/thinkgamer" target="_blank" rel="external">https://github.com/thinkgamer</a><br>公众号：搜索与推荐Wiki</p><hr><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>常见的五种神经网络系列第三篇，主要介绍深度信念网络。内容分为上下两篇进行介绍，本文主要是深度信念网络（上）篇，主要介绍以下内容：</p><ul><li>背景</li><li>玻尔兹曼机</li><li>受限玻尔兹曼机</li></ul><p>该系列的其他文章：</p><ul><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/89459131" target="_blank" rel="external">常见的五种神经网络(1)-前馈神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100531593" target="_blank" rel="external">常见的五种神经网络(2)-卷积神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100600661" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(上篇)</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100709422" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(中篇)</a></li><li><a href="https://thinkgamer.blog.csdn.net/article/details/100943664" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(下篇)</a></li><li>常见的五种神经网络(4)-深度信念网络(上篇)</li><li>常见的五种神经网络(4)-深度信念网络(下篇)</li><li>常见的五种神经网络(5)-生成对抗网络</li></ul><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>对于一个复杂的数据分布，我们往往只能观测到有限的局部特征，并且这些特征通常会包含一定的噪声。如果要对这个数据分布进行建模，就需要挖掘出可观测变量之间复杂的依赖关系，以及可观测变量背后隐藏的内部表示。</p><p>而深度信念网络可以有效的学习变量之间复杂的依赖关系。深度信念网络中包含很多层的隐变量，可以有效的学习数据的内部特征表示，也可以作为一种有效的非线性降维方法，这些学习到的内部特征表示包含了数据的更高级的、有价值的信息，因此十分有助于后续的分类和回归等任务。</p><p>玻尔兹曼机是生成模型的一种基础模型，和深度信念网络的共同问题是<strong>推断和学习</strong>，因为这两种模型都比较复杂，并且都包含隐变量，他们的推断和学习一般通过MCMC方法来进行近似估计。这两种模型和神经网络有很强的对应关系，在一定程度上也称为随机神经网络（Stochastic Neural Network，SNN）。</p><p>因为深度信念网络是有多层玻尔兹曼机组成的，所以本篇文章我们先来了解一下<strong>玻尔兹曼机</strong>和<strong>受限玻尔兹曼机</strong>。</p><h3 id="玻尔兹曼机"><a href="#玻尔兹曼机" class="headerlink" title="玻尔兹曼机"></a>玻尔兹曼机</h3><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>玻尔兹曼机（Boltzmann Machine）可以看作是一种随机动力系统，每个变量的状态都以一定的概率受到其他变量的影响。玻尔兹曼机可以用概率无向图模型来描述，如下所示：</p><p><img src="https://img-blog.csdnimg.cn/20191122090749423.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="一个有六个变量的玻尔兹曼机"></p><p>BM的三个性质：</p><ul><li>二值输出：每个随机变量可以用一个二值的随机变量表示</li><li>全连接：所有节点之间是全连接的</li><li>权重对称：每两个变量之间的相互影响是对称的</li></ul><p>BM中的每个变量$X$的联合概率由玻尔兹曼分布得到，即：</p><script type="math/tex; mode=display">p(x) = \frac{1}{Z} exp(\frac{-E(x)}{T})</script><p>其中$Z$为配分函数，能量函数$E(X)$的定义为：</p><script type="math/tex; mode=display">E(x) \overset{\bigtriangleup }{=} E(X=x) = -(   \sum_{i<j } w_{ij}x_ix_j + \sum_{i} b_i x_i  )</script><p>其中$w_{ij}$是两个变量之间的连接权重，$x_i \in \{0,1\}$表示状态，$b_i$是变量$x_i$的偏置。</p><p>玻尔兹曼机可以用来解决两类问题，一是搜索问题，当给定变量之间的连接权重，需要找到一组二值变量，使得整个网络的能量最低。另一类是学习问题，当给定一部分变量的观测值时，计算一组最优的权重。</p><h4 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h4><p>在玻尔兹曼机中配分函数$Z$通常难以计算，因此联合概率分布$p(x)$一般通过MCMC（马尔科夫链蒙特卡罗，Markov Chain Monte Carlo）方法来近似，生成一组服从$p(x)$分布的样本。这里介绍基于吉布斯采样的样本生成方法。</p><p><strong>1. 全条件概率</strong><br>吉布斯采样需要计算每个变量$X_i$的全条件概率$p(x_i|x_{\setminus i})$，其中$x_{\setminus i}$表示除了$X_i$外其它变量的取值。</p><p>对于玻尔兹曼机中的一个变量$X_i$，当给定其他变量$x_{\setminus i}$时，全条件概率公式$p(x_i|x_{\setminus i})$为：</p><script type="math/tex; mode=display">p(x_i=1|x_{\setminus i}) = \sigma( \frac{ \sum_{j} w_{ij}x_j +b_i }{T} )\\p(x_i=0|x_{\setminus i}) = 1- p(x_i=1|x_{\setminus i})</script><p>其中$\sigma(.)$为sigmoid函数。</p><p><strong>2. 吉布斯采样</strong></p><p>玻尔兹曼机的吉布斯采样过程为：随机选择一个变量$X_i$，然后根据其全条件概率$p(x_i|x_{\setminus i})$来设置其状态，即以$p(x_i=1|x_{\setminus i})$的概率将变量$X_i$设为1，否则全为0。在固定温度$T$的情况下，在运动不够时间之后，玻尔兹曼机会达到热平衡。此时，任何全局状态的概率服从玻尔兹曼分布$p(x)$，只与系统的能量有关，与初始状态无关。</p><p>要使得玻尔兹曼机达到热平衡，其收敛速度和温度$T$相关。当系统温度非常高$T \rightarrow \infty$时，$p(x_i|x_{\setminus i}) \rightarrow 0.5$，即每个变量状态的改变十分容易，每一种系统状态都是一样的，从而很快可以达到热平衡。当系统温度非常低$T \rightarrow 0$时，如果$\Delta E_i(x_{ \setminus i}) &gt; 0$，则$p(x_i|x_{\setminus i}) \rightarrow 1$，如果$\Delta E_i(x_{ \setminus i}) &lt; 0$，则$p(x_i|x_{\setminus i}) \rightarrow 0$，即：</p><script type="math/tex; mode=display">x_i = \left\{\begin{matrix}1 &  if \sum_{j}w_{ij}x_j + b_i  \geq 0\\ 0 & otherwise\end{matrix}\right.</script><p>因此，当$ \rightarrow 0$时，随机性方法变成了确定性方法，这时，玻尔兹曼机退化为一个Hopfield网络。Hopfield网络是一种确定性的动力系统，每次的状态更新都会使系统的能量降低；而玻尔兹曼机时一种随机性动力系统，每次的状态更新则以一定的概率使得系统的能力上升。</p><p><strong>3. 能量最小化与模拟退火</strong></p><p>要使得动力系统达到热平衡，温度$T$的选择十分关键。一个比较好的折中方法是让系统刚开始在一个比较高的温度下运行达到热平衡，然后逐渐降低直到系统在一个比较低的温度下达到热平衡。这样我们就能够得到一个能量全局最小的分布。这个过程被称为模拟退火（Simulated Annealing）。</p><p>模拟退火是一种寻找全局最优的近似方法。</p><h3 id="受限玻尔兹曼机"><a href="#受限玻尔兹曼机" class="headerlink" title="受限玻尔兹曼机"></a>受限玻尔兹曼机</h3><h4 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h4><p>全连接的玻尔兹曼机十分复杂，虽然基于采样的方法提高了学习效率，但在权重更新的过程中仍十分低效。在实际应用中，使用比较广泛的一种带限制的版本，即受限玻尔兹曼机（Restricted Boltzmann Machine，RBM）是一个二分图结构的无向图模型，如下所示。<br><img src="https://img-blog.csdnimg.cn/20191122145237428.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="一个有7个变量的受限玻尔兹曼机"></p><p>首先玻尔兹曼机中的变量也分为隐藏变量和可观测变量。分别用可观测层和隐藏层来表示这两组变量。同一层中的节点之间没有连接，而不同层一个层中的节点与另一层中的所有节点连接，这和两层的全连接神经网络结构相同。</p><p>一个受限玻尔兹曼机由$m_1$个可观测变量和$m_2$个隐变量组成，其定义如下：</p><ul><li>可观测的随机向量$v=[v_1, …, v_{m_1}]^T$</li><li>隐藏的随机向量 $h=[h_1, … , h_{m_2}]^T$</li><li>权重矩阵$W \in R^{m_1 * m_2}$，其中每个元素$w_{ij}$为可观测变量$v_i$和隐变量$h_j$之间边的权重</li><li>偏置$a \in R^{m_1}$和$b \in R^{m_2}$，其中$a_i$为每个可观测变量$v_i$得偏置，$b_j$为每个隐变量$h_j$得偏置</li></ul><p>受限玻尔兹曼机得能量函数定义为：</p><script type="math/tex; mode=display">E(v,h) = - \sum_{i} a_iv_i - \sum_{j}b_j h_j - \sum_{i}\sum_{j}v_i w_{ij}h_j = -a^Tv -b^Th - v^T W h</script><p>受限玻尔兹曼机得联合概率分布为$p(v,h)$定义为：</p><script type="math/tex; mode=display">p(v,h) = \frac{1}{Z} exp(-E(v,h)) = \frac{1}{Z} exp(a^Tv)exp(b^Th)exp(v^TWh)</script><p>其中$Z=\sum_{v,h}exp(-E(v,h))$为配分函数。</p><h4 id="生成模型-1"><a href="#生成模型-1" class="headerlink" title="生成模型"></a>生成模型</h4><p>受限玻尔兹曼机得联合概率分布p(v,h)一般也通过吉布斯采样的方法来近似，生成一组服从$p(v,h)$分布的样本。</p><p><strong>1. 全条件概率</strong><br>吉布斯采样需要计算每个变量$V_i$和$H_j$的全条件概率。受限玻尔兹曼机中的同层的变量之间没有连接。从无向图的性质可知，在给定可观测变量时，隐变量之间相互条件独立，同样在给定隐变量时，可观测变量之间也相互条件独立，即有：</p><script type="math/tex; mode=display">p(v_i | v_{\setminus i},h) = p(v_i|h)\\p(h_j | v,h_{\setminus j}) = p(h_j|v)</script><p>其中$v_{\setminus i}$表示除变量$V_i$外其他可观测变量得取值，$h_{\setminus j}$为除变量$H_j$外其它隐变量的取值。因此，$V_i$的全条件概率只需要计算$p(v_i|h)$，而$H_j$的全条件概率只需要计算$p(h_j|v)$</p><p>在受限玻尔兹曼机中，每个可观测变量和隐变量的条件概率为：</p><script type="math/tex; mode=display">p(v_i=1|h) = \sigma (a_i + \sum_{j}w_{ij} h_j)\\p(h_j=1|v) = \sigma (b_j + \sum_{i}w_{ij} v_i)</script><p>其中$\sigma$为sigmoid函数。</p><p><strong>2. RBM中得吉布斯采样</strong><br>受限玻尔兹曼机得采样过程如下：</p><ul><li>（给定）或随机初始化一个可观测的向量$v_0$，计算隐变量得概率，并从中采样一个隐向量$h_0$</li><li>基于$h_0$，计算可观测变量得概率，并从中采样一个个可观测的向量$v_1$</li><li>重复$t$次后，获得$(v_t, h_t)$</li><li>当$t \rightarrow \infty$时，$(v_t,h_t)$的采样服从$p(v,h)$分布</li></ul><p>下图为上述采样过程的示例：<br><img src="https://img-blog.csdnimg.cn/20191122162803614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="受限玻尔兹曼机得采样过程"></p><p><strong>3. 对比散度学习算法</strong></p><p>由于首先玻尔兹曼机得特殊结构，因此可以使用一种比吉布斯采样更高效的学习算法，即对比散度（Contrastive Divergence）。对比散度算法仅需k步吉布斯采样。</p><p>为了提高效率，对比散度算法用一个训练样本作为可观测向量的初始值，然后交替对可观测向量和隐藏向量进行吉布斯采用，不需要等到收敛，只需要k步就行了。这就是CD-k算法，通常，k=1就可以学得很好。对比散度得流程如下所示：<br><img src="https://img-blog.csdnimg.cn/20191122163920824.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="单步对比散度算法"></p><p><strong>4. 受限玻尔兹曼机得类型</strong><br>在具体的不同任务中，需要处理得数据类型不一定是二值得，也可能时连续值，为了能够处理这些数据，就需要根据输入或输出得数据类型来设计新的能量函数。一般来说受限玻尔兹曼机有以下三种：</p><ul><li>“伯努利-伯努利”受限玻尔兹曼机：即上面介绍得可观测变量喝隐变量都为二值类型得受限玻尔兹曼机</li><li>“高斯-伯努利”受限玻尔兹曼机：假设可观测变量为高斯分布，隐变量为伯努利分布，其能量函数定义为：<script type="math/tex; mode=display">E(v,h) = \sum_{i} \frac{(v_i - \mu_i)^2}{2 \sigma_i^2} - \sum{j} b_jh_j - \sum_{i}\sum{j} \frac{v_i}{\sigma_i}w_ijh_j</script>其中每个可观测变量$v_i$服从$(\mu_i, \sigma_i)$的高斯分布。</li><li>“伯努利-高斯”受限玻尔兹曼机：假设可观测变量为伯努利分布，隐变量为高斯分布，其能量函数定义为：<script type="math/tex; mode=display">E(v,h)=\sum_{i}a_i v_j - \sum_{j} \frac{(h_j-u_j)^2}{2\sigma_j^2} - \sum_{i}\sum_{j}v_iw_{ij}\frac{h_j}{\sigma_j}</script>其中每个隐变量$h_j$服从$(\mu_j, \sigma_j)$的高斯分布</li></ul><hr><center><img src="https://img-blog.csdnimg.cn/20191108184219834.jpeg"><center>扫一扫 关注微信公众号！号主 专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！----<center>【技术服务】，详情点击查看：<a href="https://mp.weixin.qq.com/s/PtX9ukKRBmazAWARprGIAg" target="_blank" rel="external">https://mp.weixin.qq.com/s/PtX9ukKRBmazAWARprGIAg</a></center><hr></center></center>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转载请注明出处：&lt;a href=&quot;https://thinkgamer.blog.csdn.net/article/details/103231385&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://thinkgamer.blog.csdn.
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="神经网络" scheme="http://thinkgamer.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>模型的独立学习方式</title>
    <link href="http://thinkgamer.cn/2019/11/12/TensorFlow/%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%8B%AC%E7%AB%8B%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%BC%8F/"/>
    <id>http://thinkgamer.cn/2019/11/12/TensorFlow/模型的独立学习方式/</id>
    <published>2019-11-12T12:53:23.000Z</published>
    <updated>2019-11-14T02:26:37.480Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>针对一个给定的任务，通常采取的步骤是：准确一定非规模的数据集，这些数据要和真实数据集的分布一致；然后设定一个优化目标和方法；然后在训练集上训练模型。</p><p>不同的模型往往都是从零开始训练的，一切知识都需要从训练集中得到，这就意味着每个任务都需要大量的训练数据。在实际应用中，我们面对的任务很难满足上述需求，比如训练任务和目标任务的数据分布不一致，训练数据集过少等。这时机器学习的任务就会受到限制，因此人们开始关注一些新的任务学习方式。<br>本篇文章主要介绍一些“模型独立的学习方式”，比如：集成学习、协同学习、自学习、多任务学习、迁移学习、终身学习、小样本学习、元学习等。</p><h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><p>集成学习（Ensemble Learning）就是通过某种策略将多个模型集成起来，通过群体决策来提高决策准确率。集成学习首要的问题是如何集成多个模型，比较常用的集成策略有直接平均、加权平均等。</p><p><strong>集成学习可以分为：Boosting、Bagging、Stacking</strong>，这三种的详细区分和流程可以参考《<a href="https://item.jd.com/12671716.html" target="_blank" rel="external">推荐系统开发实战</a>》一书中第八章 点击率预估部分。本文中主要介绍集成学习中的Boosting学习和AdaBoost算法。</p><p>集成学习的思想可以采用一句古老的谚语来描述：“三个臭皮匠，顶个诸葛亮”。但是一个有效的集成需要各个基模型的差异尽可能的大。为了增加模型之间的差异性，可以采取Bagging类和Boosting类两类方法。</p><h4 id="Bagging类方法"><a href="#Bagging类方法" class="headerlink" title="Bagging类方法"></a>Bagging类方法</h4><p>Bagging类方法是通过随机构造训练样本、随机选择特征等方法来提高每个基模型的独立性，代表性方法有Bagging和随机森林。</p><ul><li>Bagging（Bootstrap Aggregating）是一个通过不同模型的训练数据集的独立性来提高不同模型之间的独立性。我们在原始训练集上进行有放回的随机采样，得到M比较小的训练集并训练M个模型，然后通过投票的方法进行模型集成。</li><li>随机森林（Random Forest）是在Bagging的基础上再引入了随机特征，进一步提升每个基模型之间的独立性。在随机森林中，每个基模型都是一棵树。</li></ul><p>随机森林的算法步骤如下：</p><ul><li>从样本集中通过重采样的方式产生n个样本</li><li>假设样本特征数目为a，对n个样本选择a中的k个特征，用建立决策树的方式获得最佳分割点</li><li>重复m次，产生m棵决策树<br>-多数投票机制来进行预测<blockquote><p>需要注意的一点是，这里m是指循环的次数，n是指样本的数目，n个样本构成训练的样本集，而m次循环中又会产生m个这样的样本集</p></blockquote></li></ul><h4 id="Boosting类方法"><a href="#Boosting类方法" class="headerlink" title="Boosting类方法"></a>Boosting类方法</h4><p>Boosting类方法是按照一定的顺序来先后训练不同的基模型，每个模型都针对前续模型的错误进行专门训练。根据前序模型的结果，来提高训练样本的权重，从而增加不同基模型之间的差异性。Boosting类方法的代表性方法有AbaBoost，GBDT，XGB，LightGBM等。</p><p>关于GBDT的介绍同样可以参考《<a href="https://item.jd.com/12671716.html" target="_blank" rel="external">推荐系统开发实战</a>》一书。</p><p>Boosting类集成模型的目标是学习一个加性模型（additive model） ，其表达式如下：</p><script type="math/tex; mode=display">F(x) = \sum_{m=1}^{M} a_m f_m(x)</script><p>其中$f_m(x)$为弱分类器，或基分类器，$a_m$为弱分类器的集成权重，$F(x)$称为强分类器。</p><p>Boosting类方法的关键是如何训练每个弱分类器$f_m(x)$以及对应的权重$a_m$。为了提高集成的效果，应尽可能使得每个弱分类器的差异尽可能大。一种有效的方法是采用迭代的策略来学习每个弱分类器，即按照一定的顺序依次训练每个弱分类器。</p><p>在学习了第m个弱分类器之后，增加分错样本的权重，使得第$m+1$个弱分类器“更关注”于前边弱分类器分错的样本。这样增加每个弱分类器的差异，最终提升的集成分类器的准确率。这种方法称为AdaBoost（其实其他的Boost模型采用的也是类似的策略，根据前m-1颗树的误差迭代第m颗树）。</p><h4 id="AdaBoost算法"><a href="#AdaBoost算法" class="headerlink" title="AdaBoost算法"></a>AdaBoost算法</h4><p>AdaBoost算法是一种迭代式的训练算法，通过改变数据分布来提高弱分类器的差异。在每一轮训练中，增加分错样本的权重，减少对分对样本的权重，从而得到一个新的数据分布。</p><p>以两类分类为例，弱分类器$f_m(x) \in \{ +1, -1\}$，AdaBoost算法的训练过程如下所示，最初赋予每个样本同样的权重。在每一轮迭代中，根据当前的样本权重训练一个新的弱分类器。然后根据这个弱分类器的错误率来计算其集成权重，并调整样本权重。</p><p><img src="https://img-blog.csdnimg.cn/20191106144746194.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="AdaBoost算法流程"></p><p><strong>AdaBoost算法的统计学解释</strong></p><p>AdaBoost算法可以看做是一种分步优化的加性模型，其损失函数定义为：</p><script type="math/tex; mode=display">L(F) = exp(-y F(x))\\= exp(-y \sum_{m=1}^{M} a_m f_m(x))</script><p>其中$y,f_m(x)\in \{ +1,-1\}$</p><p>假设经过$m-1$次迭代，得到：</p><script type="math/tex; mode=display">F_{m-1}(x) = \sum_{t=1}^{T} a_t f_t(x)</script><p>则第$m$次迭代的目标是找一个$a_m$和$f_m(x)$使得下面的损失函数最小。</p><script type="math/tex; mode=display">L(a_m,f_m(x)) = \sum_{n=1}^{N}exp(-y^{(n)} (F_{m-1} (x^{(n)}) + a_m f_m(x^{(n)})))</script><p>令 $w_m^{(n)}=exp(-y^{(n)} F_{m-1}(x^{(n)}))$，则损失函数可以表示为：</p><script type="math/tex; mode=display">L(a_m,f_m(x)) = \sum_{n=1}^{N} w_m^{(n)} exp(-y^{(n)} a_m f_m(x^{(n)}))</script><p>因为$y,f_m(x) \in {+1, -1}$，有：</p><script type="math/tex; mode=display">yf_m(x) = 1-2I(y\neq f_m(x))</script><p>其中$I(x)$为指示函数。</p><p>将损失函数在$f_m(x)=0$处进行二阶泰勒展开，有：</p><script type="math/tex; mode=display">L(a_m, f_m(x)) = \sum_{n=1}^{N} w_m^{(n)} (  1 - a_m y^{(n)}f_m(x^{(n)}) + \frac{1}{2}a_m^2  ) \\\propto a_m \sum_{n=1}^{N} w_n^{(n)} I(y^{(n} \neq f_m(x^{(n)})</script><p>从上式可以看出，当$a_m&gt;0$时，最优的分类器$f_m(x)$为使得在样本权重为$w_m^{(n)}, 1 \leq n \leq N$时的加权错误率最小的分类器。</p><p>在求解出$f_m(x)$之后，上述的损失函数可以写为：</p><script type="math/tex; mode=display">L(a_m, f_m(x)) = \sum_{y^{(n)}=f_m(x^{(n)})} w_m^{(n)} exp(-a_m) + \sum_{y^{(n)} \neq f_m(x^{(n)})}  w_m^{(n)} exp(a_m) \\\propto (1-\epsilon _m) exp(-a_m) + \epsilon_m exp(a_m)</script><p>其中$\epsilon_m$为分类器$f_m(x)$的加权错误率</p><script type="math/tex; mode=display">\epsilon_m = \frac { \sum_{ y^{(n)} \neq f_m(x^{(n)}) } w_m^{(n)} } {\sum_{n} w_m^{(n)}}</script><p>求上式关于$a_m$的导数并令其为0，得到</p><script type="math/tex; mode=display">a_m = \frac {1}{2} log \frac {1-\epsilon_m}{\epsilon_m}</script><p><strong>AdaBoost算法的优缺点</strong><br>优点：</p><ul><li>作为分类器精度很高</li><li>可以使用各种算法构建子分类器，AdaBoost提供的是一个框架</li><li>使用简单分类器时，计算出的结果可理解，且构造简单</li><li>不需要做特征筛选</li><li>不同担心过拟合</li></ul><p>缺点：</p><ul><li>容易收到噪声干扰</li><li>训练时间长，因为需要遍历所有特征</li><li>执行效果依赖于弱分类器的选择</li></ul><h3 id="自训练和协同训练"><a href="#自训练和协同训练" class="headerlink" title="自训练和协同训练"></a>自训练和协同训练</h3><p>监督学习虽然准确度上有一定的保证，但往往需要大量的训练数据，但在一些场景中标注数据的成本是非常高的，因此如何利用大量的无标注数据提高监督学习的效率，有着十分重要的意义。这种利用少量样本标注数据和大量样本标注数据进行学习的方式称之为半监督学习（Semi-Supervised Learning，SSL）。</p><p>本节介绍两种无监督的学习算法：自训练和协同训练。</p><h4 id="自训练"><a href="#自训练" class="headerlink" title="自训练"></a>自训练</h4><p>自训练（Slef-Training）也叫自训练（Self-teaching）或者自举法（boostStrapping）。</p><p>自训练的思路是：利用已知的标注数据训练一个模型，利用该模型去预测无标注的样本数据，然后将置信度较高的样本以及其伪标签加入训练集，然后重新训练模型，进行迭代。下图给出了自训练的算法过程。</p><p><img src="https://img-blog.csdnimg.cn/20191109150434700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="自训练算法过程"></p><p>自训练和密度估计中EM算法有一定的相似之处，通过不断地迭代来提高模型能力。但自训练的缺点是无法保证每次加入训练集的样本的伪标签是正确的。如果选择样本的伪标签是错误的，反而会损害模型的预测能力。因此自训练最关键的步骤是如何设置挑选样本的标准。</p><h4 id="协同训练"><a href="#协同训练" class="headerlink" title="协同训练"></a>协同训练</h4><p>协同训练（Co-Training）是自训练的一种改进方法，通过两个基于不同视角的分类器来相互促进。很多数据都有相对独立的不同视角。比如互联网上的每个网页都由两种视角组成：文字内容和指向其他网页的链接。如果要确定一个网页的类别，可以根据文字内容来判断，也可以根据网页之间的链条关系来判断。</p><p>假设一个样本$x=[x_1,x_2]$，其中$x_1,x_2$分别表示两种不同视角$V_1,V_2$的特征，并满足下面两个假设：</p><ul><li>（1）：条件独立性，即给定样本标签y时，两种特征条件独立$p(x_1,x_2|y)=p(x_1|y)p(x_2|y)$</li><li>（2）：充足和冗余性，即当数据充分时，每种视角的特征都可以足以单独训练出一个正确的分类器。</li></ul><p>令$y=g(x)$为需要学习的真实映射函数，$f_1$和$f_2$分别为两个视角的分类器，有：</p><script type="math/tex; mode=display">\exists f_1, f_2,    \forall x \in X,\,\,\,\,\, f_1(x_1) = f_2(x_2) = g(x)</script><p>其中$X$为样本$x$的取值空间。</p><p>由于不同视角的条件独立性，在不同视角上训练出来的模型就相当于从不同的视角来理解问题，具有一定的互补性。协同训练就是利用这种互补行来进行自训练的一种方法。首先在训练集上根据不同视角分别训练两个模型$f_1$和$f_2$然后用$f_1$和$f_2$在无标记数据集上进行预测，各选取预测置信度比较高的样本加入到训练集，重新训练两个不同视角的模型，并不断重复这个过程（需要注意的是协同算法要求两种视图时条件独立的，如果两种视图完全一样，则协同训练退化成自训练算法）。</p><p>协同训练的算法过程如下：<br><img src="https://img-blog.csdnimg.cn/20191109153310892.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="协同训练的算法过程"></p><h3 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h3><p>一般的机器学习模型是针对单个任务进行的，不同任务的模型需要在各自的训练集上单独学习得到。而多任务学习（Multi-task learning）是指同时学习多个相关任务，让 这些任务在学习的过程中共享知识，利用多个任务之间的相关性来改进模型的性能和泛化能力。</p><p>多任务学习可以看做时一种归纳迁移学习（Inductive Transfer Learning），即通过利用包含在相关任务中的信息作为归纳偏置（Inductive Bias）来提高泛化能力。</p><p><strong>多任务学习的主要挑战在于如何设计多任务之间的共享机制</strong>，在传统的机器学习任务中很难引入共享信息，但是在神经网络中就变得简单了许多，常见的以下四种：</p><ul><li><strong>硬共享模式</strong>：让不同任务的神经网络模型共同使用一些共享模块来提取一些通用的特征，然后再针对每个不同的任务设置一些私有模块来提取一些任务特定的特征。</li><li><strong>软共享模式</strong>：不显式设置共享模块，但每个任务都可以从其他任务中“窃取”一些信息来提高自己的能力。窃取的方式包括直接复制使用其他任务的隐状态，或使用注意力机制来主动选择有用的信息。</li><li><strong>层次共享模式</strong>：一般神经网络中不同层抽取的特征类型不同，底层一般抽取一些低级的局部特征，高层抽取一些高级的抽象语义特征。因此如果多任务学习中不同任务也有级别高低之分，那么一个合理的共享模式是让低级任务在底层输出，高级任务在高层输出。</li><li><strong>共享-私有模式</strong>：一个更加分工明确的方式是将共享模块和任务特定（私有）模块的责任分开。共享模块捕捉一些跨任务的共享特征，而私有模块只捕捉和特点任务相关的特征。最终的表示由共享特征和私有特征共同构成。</li></ul><p>在多任务学习中，每个任务都可以有自己单独的训练集。为了让所有任务同时学习，我们通常会使用交替训练的方式来“近似”的实现同时学习，下图给出了四种常见的共享模式图</p><p><img src="https://img-blog.csdnimg.cn/20191112101743882.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="四种常见的共享模式图"></p><p>多任务学习的流程可以分为两个阶段：</p><ul><li>（1）联合训练阶段：每次迭代时，随机挑选一个任务，然后从这个任务中随机选择一些训练样本，计算梯度并更新参数</li><li>（2）单任务精调阶段：基于多任务学习到的参数，分别在每个单独任务进行精调，其中单任务精调阶段为可选阶段。当多个任务的差异性比较大时，在每个单任务上继续优化参数可以进一步提升模型能力。</li></ul><p>假设有M个相关任务，其模型分别为$f_m(x,\theta), 1\leq m \leq M$，多任务学习的联合目标函数为所有任务损失函数的线性加权：</p><script type="math/tex; mode=display">L(\theta) = \sum_{m=1}^{M}\sum_{n=1}^{N_m} \eta_m l_m(f_m(x^{(m,n)}, \theta ), y_{(m,n)})</script><p>其中$l_m$为第m个任务的损失函数，$\eta_m$是第m个任务的权重，$\theta$表示包含了共享模块和私有模块在内的所有参数。</p><p>多任务学习中联合训练阶段的具体过程如下所示：<br><img src="https://img-blog.csdnimg.cn/20191112102456841.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="多任务学习中联合训练阶段的具体过程"></p><p>多任务学习通常比单任务学习获得更好的泛化能力，主要由于以下几个原因：</p><ul><li>1.多任务学习在多个数据集上进行训练，训练集范围更大，且多任务之间具有一定的相关性，相当于是一种隐式的数据增强，可以提高模型的泛化能力。</li><li>2.多任务学习中的共享模块需要兼顾所有任务，在一定程度上避免了模型过拟合到单个任务的训练集，可以看做是一种正则化。</li><li>3.多任务学习比单任务学习可以获得更好的表示</li><li>4.在多任务学习中，每个任务都可以“选择性”利用其他任务中学习到的隐藏特征，从而提高自身的能力。</li></ul><h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><p>标准机器学习的前提假设只训练数据和测试数据的分布是相同的。如果不满足这个假设，在训练集上学习到的模型在测试集上的表现会比较差。如何将相关任务的训练数据中学习到的可泛化知识迁移到目标任务中，就是迁移学习（Transfer Learning）要解决的问题。</p><p>迁移学习根据不同的迁移方式又分为两个类型：归纳迁移学习（Inductive Transfer Learning）和推导迁移学习（Transductive Transfer Learning）。这两个类型分别对应两个机器学习的范式：归纳学习（Inductive Learning）和转导学习（Transductive Learning）。一般的机器学习任务都是指归纳学习，即希望再训练集上学习到使得期望风险最小的模型。而转导学习的目标是学习一种在给定测试集上错误率最小的模型，在训练阶段可以利用测试集的信息。</p><h4 id="归纳迁移学习"><a href="#归纳迁移学习" class="headerlink" title="归纳迁移学习"></a>归纳迁移学习</h4><p>一般而言，归纳迁移学习要求源领域和目标领域时相关的，并且源领域$D_S$有大量的训练样本，这些样本可以是有标注的样本也可以时无标注的样本。</p><ul><li>当源领域只有大量无标注数据时，源任务可以转换为无监督学习任务，比如自编码和密度估计，通过无监督任务学习一种可迁移的表示，然后将这些表示迁移到目标任务上。</li><li><p>当源领域有大量的标注数据时，可以直接将源领域上训练的模型迁移到目标领域上。<br>归纳迁移学习一般有下面两种迁移方式：</p></li><li><p>基于特征的方式：将预训练模型的输出或者中间隐藏层的输出作为特征直接加入到目标任务学习模型中。目标任务的学习模型可以时一般的浅层分类器（比如支持向量机等）或一个新的神经网络模型。</p></li><li>精调的方式：在目标任务上复用预训练模型的部分参数，并对其参数进行精调。</li></ul><p>假设预训练的模型是一个深层神经网络，不同层的可迁移性也不尽相同。通常来说网络的低层学习一些通用的低层特征，中层或者高层学习抽象的高级语义特征，而最后几层一般学习和特定任务相关的特征。因此根据目标任务的自身特点以及和源任务的相关性，可以针对性的选择预训练模型的不同层来迁移到目标任务中。</p><p>将预训练模型迁移到目标任务中通常会比从零开始学习的方式好，主要体现在以下三点：</p><ul><li>（1）初始模型的性能一般比随机初始化的模型要好</li><li>（2）训练时模型的学习速度比从零开始学习要快，收敛性更好</li><li>（3）模型的最终性能更好，具有更好的泛化性</li></ul><p>归纳迁移学习和多任务学习也比较类似，但是有下面两点区别：</p><ul><li>（1）多任务学习是同时学习多个不同任务，而归纳迁移学习通常分为两个阶段，即源任务上的学习阶段，和目标任务上的迁移学习阶段</li><li>（2）归纳迁移学习是单向的知识迁移，希望提高模型在目标任务上的性能，而多任务学习时希望提高所有任务的性能。</li></ul><h4 id="转导迁移学习"><a href="#转导迁移学习" class="headerlink" title="转导迁移学习"></a>转导迁移学习</h4><p>转导迁移学习是一种从样本到样本的迁移，直接利用源领域和目标领域的样本进行迁移学习。转导迁移学习可以看作是一种特殊的转导学习。转导迁移学习通常假设源领域有大量的标注数据，而目标领域没有（或少量）的标注数据，但是有大量的无标注数据。目标领域的数据在训练阶段是可见的。</p><p>转导迁移学习的一个常见子问题时领域适应（Domain Adaptation），在领域适应问题中，一般假设源领域和目标领域有相同的样本空间，但是数据分布不同$p_S(x,y) \neq p_T(x,y)$。</p><p>根据贝叶斯公式，$p(x,y)=p(x|y)p(y) = p(y|x)p(x)$，因此数据分布的不一致通常由三种情况造成。</p><ul><li>（1）协变量偏移（Covariate Shift）：源领域和目标领域的输入边际分布不同$p_S(x) \neq p_T(x)$，但后验分布相同$p_S(y|x) = p_T(y|x)$，即学习任务相同$T_s = T_T$</li><li>（2）概念偏移（Concept Shift）：输入边际分布相同$p_S(x) = p_T(x)$，但后验分布不同$p_S(y|x) \ neq p_T(y|x)$，即学习任务不同$T_S \neq T_T$</li><li>（3）先验偏移（Prior Shift）：源领域和目标领域中的输出$y$先验分布不同$p_S(y) \neq p_T(y)$，条件分布相同$p_S(x|y) = p_T(x|y)$。在这样的情况下，目标领域必须提供一定数量的标注样本。</li></ul><h3 id="终生学习"><a href="#终生学习" class="headerlink" title="终生学习"></a>终生学习</h3><p>终生学习（Lifelong Learning）也叫持续学习（Continuous Learning）是指像人类一样具有持续不断的学习能力，根据历史任务中学到的经验和知识来帮助学习不断出现的新任务，并且这些经验和知识是持续累积的，不会因为新的任务而忘记旧的知识。</p><p>在终生学习中，假设一个终生学习算法已经在历史人任务$T_1, T_2, …$上学习到一个模型，当出现一个新任务$T_{m+1}$时，这个算法可以根据过去在$m$个任务上学习到的知识来帮助第$m+1$个任务，同时积累所有的$m+1$个任务上的知识。</p><p>在终生学习中，一个关键的问题是如何避免<strong>灾难性遗忘（Catastrophic Forgetting）</strong>，即按照一定顺序学习多个任务时，在学习新任务的同时不忘记先前学习到的历史知识。比如在神经网络模型中，一些参数对任务$T_A$非常重要，如果在学习任务$T_B$时被改变了，就可能给任务$T_A$造成不好的影响。</p><p>解决灾难性遗忘的方法有很多，比如弹性权重巩固方法（Elastic Weight Coonsolidation）。</p><h3 id="元学习"><a href="#元学习" class="headerlink" title="元学习"></a>元学习</h3><p>根据没有免费午餐定理，没有一种通用的学习算法在所有任务上都有效。因此当使用机器学习算法实现某个任务时，我们通常需要“就事论事”，根据任务的特定来选择合适的模型、损失函数、优化算法以及超参数。</p><p>而这种动态调整学习方式的能力，称为元学习（Meta-Learning），也称为学习的学习（Learning to Learn）。</p><p>元学习的目的时从已有的任务中学习一种学习方法或元知识，可以加速新任务的学习。从这个角度来说，元学习十分类似于归纳迁移学习，但元学习更侧重从多种不同的任务中归纳出一种学习方法。</p><p>这里主要介绍两种典型的元学习方法：基于优化器的元学习和模型无关的元学习。</p><h4 id="基于优化器的元学习"><a href="#基于优化器的元学习" class="headerlink" title="基于优化器的元学习"></a>基于优化器的元学习</h4><p>目前神经网络的的学习方法主要是定义一个目标损失函数$L(\theta)$，并通过梯度下降算法来最小化$L(\theta)$</p><script type="math/tex; mode=display">\theta_t \leftarrow \theta_{t-1} - \alpha \bigtriangledown L(\theta_{t-1})</script><p>其中$\theta_t$为第$t$步时的模型参数，$\bigtriangledown L(\theta_{t-1})$为梯度，$\alpha$为学习率。在不同的任务上，通常选择不同的学习绿以及不同的优化方法，比如动量法，Adam等。这些优化算法的本质区别在于更新参数的规则不同，因此一种很自然的元学习就是自动学习一种更新参数的规则，即通过另一个神经网络（比如循环神经网络）来建模梯度下降的过程。下图给出了基于优化器的元学习示例。</p><p><img src="https://img-blog.csdnimg.cn/20191112151007633.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="基于优化器的元学习示例"></p><p>我们用函数$g_t(.)$来预测第$t$步时参数更新的差值$\Delta \theta_t = \theta_t - \theta_{t-1}$，函数$g_t(.)$称为优化器，输入是当前时刻的梯度值，输出时参数的更新差值$\Delta \theta_t$，这样第$t$步的更新规则可以写为：</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t + g_t(\bigtriangledown L(\theta_{t}), \phi )</script><p>其中$\phi$为优化器$g_t(.)$的参数。</p><p>学习优化器$g_t(.)$的过程可以看做是一种元学习过程，其目标是找到一个适用于多个不同任务的优化器。在标准的梯度下降中，每步迭代的目标是使得$L(\theta)$下降。而在优化器的元学习中，我们希望在每步迭代的目标是$L(\theta)$最小，具体的目标函数为：</p><script type="math/tex; mode=display">L(\phi) = E_f [ \sum_{t=1}^{T} w_t L(\theta_t) ]\\\theta_t = \theta_{t-1} + g_t\\[g_t: h_t] = LSTM( \bigtriangledown L(\theta_{t-1}), h_{t-1}, \phi)</script><p>其中$T$为最大迭代次数，$w_t&gt;0$为每一步的权重，一般可以设置$w_t=1,\forall t$。由于LSTM网络可以记忆梯度的历史信息，学习到的优化器可以看做是一个高阶的优化方法。</p><h4 id="模型无关的元学习"><a href="#模型无关的元学习" class="headerlink" title="模型无关的元学习"></a>模型无关的元学习</h4><p>模型无关的元学习（Model-Agnostic Meta-Learning， MAML）是一个简单的模型无关、任务无关的元学习算法。假设所有的任务都来自一个任务空间，其分布为$p(T)$，我们可以在这个任务空间的所有任务上学习一种通用的表示，这种表示可以经过梯度下降方法在一个特定的单任务上进行精调。假设一个模型为$f(\theta)$，如果我们让这个模型适应到一个新任务$T_m$上，通过一步或多步的梯度下降更新，学习到的任务适配参数为：</p><script type="math/tex; mode=display">\theta_m ' = \theta- \alpha \bigtriangledown _\theta L_{T_m}(f_\theta)</script><p>其中$\alpha$为学习率，这里的$\theta_m’$可以理解为关于$\theta$的函数，而不是真正的参数更新。</p><p>MAML的目标是学习一个参数$\theta$使得其经过一个梯度迭代就可以在新任务上达到最好的性能。</p><script type="math/tex; mode=display">\underset{ \theta }{ min } \sum_{T_m \sim  p(T)} L_{T_m}(f(\theta'_m)) = \sum_{T_m \sim  p(T)} L_{T_m} ( f(\theta - \alpha \bigtriangledown _\theta L_{T_m} (f_\theta )) )</script><p>即在所有任务上的元优化（Meta-Optimization）也采用梯度下降来进行优化，即：</p><script type="math/tex; mode=display">\theta \leftarrow \theta - \beta \bigtriangledown _\theta \sum_{m=1}^{M} L_{T_m}(f_{\theta_m'})</script><p>其中$\beta$为元学习率，这里为一个真正的参数更新步骤。需要计算关于$\theta$的二阶梯度，但用一级近似通常也可以达到比较好的性能。</p><p>MAML的具体过程算法如下：<br><img src="https://img-blog.csdnimg.cn/20191112155840241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="MAML的具体过程算法"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>目前神经网路的学习机制主要是以监督学习为主，这种学习方式得到的模型往往是定向的，也是孤立的，每个任务的模型都是从零开始训练的，一切知识都需要从训练数据中得到，导致每个任务都需要大量的训练数据。本章主要介绍了一些和模型无关的学习方式，包括集成学习、自训练和协同训练、多任务学习、迁移学习、元学习，这些都是深度学习中研究的重点。</p><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;针对一个给定的任务，通常采取的步骤是：准确一定非规模的数据集，这些数据要和真实数据集的分布一致；然后设定一个优化目标和方法；然后在训练集上训
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="集成学习" scheme="http://thinkgamer.cn/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="迁移学习" scheme="http://thinkgamer.cn/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="元学习" scheme="http://thinkgamer.cn/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>【论文】文本相似度计算方法综述</title>
    <link href="http://thinkgamer.cn/2019/11/07/%E8%AE%BA%E6%96%87/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0/"/>
    <id>http://thinkgamer.cn/2019/11/07/论文/【论文】文本相似度计算方法综述/</id>
    <published>2019-11-07T07:55:25.000Z</published>
    <updated>2019-11-14T02:26:37.482Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>在信息爆炸时代，人们迫切希望从海量信息中获取与自身需要和兴趣吻合度高的内容，为了满足此需求，出现了多种技术，如：搜索引擎、推荐系统、问答系统、文档分类与聚类、文献查重等，而这些应用场景的关键技术之一就是文本相似度计算技术。因此了解文本相似度的计算方法是很有必要的。</p><h1 id="文本相似度定义"><a href="#文本相似度定义" class="headerlink" title="文本相似度定义"></a>文本相似度定义</h1><p>文本相似度在不同领域被广泛讨论，由于应用场景不同，其内涵有所差异，故没有统一、公认的定义。</p><p>Lin从信息论的角度阐明相似度与文本之间的共性和差异有关，共性越大、差异越小、则相似度越高；共性越小、差异越大、则相似度越低。相似度最大的情况是文本完全相同。同时提出基于假设推论出相似度定理，如下所示：</p><script type="math/tex; mode=display">Sim(A,B) = \frac{ log P(common(A,B)) } {log P(description(A,B))}</script><p>其中，common(A,B)是A和B的共性信息，description(A,B)是描述A和B的全部信息，上述公式表达出相似度与文本共性成正相关。 由于没有限制领域，此定义被采用较多。</p><blockquote><p>相关度与相似度是容易混淆的概念，大量学者没有对此做过对比说明。相关度体现在文本共现或者以任何形式相互关联（包括上下位关系、同义关系、反义关系、部件-整体关系、值-属性关系等）反映出文本的组合特点。而相似度是相关度的一种特殊情况，包括上下位关系和同义关系。由此得出，文本的相似度越高，则相关度越大，但是相关度越大并不能说明相似度高。</p></blockquote><p>相似度一般用[0,1]表示，该实数可以通过语义距离计算获得。相似度与语义距离呈反比关系，语义距离越小，相似度越高；语义距离越大，相似度越低。通常用下面的公式表示相似度与语义距离的关系。</p><script type="math/tex; mode=display">Sim(S_A,S_B) = \frac {\alpha} { Dis(S_A,S_B) + \alpha }</script><p>其中，$Dis(S_A,S_B)$表示文本$S_A,S_B$之间的非负语义距离，$\alpha$为调节因子，保证了当语义距离为0时上述公式的意义。</p><p>文本相似度计算中还有一个重要的概念是文本表示，代表对文本的基本处理，目的是将半结构化或非结构化的文本转化为计算机可读形式。<strong>文本相似度计算方法的不同本质是文本表示方法不同</strong></p><h1 id="文本相似度计算方法"><a href="#文本相似度计算方法" class="headerlink" title="文本相似度计算方法"></a>文本相似度计算方法</h1><p><img src="https://img-blog.csdnimg.cn/20191105152528460.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="文本相似度计算方法"></p><p>文本相似度计算方法可分为四大类：</p><ul><li>基于字符串的方法（String-Based）</li><li>基于语料库的方法（Corpus-Based）</li><li>基于世界知识的方法（Knowledge-Based）</li><li>其他方法</li></ul><h2 id="基于字符串的方法"><a href="#基于字符串的方法" class="headerlink" title="基于字符串的方法"></a>基于字符串的方法</h2><p>该方法从字符串匹配度出发，以字符串共现和重复程度为相似度的衡量标准。根据计算粒度不同，可以将该方法分为<strong>基于字符的方法</strong>和<strong>基于词语的方法</strong>。下图列出两种方法常见的算法以及思路</p><p><img src="https://img-blog.csdnimg.cn/20191105153106412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="基于字符串的方法"></p><p>基于字符串的方法是在字面层次上的文本比较，文本表示即为原始文本，该方法原理简单，易于实现，现已成为其他方法的计算基础。</p><p>但不足的是将字符或词语作为独立的知识单元，并未考虑词语本身的含义和词语之间的关系。以同义词为例，尽管表达不同，但具有相同的含义，而这类词语的相似度依靠基于字符串的方法并不能准确计算。</p><h2 id="基于语料库的方法"><a href="#基于语料库的方法" class="headerlink" title="基于语料库的方法"></a>基于语料库的方法</h2><p>基于语料库的方法利用语料库中获取的信息计算文本相似度。基于语料库的方法可以划分为：</p><ul><li>基于词袋模型的方法</li><li>基于神经网络的方法</li><li>基于搜索引擎的方法</li></ul><h3 id="基于词袋"><a href="#基于词袋" class="headerlink" title="基于词袋"></a>基于词袋</h3><p>词袋模型（Bag of Words Model，BOW）建立在分布假说的基础上，即“词语所处的上下文语境相似，其语义则相似”。其基本思想是：不考虑词语在文档中出现的顺序，将文档表示成一系列词语的组合。</p><p>根据考虑的语义成程度不同，基于词袋模型的方法主要包括：</p><ul><li>向量空间模型（Vector Space Model，VSM）</li><li>潜在语义分析（Latent Semantic Analysis，LSA）</li><li>概率潜在语义分析（Probabilistic Latent Semantic Analysis，PLSA）</li><li>潜在狄利克雷分布（Latent Dirichlet Allocation，LDA）</li></ul><h4 id="VSM"><a href="#VSM" class="headerlink" title="VSM"></a>VSM</h4><p>VSM模型的基本思想是将每篇文档表示成一个基于词频或者词频-逆文档频率权重的实值向量，那么N篇文档则构成n维实值空间，其中空间的每一维都对用词项，每一篇文档表示该空间的一个点或者向量。两个文档之间的相似度就是两个向量的距离，一般采用余弦相似度方法计算。</p><p>VSM有两个明显的缺点：一是该方法基于文本中的特征项进行相似度计算，当特征项较多时，产生的高维稀疏矩阵导致计算效率不高；二是向量空间模型算法的假设是文本中抽取的特征项没有关联，不符合文本语义表达。</p><h4 id="LSA，PLSA"><a href="#LSA，PLSA" class="headerlink" title="LSA，PLSA"></a>LSA，PLSA</h4><p>LSA算法的基本思想是将文本从稀疏的高维词汇空间映射到低维的潜在语义空间，在潜在的语义空间计算相似性。LSA是基于VSM提出的，两种方法都是采用空间向量表示文本，但LSA使用潜在语义空间，利用奇异值分解提高对高维的词条-文档矩阵进行处理，去除了原始向量空间的某些“噪音”，使数据不再稀疏。Hofmann在LSA的基础上引入主题层，采用期望最大化算法（EM）训练主题。</p><p>LSA本质上是通过降维提高计算准确度，但该算法复杂度比较高，可移植性差，比较之下，PLSA具备统计基础，多义词和同义词在PLSA中分别被训练到不同的主题和相同的主题，从而避免了多义词，同义词的影响，使得计算结构更加准确，但不适用于大规模文本。</p><h4 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h4><p>LDA主题模型是一个三层的贝叶斯概率网络，包含词、主题和文档三层结构。采用LDA计算文本相似性的基本思想是对文本进行主题建模，并在主题对应的词语分布中遍历抽取文本中的词语，得到文本的主题分布，通过此分布计算文本相似度。</p><p>以上三类尽管都是采用词袋模型实现文本表示，但是不同方法考虑的语义程度有所不同。基于向量空间建模的方法语义程度居中，加入潜在语义空间概念，解决了向量空间模型方法的稀疏矩阵问题并降低了多义词，同义词的影响。基于LDA的主题模型的方法语义程度最高，基于相似词语可能属于统一主题的理论，主题经过训练得到，从而保证了文本的语义性。</p><h3 id="基于神经网络"><a href="#基于神经网络" class="headerlink" title="基于神经网络"></a>基于神经网络</h3><p>基于神经网络生成词向量计算文本相似度是近些年提的比较多的。不少产生词向量的模型和工具也被提出，比如Word2Vec和GloVe等。词向量的本质是从未标记的非结构文本中训练出一种低维实数向量，这种表达方式使得类似的词语在距离上更为接近，同时较好的解决了词袋模型由于词语独立带来的维数灾难和语义不足问题。</p><p>基于神经网络方法与词袋模型方法的不同之处在于表达文本的方式。词向量是经过训练得到的低维实数向量，维数可以认为限制，实数值可根据文本距离调整，这种文本表示符合人理解文本的方式，所以基于词向量判断文本相似度的效果有进一步研究空间。</p><h3 id="基于搜索引擎"><a href="#基于搜索引擎" class="headerlink" title="基于搜索引擎"></a>基于搜索引擎</h3><p>基本原理是给定搜索关键词$x,y$，搜索引擎返回包含 $x,y$的网页数量$f(x),f(y)$以及同时包含$x,y$的网页数量$f(x,y)$，计算谷歌相似度距离如下所示:</p><script type="math/tex; mode=display">NGD(x,y) = \frac { G(x,y) - min(G(x),G(y)) } { max(G(x),G(y)}\\= \frac {max\{ log \,f(x), log\,f(y) \} - log \, f(x,y)} { log \, N - min{log \,f(x), log \, f(y)} }</script><p>但是该方法最大的不足是计算结果完全取决于搜索引擎的查询效果, 相似度因搜索引擎而异</p><h2 id="基于世界知识的方法"><a href="#基于世界知识的方法" class="headerlink" title="基于世界知识的方法"></a>基于世界知识的方法</h2><p>基于世界知识的方法是利用具有规范组织体系的知识库计算文本相似度，一般分为两种：基于本体知识和基于网络知识。</p><h3 id="基于本体知识"><a href="#基于本体知识" class="headerlink" title="基于本体知识"></a>基于本体知识</h3><p>文本相似度计算方法使用的本体不是严格的本体概念, 而指广泛的词典、叙词表、词汇表以及狭义的本体。由于本体能够准确地表示概念含义并能反映出概念之间的关系, 所以本体成为文本相似度的研究基础[7]。最常利用的本体是通用词典, 例如 WordNet、《知网》(HowNet)和《同义词词林》等, 除了词典还有一些领域本体, 例如医疗本体、电子商务本体、地理本体、农业本体等。</p><p>结合Hliaoutaki、Batet等的研究，将基于本体的文本相似度算法概括为四种：</p><ul><li>基于距离</li><li>基于内容</li><li>基于属性</li><li>混合式相似度</li></ul><p>下表列出了各种方法的基本原理、代表方法和特点<br><img src="https://img-blog.csdnimg.cn/20191105162644574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="基于本体的文本相似度算法"></p><h3 id="基于网络知识"><a href="#基于网络知识" class="headerlink" title="基于网络知识"></a>基于网络知识</h3><p>由于本体中词语数量的限制，有些学者开始转向基于网络知识方法的研究，原因是后者覆盖范围广泛、富含丰富的语义信息、更新速度相对较快，使用最多的网络知识是维基百科、百度百科。网络知识一般包括两种结构，分别是词条页面之间的链接和词条之间的层次结构。</p><p>基于网络知识的文本相似度计算方法大多利用页面链接或层次结构，能较好的反映出词条的语义关系。但其不足在于：词条与词条的信息完备程度差异较大，不能保证计算准确度，网络知识的生产方式是大众参与，导致文本缺少一定的专业性。</p><h2 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h2><p>除了基于字符串、基于语料库和基于世界知识的方法, 文本相似度计算还有一些其他方法，比如：</p><ul><li>句法分析</li><li>混合方法</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文总结了文本相似度计算的四种方法，以及他们的优缺点。作者认为今后文本相似度的计算方法趋势有三个方向，分别是：</p><ul><li>基于神经网络的方法研究将更加丰富</li><li>网络资源为文本相似度计算方法研究提供更多支持</li><li>针对特定领域以及跨领域文本的相似度计算将成为今后发展的重点</li></ul><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;在信息爆炸时代，人们迫切希望从海量信息中获取与自身需要和兴趣吻合度高的内容，为了满足此需求，出现了多种技术，如：搜索引擎、推荐系统、问答系统
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="NLP" scheme="http://thinkgamer.cn/tags/NLP/"/>
    
      <category term="论文" scheme="http://thinkgamer.cn/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="文本相似度" scheme="http://thinkgamer.cn/tags/%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>无监督学习中的无监督特征学习、聚类和密度估计</title>
    <link href="http://thinkgamer.cn/2019/11/05/TensorFlow/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%97%A0%E7%9B%91%E7%9D%A3%E7%89%B9%E5%BE%81%E5%AD%A6%E4%B9%A0%E3%80%81%E8%81%9A%E7%B1%BB%E5%92%8C%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1/"/>
    <id>http://thinkgamer.cn/2019/11/05/TensorFlow/无监督学习中的无监督特征学习、聚类和密度估计/</id>
    <published>2019-11-05T02:58:36.000Z</published>
    <updated>2019-11-14T02:26:37.480Z</updated>
    
    <content type="html"><![CDATA[<h2 id="无监督学习概述"><a href="#无监督学习概述" class="headerlink" title="无监督学习概述"></a>无监督学习概述</h2><p>无监督学习（Unsupervised Learning）是指从无标签的数据中学习出一些有用的模式，无监督学习一般直接从原始数据进行学习，不借助人工标签和反馈等信息。典型的无监督学习问题可以分为以下几类：</p><ul><li><p>无监督特征学习（Unsupervised Feature Learning）</p><blockquote><p>从无标签的训练数据中挖掘有效的特征表示，无监督特征学习一般用来进行降维，数据可视化或监督学习前期的特征预处理。</p></blockquote></li><li><p>密度估计（Density Estimation）</p><blockquote><p>是根据一组训练样本来估计样本空间的概率密度。密度估计可以分为：参数密度估计和非参数密度估计。参数密度估计是假设数据服从某个已知概率密度函数形式的分布，然后根据训练样本去估计该分布的参数。非参数密度估计是不假设服从某个概率分布，只利用训练样本对密度进行估计，可以进行任意形状的密度估计，非参数密度估计的方法包括：直方图、核密度估计等。</p></blockquote></li><li><p>聚类（Clustering）</p><blockquote><p>是将一组样本根据一定的准则划分到不同的组。一个通用的准则是组内的样本相似性要高于组间的样本相似性。常见的聚类方法包括：KMeans、谱聚类、层次聚类等。</p></blockquote></li></ul><p>聚类大家已经非常熟悉了，下文主要介绍无监督特征学习和概率密度估计。</p><h2 id="无监督特征学习"><a href="#无监督特征学习" class="headerlink" title="无监督特征学习"></a>无监督特征学习</h2><p>无监督特征学习是指从无标注的数据中自动学习有效的数据表示，从而能够帮助后续的机器学习模型达到更好的性能。无监督特征学习主要方法有：</p><ul><li>主成分分析</li><li>稀疏编码</li><li>自编码器</li></ul><h3 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h3><p>主成分分析（Principal Component Analysis，PCA）是一种最常用的数据降维方法，使得在转换后的空间中数据的方差最大。以下部分摘自于 <a href="https://zhuanlan.zhihu.com/p/32412043" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/32412043</a></p><h4 id="PCA中的最大可分性思想"><a href="#PCA中的最大可分性思想" class="headerlink" title="PCA中的最大可分性思想"></a>PCA中的最大可分性思想</h4><p>PCA降维，用原始样本数据中最主要的方面代替原始数据，最简单的情况是从2维降到1维，如下图所示，我们希望找到某一个维度方向，可以代表两个维度的数据，图中列了两个方向 $u_1, u_2$，那么哪个方向可以更好的代表原始数据呢？</p><p><img src="https://img-blog.csdnimg.cn/2019110418180564.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="最大可分性示例"><br>从直观上看，$u_1$比$u_2$好，这就是所说的最大可分性。</p><h4 id="基变换"><a href="#基变换" class="headerlink" title="基变换"></a>基变换</h4><p><img src="https://img-blog.csdnimg.cn/20191104182446889.jpg" alt="基变换"></p><p>其中$p_i \in {p_1, p_2, …, p_R}$，$p_i \in R^{1<em>N}$是一个行向量，表示第i个基，$a_j \in {a_1, a_2, …, a_M}$，$a_i \in R^{N</em>1}$是一个列向量，表示第$j$个原始数据记录，特别要注意的是，这里R可以小于N，而R决定了变维后数据的维数。</p><p>从上图和文字解释我们可以得到一种矩阵相乘的物理解释：两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去。更抽象的说，一个矩阵可以表示一种线性变换。很多同学在学习矩阵相乘时，只是简单的记住了相乘的规则，但并不清楚其背后的物理意义。</p><h4 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h4><p>如何考虑一个方向或者基是最优的，看下图：</p><p><img src="https://img-blog.csdnimg.cn/20191104184311912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="周志华机器学习插图"></p><p>我们将所有的点向两条直线做投影，基于前面PCA最大可分性思想，我们要找的是降维后损失最小，可以理解为投影后数据尽可能的分开，那么在数学中去表示数据的分散使用的是方差，我们都知道方差越大，数据越分散，方差的表达式如下：</p><script type="math/tex; mode=display">Var(a) = \frac{1}{m} \sum_{i=1}^{m} (a_i - \mu)^2</script><p>其中$\mu$为样本均值，如果提前对样本做去中心化，则方差表达式为：</p><script type="math/tex; mode=display">Var(a) = \frac{1}{m} \sum_{i=1}^{m} (a_i)^2</script><p>到现在，我们知道了以下几点：</p><ul><li>对原始数据进行（线性变换）基变换可以对原始样本给出不同的表示</li><li>基的维度小于样本的维度可以起到降维的作用，</li><li>对基变换后新的样本求其方差，选取使其方差最大的基</li></ul><p>那么再考虑另外一个问题？</p><blockquote><p>上面只是说明了优化目标，但并没有给出一个可行性的操作方案或者算法，因为只说明了要什么，但没说怎么做，所以继续进行探讨。</p></blockquote><h4 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h4><p>从二维降到一维可以采用方差最大来选出能使基变换后数据分散最大的方向（基），但遇到高纬的基变换，当完成第一个方向（基）选择后，第二个投影方向应该和第一个“几乎重合在一起”，这样显然是没有用的，要有其他的约束，我们希望两个字段尽量表示更多的信息，使其不存在相关性。</p><p>数学上使用协方差表示其相关性。</p><script type="math/tex; mode=display">Cov(a,b)= \frac{1}{m} \sum_{i=1}^{m}a_i b_i</script><p>当Cov(a,b)=0时表示两个字段完全独立，也是我们优化的目标。</p><blockquote><p>注意这里的 $a_i,b_i$是经过去中心化处理的。</p></blockquote><h4 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a>协方差矩阵</h4><p>我们想要达到的目标与字段内方差及协方差有密切的关系，假如只有a、b两个字段，将他们按行组成矩阵X，表示如下：</p><p><img src="https://img-blog.csdnimg.cn/20191104190715730.png" alt="矩阵X"></p><p>然后用X乘以X的转置矩阵，并乘以系数 $\frac{1}{m}$得：</p><p><img src="https://img-blog.csdnimg.cn/20191104190820539.png" alt="在这里插入图片描述"></p><p>可见，协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差，而其他元素是a 和 b的协方差，然后会发现两者被合并到了一个矩阵内。</p><h4 id="协方差矩阵对角化"><a href="#协方差矩阵对角化" class="headerlink" title="协方差矩阵对角化"></a>协方差矩阵对角化</h4><p>我们的目标是使$\frac{1}{m}\sum_{i=1}^{m}a_ib_i=0$，根据上述的推导，可以看出优化目标是$C=\frac{1}{m}XX^T$等价于协方差矩阵对角化。即除对角线外的其他元素（如$\frac{1}{m} \sum_{i=1}^{m}a_i b_i$）化为0，并且在对角线上将元素按大小从上到下排列，这样我们就达成了优化目的。</p><p>这样说可能不是很明晰，我们进一步看下原矩阵和基变换后矩阵协方差矩阵的关系：</p><p>设原始数据矩阵为X，对应的协方差矩阵为C，而P是一组基按行组成的矩阵，设Y=PX，则Y为X对P做基变换后的数据。设Y的协方差矩阵为D，我们推导一下D与C的关系：</p><script type="math/tex; mode=display">D=\frac{1}{m}YY^T\\= \frac{1}{m}(PX)(PX)^T\\= \frac{1}{m} PXX^TP^T\\=P(\frac{1}{m} XX^T)P^T\\= PCP^T\\=P \begin{pmatrix}\frac{1}{m} \sum_{i=1}^{m} a_i^2 & \frac{1}{m} \sum_{i=1}^{m} a_i b_i \\  \frac{1}{m} \sum_{i=1}^{m} a_ib_i  & \frac{1}{m} \sum_{i=1}^{m} b_i^2 \end{pmatrix} P^T</script><p>可见我们要找的P不是别的，而是能让原始协方差矩阵对角化的P。换句话说，优化目标变成了寻找一个矩阵P，满足$PCP^T$是一个对角矩阵，并且对角元素按从大到小依次排列，那么P的前K行就是要寻找的基，用P的前K行组成的矩阵乘以X就使得X从N维降到了K维并满足上述优化条件。</p><p>我们希望投影后的方差最大化，于是优化目标可以改写为：</p><script type="math/tex; mode=display">\underset{P}{max} \, tr(PCP^T)\\s.t. \,PP^T=I</script><p>利用拉格朗日函数可以得到：</p><script type="math/tex; mode=display">J(P) = tr(PCP^T) + \lambda(PP^T - I)</script><p>对P求导有$CP^T + \lambda P^T = 0$，整理得：</p><script type="math/tex; mode=display">CP^T = (- \lambda) P^T</script><p>于是，只需对协方差矩阵C进行特征分解，对求得的特征值进行排序，再对 $P^T = (P_1, P_2, …, P_R)$取前K列组成的矩阵乘以原始数据矩阵X，就得到了我们需要的降维后的数据矩阵Y。</p><h4 id="PCA算法流程"><a href="#PCA算法流程" class="headerlink" title="PCA算法流程"></a>PCA算法流程</h4><p>从上边可以看出，求样本$x_i$的$n’$维的主成分，其实就是求样本集的协方差矩阵$\frac{1}{m}XX^T$的前$n’$维个特征值对应特征向量矩阵P，然后对于每个样本$x_i$，做如下变换$y_i = P x_i$，即达到PCA降维的目的。</p><p>具体的算法流程如下：</p><ul><li>输入：n维的样本集 $X=(x_i, x_2,…,x_m)$，要降维到的维数$n’$</li><li>输出：降维后的维度Y</li></ul><ol><li>对所有的样本集去中心化 $x_i = x_i - \frac{1}{m} \sum_{j=1}^{m}x_j$</li><li>计算样本的协方差矩阵$C = \frac{1}{m}XX^T$</li><li>求出协方差矩阵对应的特征值和对应的特征向量</li><li>将特征向量按照特征值从大到小，从上到下按行排列成矩阵，取前k行组成矩阵P</li><li>$Y=PX$即为降维到K维之后的数据</li></ol><p>注意：有时候降维并不会指定维数，而是指定一个比例$t$，比如降维到原先的t比例。</p><h4 id="PCA算法总结"><a href="#PCA算法总结" class="headerlink" title="PCA算法总结"></a>PCA算法总结</h4><p>PCA算法的主要优点：</p><ul><li>仅仅需要以方差衡量信息量，不受数据集意外因素的影响</li><li>各主成分之间正交，可消除原始数据各成分间的相互影响的因素</li><li>方法设计简单，主要运算是特征值分解，易于实现</li></ul><p>PCA算法的主要缺点：</p><ul><li>主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的可解释性强</li><li>方差小的非主成分也可能包含对样本差异的重要信息，因降维丢弃可能会对后续数据处理有影响</li><li>当样本特征维度较大时，需要巨大的计算量（比如，10000*10000，这时候就需要SVD[奇异值分解]，SVD不仅可以得到PCA降维的结果，而且可以大大的减小计算量）</li></ul><h3 id="稀疏编码"><a href="#稀疏编码" class="headerlink" title="稀疏编码"></a>稀疏编码</h3><h4 id="稀疏编码（Sparse-Coding）介绍"><a href="#稀疏编码（Sparse-Coding）介绍" class="headerlink" title="稀疏编码（Sparse Coding）介绍"></a>稀疏编码（Sparse Coding）介绍</h4><p>在数学上，线性编码是指给定一组基向量$A=[a_1,a_2,…,a_p]$，将输入样本$x\in R$表示为这些基向量的线性组合</p><script type="math/tex; mode=display">x = \sum _{i=1}^{p} z_i a_i = Az</script><p>其中基向量的系数$z=[z_1,…,z_p]$称为输入样本x的编码，基向量A也称为字典（dictionary）。</p><p>编码是对d维空间中的样本x找到其在p维空间中的表示（或投影），其目标通常是编码的各个维度都是统计独立的，并且可以重构出输入样本。编码的关键是找到一组“完备”的基向量A，比如主成分分析等。但是是主成分分析得到的编码通常是稠密向量，没有稀疏性。</p><blockquote><p>如果p个基向量刚好可以支撑p维的欧式空间，则这p个基向量是完备的，如果p个基向量可以支撑d维的欧式空间，并且p&gt;d，则这p个基向量是过完备，冗余的。<br><br><br>“过完备”基向量一般指的是基向量个数远大于其支撑空间维度，因此这些基向量一般是不具备独立，正交等性质。</p></blockquote><p>给定一组N个输入向量$x^1, …, x^N$，其稀疏编码的目标函数定义为：</p><script type="math/tex; mode=display">L(A,Z)= \sum _{n=1}^{N}( || x^n - Az^n || ^2 + \eta \rho (z^n))</script><p>其中$\rho(.)$是一个稀疏性衡量函数，$\eta$是一个超参数，用来控制稀疏性的强度。</p><p>对于一个向量$z \in R$，其稀疏性定义为非零元素的比例。如果一个向量只有很少的几个非零元素，就说这个向量是稀疏的。稀疏性衡量函数$\rho(z)$是给向量z一个标量分数。z越稀疏，$\rho(z)$越小。</p><p>稀疏性衡量函数有多种选择，最直接的衡量向量z稀疏性的函数是$l_0$范式</p><script type="math/tex; mode=display">\rho(z) = \sum _{i=1}^{p} I(|z_i| > 0)</script><p>但$l_0$范数不满足连续可导，因此很难进行优化，在实际中，稀疏性衡量函数通常选用$l_1$范数</p><script type="math/tex; mode=display">\rho(z) = \sum _{i=1}^{p} |z_i|</script><p>或对数函数</p><script type="math/tex; mode=display">\rho(z) = \sum _{i=1}^{p} log(1+z_i^2)</script><p>或指数函数</p><script type="math/tex; mode=display">\rho(z) = \sum _{i=1}^{p} -exp(-z_i^2)</script><h4 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h4><p>给定一组N个输入向量$x^1, … , x^N$，需要同时学习基向量A以及每个输入样本对应的稀疏编码$z^1, …,z^N$。</p><p>稀疏编码的训练过程一般用交替优化的方法进行（这一点和ALS很相似）。</p><p>（1）固定基向量A，对每个输入$x^n$ ，计算其对应的最优编码（原内容为减去稀疏性衡量函数，觉得不对）</p><script type="math/tex; mode=display">\underset{x^n}{min} || x^n - Az^n ||^2 + \eta \rho (z^n), \forall n \in [1,N]</script><p>（2）固定上一步得到的编码$z^1, …,z^N$，计算其最优的基向量</p><script type="math/tex; mode=display">\underset{A}{min} \sum _{i=1}^{N} ( || x^n - Az^n ||^2 ) + \lambda \frac{1}{2} ||A||^2</script><p>其中第二项为正则化项，$\lambda$为正则化项系数。</p><h4 id="稀疏编码优缺点"><a href="#稀疏编码优缺点" class="headerlink" title="稀疏编码优缺点"></a>稀疏编码优缺点</h4><p>稀疏编码的每一维都可以看作是一种特征，和基于稠密向量的分布式表示相比，稀疏编码具有更小的计算量和更好的可解释性等优点。</p><p><strong>计算量</strong> 稀疏性带来的最大好处就是可以极大的降低计算量</p><p><strong>可解释性</strong> 因为稀疏编码只有少数的非零元素，相当于将一个输入样本表示为少数几个相关的特征，这样我们可以更好的描述其特征，并易于理解</p><p><strong>特征选择</strong> 稀疏性带来的另一个好处是可以实现特征的自动选择，只选择和输入样本相关的最少特征，从而可以更好的表示输入样本，降低噪声并减轻过拟合</p><h3 id="自编码器"><a href="#自编码器" class="headerlink" title="自编码器"></a>自编码器</h3><p>自编码器（Auto-Encoder，AE）是通过无监督的方式来学习一组数据的有效编码。</p><p>假设有一组d维的样本$x^n \in R^d, 1 \leq n \leq N$，自编码器将这组数据映射到特征空间得到每个样本的编码$z^n \in R^p, 1 \leq n \leq N$，并且希望这组编码可以重构出原来的样本。</p><p>自编码器的结构可分为两部分：编码器（encoder）：$f: R^d -&gt; R^p$和解码器（decoder）：$R^p -&gt; R^d$</p><p>自编码器的学习目标是最小化重构误差（reconstruction errors）</p><script type="math/tex; mode=display">L = \sum_{n=1}^{N} || x^n -g(f(x^n)) ||^2 = \sum || x^n -f \cdot  g(x^n) ||^2</script><p>如果特征空间的维度p小雨原始空间的维度d，自编码器相当于是一种降维或特征抽取方法。如果$p \geq d$，一定可以找到一组或多组解使得$f \cdot g$为单位函数（Identity Function），并使得重构错误为0。但是这样的解并没有太多的意义，但是如果再加上一些附加的约束，就可以得到一些有意义的解，比如编码的稀疏性、取值范围，f和g的具体形式等。如果我们让编码只能取k个不同的值（k&lt;N），那么自编码器就可以转换为一个k类的聚类问题。</p><p>最简单的自编码器如下图所示的两层神经网络，输入层到隐藏层用来编码，隐藏层到输出层用来解码，层与层之间互相全连接。</p><p><img src="https://img-blog.csdnimg.cn/20191104162315242.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="最简单的自编码器"></p><p>对于样本x，中间隐藏层为编码：</p><script type="math/tex; mode=display">z = s(W^1 x + b^l)</script><p>输出为重构的数据</p><script type="math/tex; mode=display">x' = s(W^2 z + b^l)</script><p>其中$W,b$为网格参数，$s(.)$为激活函数。如果令$W^2$等于$W^1$的转置，即$W^2=W^{(1)T}$，称为捆绑权重（tied weights）。</p><p>给定一组样本 $x^n \in [0,1]^d, 1 \leq n \leq N$，其重构错误为：</p><script type="math/tex; mode=display">L = \sum_{n=1}^{N} || x^n -x^{'n} ||^2 + \lambda ||W||_F^2</script><p>其中$\lambda$为正则化系数，通过最小化重构误差，可以有效的学习网格的参数。</p><p>我们使用自编码器是为了得到有效的数据表示，因此在训练数据后，我们一般去掉解码器，只保留编码器，编码器的输出可以直接作为后续机器学习模型的输入。</p><h3 id="稀疏自编码器"><a href="#稀疏自编码器" class="headerlink" title="稀疏自编码器"></a>稀疏自编码器</h3><p>自编码器除了可以学习低维编码之外，也学习高维的稀疏编码。假设中间隐藏层z的维度为p，大于输入样本的维度，并让z尽量稀疏，这就是稀疏自编码器（Sparse Auto-Encoder）。和稀疏编码一样，稀疏自编码器的优点是有很高的模型可解释性，并同时进行了隐式的特征选择。</p><p>通过给自编码器中隐藏单元z加上稀疏性限制，自编码器可以学习到数据中一些有用的结构。</p><h3 id="堆叠自编码器"><a href="#堆叠自编码器" class="headerlink" title="堆叠自编码器"></a>堆叠自编码器</h3><p>对于很多数据来说，仅使用两层神经网络的自编码器还不足以获取一种好的数据表示，为了获取更好的数据表示，我们可以使用更深层的神经网络。深层神经网络作为自编码器提取的数据表示一般会更加抽象，能够很好的捕捉到数据的语义信息。在实践中经常使用逐层堆叠的方式来训练一个深层的自编码器，称为堆叠自编码器（Stacked Auto-Encoder，SAE）。堆叠自编码一般可以采用逐层训练（layer-wise training）来学习网络参数。</p><h3 id="降噪自编码器"><a href="#降噪自编码器" class="headerlink" title="降噪自编码器"></a>降噪自编码器</h3><p>降噪自编码器（Denoising Autoencoder）就是一种通过引入噪声来增加编码鲁棒性的自编码器。对于一个向量x，我们首先根据一个比例$\mu$随机将x的一些维度的值设置为0，得到一个被损坏的向量$\tilde x$。然后将被损坏的向量$\tilde x$输入给自编码器得到编码z，并重构原始的无损输入x。</p><p>下图给出了自编码器和降噪自编码器的对比，其中$f_{\theta}$为编码器，$g_{\theta^’}$为解码器，$L(x,x’)$为重构错误。</p><p><img src="https://img-blog.csdnimg.cn/20191104175727219.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="自编码器和降噪自编码器的对比"></p><p>降噪自编码器的思想十分简单，通过引入噪声来学习更鲁棒性的数据编码，并提高模型的泛化能力。</p><h2 id="概率密度估计"><a href="#概率密度估计" class="headerlink" title="概率密度估计"></a>概率密度估计</h2><p>概率密度估计（Probabilistic Density Estimation）简称密度估计（Density Estimation），是基于一些观测样本来估计一个随机变量的概率密度函数。密度估计在机器学习和数学建模中应用十分广泛。</p><p>概率密度估计分为：</p><ul><li>参数密度估计</li><li>非参数密度估计</li></ul><h3 id="参数密度估计"><a href="#参数密度估计" class="headerlink" title="参数密度估计"></a>参数密度估计</h3><p>参数密度估计（Parametric Density Estimation）是根据先验知识假设随机变量服从某种分布，然后通过训练样本来估计分布的参数。</p><p>令 $D = {\{x^n\}}_{i=1}^{N}$为某个未知分布中独立抽取的N个训练样本，假设这些样本服从一个概率分布函数$p(x|\theta)$，其对数似然函数为：</p><script type="math/tex; mode=display">log\,p(D|\theta) = \sum_{n=1}^{N}log\,p(x^n|\theta)</script><p>要估计一个参数$\theta ^{ML}$来使得：</p><script type="math/tex; mode=display">\theta ^{ML} = \underset{\theta}{arg\,max } \sum_{n=1}^{N}log\,p(x^n|\theta)</script><p>这样参数估计问题就转化为最优化问题。</p><h4 id="正态分布中的参数密度估计"><a href="#正态分布中的参数密度估计" class="headerlink" title="正态分布中的参数密度估计"></a>正态分布中的参数密度估计</h4><p>假设样本$x \in X$服从正态分布 $X \sim N(\mu,\sigma^2)$，正态分布的表达式如下：</p><script type="math/tex; mode=display">X \sim N(\mu,\sigma^2) = \frac{1}{ \sqrt{2\pi} \sigma^2} e^{- \frac{(x-\mu)^2}{2\sigma^2}}</script><p>求 $\mu,\sigma^2$的最大似然估计量。</p><p>$X$的概率密度为：</p><script type="math/tex; mode=display">f(x;\mu,\sigma^2) = \frac{1}{ \sqrt{2\pi} \sigma^2} e^{- \frac{(x-\mu)^2}{2\sigma^2}}</script><p>似然函数为：</p><script type="math/tex; mode=display">L(\mu,\sigma^2) = \prod_{i=1}^{N} \frac{1}{ \sqrt{2\pi} \sigma^2} e^{- \frac{(x-\mu)^2}{2\sigma^2}}\\= (2\pi)^{-\frac{N}{2}} (\sigma^2)^{-\frac{N}{2}} e^{(-\frac{1}{2\sigma^2} \sum_{i=1}^{N} (x_i - \mu)^2)}</script><p>对其求导可得对数似然函数为：</p><script type="math/tex; mode=display">Ln\, L =-\frac{N}{2} ln(2\pi)-\frac{N}{2} ln(\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{N}(x_i - \mu)^2</script><p>令：</p><script type="math/tex; mode=display">\left\{\begin{matrix}\frac{\partial }{\partial \mu }ln\, L = \frac{1}{\sigma^2} (\sum_{i=1}^{N} x_i -N\mu ) =0 & \\ \\\frac{\partial }{\partial \sigma^2 }ln\, L = - \frac{N}{2\sigma^2} + \frac{1}{ (2\sigma^2)^2} \sum_{i=1}^{N}(x_i-\mu)^2 =0& \end{matrix}\right.</script><p>由前一式解得$\tilde{\mu}=\frac{1}{N}\sum_{i=1}^{N}x_i = \bar{\mu}$，代入后一式得$\tilde{\sigma^2}=\frac{1}{N}\sum_{i=1}^{N}(x_i-\bar{x})^2$，因此得$\mu,\sigma^2$的最大似然估计为：</p><script type="math/tex; mode=display">\tilde{\mu} = \bar{X},\tilde{\sigma^2}=\frac{1}{N}(x_i - \bar{x})^2</script><h4 id="多项分布中的参数密度估计"><a href="#多项分布中的参数密度估计" class="headerlink" title="多项分布中的参数密度估计"></a>多项分布中的参数密度估计</h4><p>假设样本服从K个状态的多态分布，令onehot向量$x\in[0,1]^K$来表示第K个状态，即$x_k=1$，其余$x_{i,k \neq k}=0$，则样本x的概率密度函数为：</p><script type="math/tex; mode=display">p(x|\mu) = \prod_{k=1}^{K}\mu_k ^{x_K}</script><p>其中$\mu_k$为第k个状态的概率，并且满足$\sum_{k=1}^{K} \mu_k =1$。</p><p>数据集$D={\{x^n\}}_{n=1}^{N}$的对数似然函数为：</p><script type="math/tex; mode=display">log(D|\mu) = \sum_{n=1}^{N} \sum_{k=1}^{K} x_n ^k log (\mu _k)</script><p>多项分布的参数估计为约束优化问题，引入拉格朗日乘子$\lambda$，将原问题转化为无约束优化问题。</p><script type="math/tex; mode=display">\underset{\mu, \lambda}{ max} \sum_{n=1}^{N} \sum_{k=1}^{K} x_k ^n log(\mu_k) + \lambda (\sum_{k=1}^{K} \mu_k -1)</script><p>上式分别对$\mu_k,\lambda$求偏，并令其等于0，得到：</p><script type="math/tex; mode=display">\mu_k ^{ML} = \frac{m_k}{N}, 1 \leq N \leq K</script><p>其中$m_k = \sum_{n=1}^{N} x_k ^n$为数据集中取值为第k个状态的样本数量。</p><p>在实际应用中，参数密度估计一般存在两个问题：</p><ul><li>（1）模型选择问题，即如何选择数据分布的密度函数，实际的数据分布往往是非常复杂的，而不是简单的正态分布或者多项分布。</li><li>（2）不可观测变量问题，即我们用来训练数据的样本只包含部分的可观测变量，还有一些非常关键的变量是无法观测的，这导致我们很难估计数据的真实分布。</li><li>（3）维度灾难问题，即高维的参数估计十分困难。随着维度的增加，估计参数所需要的样本量呈指数增加。在样本不足时会出现过拟合。</li></ul><h4 id="非参数密度估计"><a href="#非参数密度估计" class="headerlink" title="非参数密度估计"></a>非参数密度估计</h4><p>非参数密度估计（Nonparametric Density Estimation）是不假设数据服从某种分布，通过将样本空间划分为不同的区域并估计每个区域的概率来近似数据的概率密度函数。</p><p>对于高纬空间中的一个随机向量x，假设其服从一个未知分布p(x)，则x落入空间中的小区域R的概率为：  $P=\int_{R} p(x)dx$。</p><p>给定N个训练样本$D=\{x^n\}_{n=1}^{N}$，落入区域R的样本数量K服从二项分布：</p><script type="math/tex; mode=display">P_K = \binom{N}{K}P^K(1-P)^{1-K}</script><p>其中$K/N$的期望为$E[K/N]=P$，方差为$var(K/N)=P(1-P)/N$。当N非常大时，我们可以近似认为：$P\approx \frac{K}{N}$，假设区域R足够小，其内部的概率密度是相同的，则有$P\approx p(x)V$，其中V为区域R的提及，结合前边的两个公式，可得：$p(x)\approx \frac{K}{NV}$。</p><p>根据上式，要准确的估计p(x)需要尽量使得样本数量N足够大，区域体积V尽可能的小。但在具体的应用中吗，样本数量一般有限，过小的区域导致落入该区域的样本比较少，这样估计的概率密度就不太准确。</p><p>因此在实践中估计非参数密度通常使用两种方法：</p><ul><li>（1）固定区域大小V，统计落入不同区域的数量，这种方式包括直方图和核方法两种</li><li>（2）改变区域大小，以使得落入每个区域的样本数量为K，这种方法成为K近邻方法</li></ul><h5 id="直方图方法"><a href="#直方图方法" class="headerlink" title="直方图方法"></a>直方图方法</h5><p>直方图（Histogram Method）是一种非常直观的估计连续变量密度函数的方法，可以表示为一种柱状图。</p><p>以一维随机变量为例，首先将其取值范围划分为M个连续的、不重叠的区间，每个区间的宽度为$\Delta m$，给定$N$个训练样本，我们统计这些样本落入每个区间的数量$K_m$，然后将他们归一化为密度函数。</p><script type="math/tex; mode=display">p_m = \frac {K_m}{N\Delta m},1 \leq m \leq  M</script><p>直方图的关键问题是如何选择一个合适的$\Delta m$，如果该值太小，那么落入每个区间的样本会特别少，其估计的区间密度也会有很大的随机性，如果该值过大，其估计的密度函数会变得十分平滑。下图给出了两个直方图的例子，其中蓝色表示真实的密度函数，红色表示直方图估计的密度函数。</p><p><img src="https://img-blog.csdnimg.cn/20191104090336556.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="直方图估计密度函数"></p><p>直方图通常用来处理低维随机变量，可以非常快速的对数据的分布进行可视化，但其<strong>缺点</strong>是很难扩展到高维变量，假设一个d维的随机变量，如果每一维都划分为M个空间，那么整个空间的区域数量为$M^d$，直方图估计的方法会随着空间的增大而指数增长，从而形成<strong>维度灾难（Curse Of Dimensionality）</strong></p><h5 id="核方法"><a href="#核方法" class="headerlink" title="核方法"></a>核方法</h5><p>核密度估计（Kernel Density Estimation），也叫Parzen窗方法，是一种直方图方法的改进。</p><p>假设$R$为$d$维空间中的一个以点x为中心的“超立方体”，并定义核函数</p><script type="math/tex; mode=display">\phi (\frac{z-x}{h}) = \left\{\begin{matrix}1 \,\,\,\,\,\, if \, |z_i - x_i|< \frac{h}{2},  1 \leq i \leq d & \\ 0 \,\,\,\,\,\, else & \end{matrix}\right.</script><p>来表示一个样本是否落入该超立方体中，其中$h$为超立方体的边长，也称为核函数的密宽度。</p><p>给定$N$个训练样本$D$，落入区域$R$的样本数量$K$为：</p><script type="math/tex; mode=display">K = \sum_{n=1}^{K} \phi (\frac {x^n - x}{h})</script><p>则点$x$的密度估计为：</p><script type="math/tex; mode=display">p(x) = \frac{K}{Nh^d} =\frac{1}{Nh^d} \sum_{n=1}^{K} \phi (\frac {x^n - x}{h})</script><p>其中$h^d$表示区域$R$的体积。</p><p>除了超立方体的核函数意外之外，我们还可以选择更加平滑的核函数，比如高斯核函数：</p><script type="math/tex; mode=display">\phi (\frac {z-x}{h}) = \frac {1}{ (2\pi)^{\frac{1}{2}} h} exp(- \frac{||z-x||^2}{2h^2})</script><p>其中$h^2$可以看做是高斯核函数的方差，这样点$x$的密度估计为：</p><script type="math/tex; mode=display">p (x) = \frac{1}{N} \sum_{n=1}^{N}   \frac {1}{ (2\pi)^{\frac{1}{2}} h} exp(- \frac{||z-x||^2}{2h^2})</script><h5 id="K近邻方法"><a href="#K近邻方法" class="headerlink" title="K近邻方法"></a>K近邻方法</h5><p>核密度估计方法中的核宽度是固定的，因此同一个宽度可能对高密度的区域过大，而对低密度的区域过小。一种更加灵活的方式是设置一种可变宽度的区域，并使得落入每个区域中的样本数量固定为K。</p><p>要估计点x的密度，首先找到一个以x为中心的球体，使得落入球体的样本数量为K，然后根据公式$p(x)\approx \frac{K}{NV}$就可以计算出点x的密度。因为落入球体的样本也是离x最近的K个样本，所以这种方法也称为K近邻（K-Nearest Neughbor）方法。</p><p>在K近邻方法中，K值的选择十分重要，如果K太小，无法有效的估计密度函数，而K太大也会使局部的密度不准确，并且会增加计算开销。</p><p>K近邻方法也经常用于分类问题，称为K近邻分类器。 当K=1时为最近邻分类器。</p><p>最近邻分类器的一个性质是，当 $N \rightarrow \infty$，其分类错误率不超过最优分类器错误率的两倍。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>无监督学习是一种十分重要的机器学习方法，无监督学习问题主要可以分为聚类，特征学习，密度估计等几种类型。但是无监督学习并没有像有监督学习那样取得广泛的成功，主要原因在于其缺少有效客观评价的方法，导致很难衡量一个无监督学习方法的好坏。</p><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;无监督学习概述&quot;&gt;&lt;a href=&quot;#无监督学习概述&quot; class=&quot;headerlink&quot; title=&quot;无监督学习概述&quot;&gt;&lt;/a&gt;无监督学习概述&lt;/h2&gt;&lt;p&gt;无监督学习（Unsupervised Learning）是指从无标签的数据中学习出一些有用的模式，无
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="无监督学习" scheme="http://thinkgamer.cn/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="密度估计" scheme="http://thinkgamer.cn/tags/%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>冷启动中的多避老虎机问题（Multi-Armed Bandit，MAB）</title>
    <link href="http://thinkgamer.cn/2019/10/15/RecSys/%E5%86%B7%E5%90%AF%E5%8A%A8%E4%B8%AD%E7%9A%84%E5%A4%9A%E9%81%BF%E8%80%81%E8%99%8E%E6%9C%BA%E9%97%AE%E9%A2%98%EF%BC%88Multi-Armed%20Bandit%EF%BC%8CMAB%EF%BC%89/"/>
    <id>http://thinkgamer.cn/2019/10/15/RecSys/冷启动中的多避老虎机问题（Multi-Armed Bandit，MAB）/</id>
    <published>2019-10-15T02:50:47.000Z</published>
    <updated>2019-10-18T08:56:37.262Z</updated>
    
    <content type="html"><![CDATA[<p>转载请注明出处：<a href="https://thinkgamer.blog.csdn.net/article/details/102560272" target="_blank" rel="external">https://thinkgamer.blog.csdn.net/article/details/102560272</a><br>博主微博：<a href="http://weibo.com/234654758" target="_blank" rel="external">http://weibo.com/234654758</a><br>Github：<a href="https://github.com/thinkgamer" target="_blank" rel="external">https://github.com/thinkgamer</a><br>公众号：搜索与推荐Wiki</p><hr><p>推荐系统中有两个很重要的问题：EE问题和冷启动。在实际的场景中很好的解决这两个问题又很难，比如冷启动，我们可以基于热门、用户、第三方等信息进行半个性化的推荐，但很难去获得用户的真实兴趣分布。那么有没有一种算法可以很好的解决这个问题呢？答案就是：Bandit。</p><h3 id="Bandit算法与推荐系统"><a href="#Bandit算法与推荐系统" class="headerlink" title="Bandit算法与推荐系统"></a>Bandit算法与推荐系统</h3><p>在推荐系统领域里，有两个比较经典的问题常被人提起，一个是EE问题，另一个是用户冷启动问题。</p><p>EE问题又叫Exploit-Explore。</p><ul><li>Exploit表示的是对于用户已经确定的兴趣当然要迎合。</li><li>Explore表示的如果仅对用户进行兴趣投放，很快就会看厌，所以要不断的探索用户的新兴趣</li></ul><p>所以在进行物品推荐时，不仅要投其所好，还要进行适当的长尾物品挖掘。</p><p>用户冷启动问题，也就是面对新用户时，如何能够通过若干次实验，猜出用户的大致兴趣。</p><p>这两个问题本质上都是如何选择用户感兴趣的主题进行推荐，比较符合Bandit算法背后的MAB问题。</p><p>比如，用Bandit算法解决冷启动的大致思路如下：用分类或者Topic来表示每个用户兴趣，也就是MAB问题中的臂（Arm），我们可以通过几次试验，来刻画出新用户心目中对每个Topic的感兴趣概率。这里，如果用户对某个Topic感兴趣（提供了显式反馈或隐式反馈），就表示我们得到了收益，如果推给了它不感兴趣的Topic，推荐系统就表示很遗憾（regret）了。如此经历“选择-观察-更新-选择”的循环，理论上是越来越逼近用户真正感兴趣的Topic的。</p><h3 id="Bandit算法来源"><a href="#Bandit算法来源" class="headerlink" title="Bandit算法来源"></a>Bandit算法来源</h3><p>Bandit算法来源于历史悠久的赌博学，它要解决的问题是这样的：</p><p>一个赌徒，要去摇老虎机，走进赌场一看，一排老虎机，外表一模一样，但是每个老虎机吐钱的概率可不一样，他不知道每个老虎机吐钱的概率分布是什么，那么每次该选择哪个老虎机可以做到最大化收益呢？这就是多臂赌博机问题（Multi-armed bandit problem, K-armed bandit problem, MAB）。</p><p>怎么解决这个问题呢？最好的办法是去试一试，不是盲目地试，而是有策略地快速试一试，这些策略就是Bandit算法。</p><p>这个多臂问题，推荐系统里很多问题都与它类似：</p><ul><li>假设一个用户对不同类别的内容感兴趣程度不同，那么我们的推荐系统初次见到这个用户时，怎么快速地知道他对每类内容的感兴趣程度？这就是推荐系统的冷启动。</li><li>假设我们有若干广告库存，怎么知道该给每个用户展示哪个广告，从而获得最大的点击收益？是每次都挑效果最好那个么？那么新广告如何才有出头之日？</li><li>我们的算法工程师又想出了新的模型，有没有比A/B test更快的方法知道它和旧模型相比谁更靠谱？</li><li>如果只是推荐已知的用户感兴趣的物品，如何才能科学地冒险给他推荐一些新鲜的物品？</li></ul><p>Bandit算法需要量化一个核心问题：错误的选择到底有多大的遗憾？能不能遗憾少一些？常见Bandit算法有哪些呢？往下看</p><h3 id="Thompson-sampling"><a href="#Thompson-sampling" class="headerlink" title="Thompson sampling"></a>Thompson sampling</h3><h4 id="1、Beta分布"><a href="#1、Beta分布" class="headerlink" title="1、Beta分布"></a>1、Beta分布</h4><p>Thompson Sampling是基于Beta分布进行的，所以首先看下什么是Beta分布？</p><p>Beta分布可以看作是一个概率的概率分布，当你不知道一个东西的具体概率是多少时，他可以给出所有概率出现的可能性。Beta是一个非固定的公式，其表示的是一组分布（这一点和距离计算中的闵可夫斯基距离类似）。</p><p>比如：</p><p>二项分布（抛n次硬币，正面出现k次的概率）</p><script type="math/tex; mode=display">P(S=k)=\binom{n}{k} p^k (1-p)^{n-k}</script><p>几何分布（抛硬币，第一次抛出正面所需的次数的概率）</p><script type="math/tex; mode=display">P(T=t)= (1-p)^{t-1} p</script><p>帕斯卡分布（抛硬币，第k次出现正面所需次数的概率）</p><script type="math/tex; mode=display">P(Y_k=t)=\binom{t-1}{k-1} p^{k-1} (1-p)^{t-k}p</script><p>去找一个统一的公式去描述这些分布，就是Beta分布：</p><script type="math/tex; mode=display">Beta(x| \alpha,\beta) = \frac{1}{B(\alpha, \beta)} x^{\alpha-1} (1-x)^\beta</script><p>其中 $B(\alpha, \beta)$是标准化函数，他的作用是使总概率和为1，$\alpha, \beta$为形状参数，不同的参数对应的图像形状不同，他不但可以表示常见的二项分布、几何分布等，还有一个好处就是，不需要去关系某次实验结果服从什么分布，而是利用<br>$\alpha, \beta$的值就可以计算出我们想要的统计量。</p><p>常见的参数对应的图形为：</p><p><img src="https://img-blog.csdnimg.cn/20191015085055652.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="Beta分布"></p><p>$Beta(\alpha, \beta)$的常见的统计量为：</p><ul><li>众数为：$\frac {\alpha-1}{\alpha + \beta -1}$</li><li>期望为：$\mu = E(x)= \frac {\alpha} {\alpha + \beta}$</li><li>方差为：$Var(x) = E(x - \mu)^2 = \frac { \alpha \beta } { (\alpha + \beta)^2 (\alpha + \beta +1) }$</li></ul><h4 id="2、Beta分布的例子"><a href="#2、Beta分布的例子" class="headerlink" title="2、Beta分布的例子"></a>2、Beta分布的例子</h4><p>网上资料中一个很常见的例子是棒球运动员的，这里进行借鉴。</p><p>棒球运动有一个指标是棒球击球率(batting average)，就是用一个运动员击中的球数除以击球的总数，我们一般认为0.266是正常水平的击球率，而如果击球率高达0.3就被认为是非常优秀的。</p><p>现在有一个棒球运动员，我们希望能够预测他在这一赛季中的棒球击球率是多少。你可能就会直接计算棒球击球率，用击中的数除以击球数，但是如果这个棒球运动员只打了一次，而且还命中了，那么他就击球率就是100%了，这显然是不合理的，因为根据棒球的历史信息，我们知道这个击球率应该是0.215到0.36之间才对啊。</p><p>对于这个问题，我们可以用一个二项分布表示（一系列成功或失败），一个最好的方法来表示这些经验（在统计中称为先验信息）就是用beta分布，这表示在我们没有看到这个运动员打球之前，我们就有了一个大概的范围。beta分布的定义域是(0,1)这就跟概率的范围是一样的。</p><p>接下来我们将这些先验信息转换为beta分布的参数，我们知道一个击球率应该是平均0.27左右，而他的范围是0.21到0.35，那么根据这个信息，我们可以取$\alpha$=81,$\beta$=219</p><p><img src="https://img-blog.csdnimg.cn/20191015090126646.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="棒球运动员Beta分布例子"></p><p>之所以取这两个参数是因为：</p><ul><li>beta分布的均值是：$\frac{81} {81 + 219}=0.27$</li><li>从图中可以看到这个分布主要落在了(0.2,0.35)间，这是从经验中得出的合理的范围。</li></ul><blockquote><p>在这个例子里，我们的x轴就表示各个击球率的取值，x对应的y值就是这个击球率所对应的概率。也就是说beta分布可以看作一个概率的概率分布。</p></blockquote><p>有了这样的初始值，随着运动的进行，其表达式可以表示为：</p><script type="math/tex; mode=display">Beta(\alpha_0 + hits , \beta_0 + misses)</script><p>其中 $\alpha_0, \beta_0$是一开始的参数，值为81，219。当击中一次球是 hits + 1，misses不变，当未击中时，hits不变，misses+1。这样就可以在每次击球后求其最近的平均水平了。</p><h4 id="3、Thompson-Smapling"><a href="#3、Thompson-Smapling" class="headerlink" title="3、Thompson Smapling"></a>3、Thompson Smapling</h4><p>Thompson sampling算法简单实用，简单介绍一下它的原理，要点如下：</p><ul><li>假设每个臂是否产生收益，其背后有一个概率分布，产生收益的概率为p。</li><li>我们不断地试验，去估计出一个置信度较高的“概率p的概率分布”就能近似解决这个问题了。</li><li>怎么能估计“概率p的概率分布”呢？ 答案是假设概率p的概率分布符合beta(wins, lose)分布，它有两个参数: wins, lose。</li><li>每个臂都维护一个beta分布的参数。每次试验后，选中一个臂，摇一下，有收益则该臂的wins增加1，否则该臂的lose增加1。</li><li>每次选择臂的方式是：计算每个臂现有的beta分布的平均水平，选择所有臂产生的随机数中最大的那个臂去摇。</li></ul><h4 id="4、TS的Python实现"><a href="#4、TS的Python实现" class="headerlink" title="4、TS的Python实现"></a>4、TS的Python实现</h4><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import numpy as <span class="built_in">np</span></span><br><span class="line">import <span class="built_in">random</span></span><br><span class="line"></span><br><span class="line">def ThompsonSampling(wins, trials):</span><br><span class="line">    pbeta = [<span class="number">0</span>] * N</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, len(trials)):</span><br><span class="line">        pbeta[i] = <span class="built_in">np</span>.<span class="built_in">random</span>.<span class="built_in">beta</span>(wins[i] + <span class="number">1</span>, trials[i] - wins[i] + <span class="number">1</span>)</span><br><span class="line">    choice = <span class="built_in">np</span>.argmax(pbeta)</span><br><span class="line">    trials[choice] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">random</span>.<span class="built_in">random</span>() &gt; <span class="number">0.5</span>:</span><br><span class="line">        wins[choice] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">T = <span class="number">10000</span>  # 实验次数</span><br><span class="line">N = <span class="number">10</span>  # 类别个数</span><br><span class="line"># 臂的选择总次数</span><br><span class="line">trials = <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">0</span>] * N )</span><br><span class="line"># 臂的收益</span><br><span class="line">wins = <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">0</span>] * N )</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, T):</span><br><span class="line">    ThompsonSampling(wins, trials)</span><br><span class="line"><span class="built_in">print</span>(trials)</span><br><span class="line"><span class="built_in">print</span>(wins)</span><br><span class="line"><span class="built_in">print</span>(wins/trials)</span><br></pre></td></tr></table></figure><h3 id="UCB"><a href="#UCB" class="headerlink" title="UCB"></a>UCB</h3><h4 id="1、UCB的原理"><a href="#1、UCB的原理" class="headerlink" title="1、UCB的原理"></a>1、UCB的原理</h4><p>UCB（Upper Confidence Bound，置信区间上界）可以理解为不确定性的程度，区间越宽，越不确定，反之就越确定，其表达式如下：</p><script type="math/tex; mode=display">score(i) = \frac {N_i}{T} + \sqrt{ \frac{2 ln T}{N_i}}</script><p>其中 Ni 表示第i个臂收益为 1 的次数，T表示选择的总次数</p><p>公式分为左右两部分，左侧（+左侧部分）表示的是候选臂i到目前为止的平均收益，反应的是它的效果。右侧（+右侧部分）叫做Bonus，本质上是均值的标准差，反应的是候选臂效果的不确定性，就是置信区间的上边界。</p><blockquote><p>统计学中的一些统计量表达的含义</p></blockquote><p>如果一个臂的收益很少，即Ni很小，那么他的不确定性就越大，在最后排序输出时就会有优势，bouns越大，候选臂的平均收益置信区间越宽，越不稳定，就需要更多的机会进行选择。反之如果平均收益很大，即+号左侧户数很大，在选择时也会有被选择的机会。</p><h4 id="2、UCB的Python实现"><a href="#2、UCB的Python实现" class="headerlink" title="2、UCB的Python实现"></a>2、UCB的Python实现</h4><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">import numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 T = 1000 个用户，即总共进行1000次实现</span></span><br><span class="line">T = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 定义 N = 10 个标签，即 N 个 物品</span></span><br><span class="line">N = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保证结果可复现，设置随机数种子</span></span><br><span class="line">np.<span class="built_in">random</span>.seed(<span class="number">888</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个物品的累积点击率（理论概率）</span></span><br><span class="line">true_rewards = np.<span class="built_in">random</span>.uniform(low=<span class="number">0</span>, high=<span class="number">1</span>, size= N)</span><br><span class="line"><span class="comment"># true_rewards = np.array([0.5] * N)</span></span><br><span class="line"><span class="comment"># 每个物品的当前点击率</span></span><br><span class="line">now_rewards = np.zeros(N)</span><br><span class="line"><span class="comment"># 每个物品的点击次数</span></span><br><span class="line">chosen_count = np.zeros(N)</span><br><span class="line"></span><br><span class="line">total_reward = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算ucb的置信区间宽度</span></span><br><span class="line">def calculate_delta(T, <span class="keyword">item</span>):</span><br><span class="line">    <span class="keyword">if</span> chosen_count[<span class="keyword">item</span>] == <span class="number">0</span>:</span><br><span class="line">        <span class="literal">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="literal">return</span> np.<span class="built_in">sqrt</span>( <span class="number">2</span> * np.<span class="built_in">log</span>( T ) / chosen_count[<span class="keyword">item</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算UCB</span></span><br><span class="line">def ucb(t, N):</span><br><span class="line">    <span class="comment"># ucb得分</span></span><br><span class="line">    upper_bound_probs = [ now_rewards[<span class="keyword">item</span>] + calculate_delta(t,<span class="keyword">item</span>) <span class="keyword">for</span> <span class="keyword">item</span> <span class="keyword">in</span> range(N) ]</span><br><span class="line">    <span class="keyword">item</span> = np.argmax(upper_bound_probs)</span><br><span class="line">    <span class="comment"># 模拟伯努利收益</span></span><br><span class="line">    <span class="comment"># reward = sum(np.random.binomial(n =1, p = true_rewards[item], size=20000)==1 ) / 20000</span></span><br><span class="line">    reward = np.<span class="built_in">random</span>.binomial(n =<span class="number">1</span>, p = true_rewards[<span class="keyword">item</span>])</span><br><span class="line">    <span class="literal">return</span> <span class="keyword">item</span>, reward</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">1</span>,T+<span class="number">1</span>):</span><br><span class="line">    <span class="comment"># 为第 t个用户推荐一个物品</span></span><br><span class="line">    <span class="keyword">item</span>, reward = ucb(t, N)</span><br><span class="line">    <span class="comment"># print("item is %s, reward is %s" % (item, reward))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一共有多少用户接受了推荐的物品</span></span><br><span class="line">    total_reward += reward</span><br><span class="line">    chosen_count[<span class="keyword">item</span>] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新物品的当前点击率</span></span><br><span class="line">    now_rewards[<span class="keyword">item</span>] =  ( now_rewards[<span class="keyword">item</span>] * (t<span class="number">-1</span>) + reward) /  t</span><br><span class="line">    <span class="comment"># print("更新后的物品点击率为：%s" % (now_rewards[item]))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出当前点击率 / 累积点击率</span></span><br><span class="line">    <span class="comment"># print("当前点击率为: %s" % now_rewards)</span></span><br><span class="line">    <span class="comment"># print("累积点击率为: %s" % true_rewards)</span></span><br><span class="line"></span><br><span class="line">    diff =  np.<span class="built_in">subtract</span>( true_rewards, now_rewards)</span><br><span class="line">    print(diff[<span class="number">0</span>])</span><br><span class="line">    print(total_reward)</span><br></pre></td></tr></table></figure><h4 id="3、UCB的推导"><a href="#3、UCB的推导" class="headerlink" title="3、UCB的推导"></a>3、UCB的推导</h4><p>观测 1：假设一个物品被推荐了k次，获取了k次反馈（点击 or 不点击），可以计算出物品被点击的平均概率</p><p>当k 接近于正无穷时，p’ 会接近于真实的物品被点击的概率</p><script type="math/tex; mode=display">p' = \frac {\sum reward_i}{k}</script><p>观测 2：现实中物品被点击的次数不可能达到无穷大，因此估计出的被点击的概率 p’ 和真实的点击的概率 p 总会存在一个差值 d，即：</p><script type="math/tex; mode=display">p'-d \leqslant p \leqslant p'+d</script><p>最后只需要解决差值 d 到底是怎么计算的？</p><p>首先介绍霍夫丁不等式（Chernoff-Hoeffding Bound），霍夫丁不等式假设reward_1, … , reward_n 是在[0,1]之间取值的独立同分布随机变量，用p’ 表示样本的均值，用p表示分布的均值，那么有：</p><script type="math/tex; mode=display">P\{|p'-p| \leqslant \delta \} \geqslant 1 - 2e^{-2n\delta ^2}</script><p>当 $\delta$ 取值为$\sqrt { 2In T /n}$ （其中 T 表示有物品被推荐的次数，n表示有物品被点击的次数），可以得到：</p><script type="math/tex; mode=display">P\{|p'-p| \leqslant \sqrt { \frac{2In T }{n}} \} \geqslant 1 - \frac{ 2 }{ T^4}</script><p>也就是说：</p><script type="math/tex; mode=display">p' - \sqrt { \frac{2In T }{n}} \leqslant p \leqslant p' + \sqrt { \frac{2In T }{n}}</script><p>是以 1 - 2/T^4 的概率成立的，<br>当T=2时，成立的概率为0.875<br>当T=3时，成立的概率为0.975<br>当T=4时，成立的概率为0.992<br>可以看出 $d =  \sqrt { \frac{2In T }{n}}$ 是一个不错的选择。</p><h3 id="Epsilon-Greedy"><a href="#Epsilon-Greedy" class="headerlink" title="Epsilon-Greedy"></a>Epsilon-Greedy</h3><h4 id="1、算法原理"><a href="#1、算法原理" class="headerlink" title="1、算法原理"></a>1、算法原理</h4><p>这是一个朴素的Bandit算法，有点类似模拟退火的思想：</p><ol><li>选一个（0,1）之间较小的数作为epsilon；</li><li>每次以概率epsilon做一件事：所有臂中随机选一个；</li><li>每次以概率1-epsilon 选择截止到当前，平均收益最大的那个臂。</li></ol><p>是不是简单粗暴？epsilon的值可以控制对Exploit和Explore的偏好程度。越接近0，越保守，只选择收益最大的。</p><h4 id="2、Python实现"><a href="#2、Python实现" class="headerlink" title="2、Python实现"></a>2、Python实现</h4><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EpsilonGreedy</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, epsilon, counts, values)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.epsilon = epsilon</span><br><span class="line">        <span class="keyword">self</span>.counts = counts</span><br><span class="line">        <span class="keyword">self</span>.values = values</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initialize</span><span class="params">(<span class="keyword">self</span>, n_arms)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.counts = [<span class="number">0</span> <span class="keyword">for</span> col <span class="keyword">in</span> range(n_arms)]</span><br><span class="line">        <span class="keyword">self</span>.values = [<span class="number">0</span>.<span class="number">0</span> <span class="keyword">for</span> col <span class="keyword">in</span> range(n_arms)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">select_arm</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &gt; <span class="keyword">self</span>.<span class="symbol">epsilon:</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">self</span>.values.index( max(<span class="keyword">self</span>.values) )</span><br><span class="line">        <span class="symbol">else:</span></span><br><span class="line">            <span class="comment"># 随机返回 self.values 中个的一个</span></span><br><span class="line">            <span class="keyword">return</span> random.randrange(len(<span class="keyword">self</span>.values))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reward</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> random.random() &gt; <span class="number">0</span>.<span class="number">5</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(<span class="keyword">self</span>, chosen_arm, reward)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.counts[chosen_arm] = <span class="keyword">self</span>.counts[chosen_arm] + <span class="number">1</span></span><br><span class="line">        n = <span class="keyword">self</span>.counts[chosen_arm]</span><br><span class="line"></span><br><span class="line">        value = <span class="keyword">self</span>.values[chosen_arm]</span><br><span class="line">        new_value = ((n - <span class="number">1</span>)  * value + reward ) / float(n)</span><br><span class="line">        <span class="keyword">self</span>.values[chosen_arm] = round(new_value,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">n_arms = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">algo = EpsilonGreedy(<span class="number">0</span>.<span class="number">1</span>, [], [])</span><br><span class="line"></span><br><span class="line">algo.initialize(n_arms)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">100</span>)<span class="symbol">:</span></span><br><span class="line">    chosen_arm = algo.select_arm()</span><br><span class="line">    reward = algo.reward()</span><br><span class="line">    algo.update(chosen_arm, reward)</span><br><span class="line"></span><br><span class="line">print(algo.counts)</span><br><span class="line">print(algo.values)</span><br></pre></td></tr></table></figure><h3 id="朴素Bandit算法"><a href="#朴素Bandit算法" class="headerlink" title="朴素Bandit算法"></a>朴素Bandit算法</h3><p>最朴素的Bandit算法就是：先随机试若干次，计算每个臂的平均收益，一直选均值最大那个臂。这个算法是人类在实际中最常采用的，不可否认，它还是比随机乱猜要好。</p><p>Python实现比较简单，这里就不做演示了。</p><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转载请注明出处：&lt;a href=&quot;https://thinkgamer.blog.csdn.net/article/details/102560272&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://thinkgamer.blog.csdn.
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="推荐算法" scheme="http://thinkgamer.cn/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="冷启动，Bandit" scheme="http://thinkgamer.cn/tags/%E5%86%B7%E5%90%AF%E5%8A%A8%EF%BC%8CBandit/"/>
    
  </entry>
  
  <entry>
    <title>神经网络中的网络优化和正则化（四）之正则化</title>
    <link href="http://thinkgamer.cn/2019/09/27/TensorFlow/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%88%E5%9B%9B%EF%BC%89%E4%B9%8B%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <id>http://thinkgamer.cn/2019/09/27/TensorFlow/神经网络中的网络优化和正则化（四）之正则化/</id>
    <published>2019-09-27T00:15:10.000Z</published>
    <updated>2019-10-14T12:28:36.844Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>神经网络中的网络优化和正则化问题介绍主要分为一，二，三，四篇进行介绍（如下所示），本篇为最后一篇主要介绍神经网络中的网络正则化。</p><ul><li>第一篇包括<ul><li>网络优化和正则化概述</li><li>优化算法介绍</li></ul></li><li>第二篇包括<ul><li>参数初始化 </li><li>数据预处理</li><li>逐层归一化</li></ul></li><li>第三篇包括<ul><li>超参数优化</li></ul></li><li>第四篇包括<ul><li>网络正则化</li></ul></li></ul><p>机器学习模型中的关键是泛化问题，即样本在真实数据集上的期望风险最小化，而在训练集上的经验风险最小化和期望风险并不一致。由于神经网络的拟合能力很强，其在训练集上的训练误差会降的很小，从而导致过拟合。</p><p><strong>正则化（Regularization）</strong>是一类通过限制模型复杂度，从而避免过拟合，提高模型泛化能力的一种方法，包括引入一些约束规则，增加先验，提前终止等。</p><p>在传统的机器学习模型中，提高模型泛化能力的主要方法是限制模型复杂度，比如$l_1,l_2$正则，但是在训练深层神经网络时，特别是在过度参数（OverParameterized）时，$l_1,l_2$正则化不如机器学习模型中效果明显，因此会引入其他的一些方法，比如：数据增强，提前终止，丢弃法，继承法等。</p><h3 id="l-1-l-2-正则"><a href="#l-1-l-2-正则" class="headerlink" title="$l_1,l_2$正则"></a>$l_1,l_2$正则</h3><p>$l_1,l_2$正则是机器学习中常用的正则化方法，通过约束参数的$l_1,l_2$范数来减少模型在训练数据上的过拟合现象。</p><p>通过引入$l_1,l_2$正则，优化问题变为：</p><script type="math/tex; mode=display">a\theta ^* = \underset{a}{ arg \,  min } \frac{1}{N} L ( y^n, f(x^n, \theta))+\lambda l_p(\theta)</script><p>$L$为损失函数，$N$为训练的样本数量，$f(.)$为待学习的神经网络，$\theta$为参数，$l_p$为$l_1,l_2$正则中的一个，$\lambda$为正则项系数。</p><p>带正则化的优化问题等价于下面带约束条件的优化问题：</p><script type="math/tex; mode=display">\theta ^* = \underset{a}{ arg \,  min } \frac{1}{N} L ( y^n, f(x^n, \theta))\\subject \, to \, l_p(\theta) \leq 1</script><p>下图给出了不同范数约束条件下的最优化问题示例：<br><img src="https://img-blog.csdnimg.cn/20190926205404238.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="不同范数约束条件下的最优化问题示例"></p><p>上图中红线表示$l_p$范数，黑线表示$f(\theta)$的等高线（简单起见，这里用直线表示）</p><p>从上图最左侧图可以看出，$l_1$范数的约束条件往往会使最优解位于坐标轴上，从而使用最终的参数为稀疏向量，此外$l_1$范数在零点不可导，常用下式来代替：</p><script type="math/tex; mode=display">l_1(\theta) = \sum_{i} \sqrt{\theta_i ^2 + \epsilon }</script><p>其中$\epsilon$为一个非常小的常数。</p><p>一种折中的方法是<strong>弹性网络正则化（Elastic Net Regularization）</strong> ，同时加入$l_1, l_2$正则，如下：</p><script type="math/tex; mode=display">a\theta ^* = \underset{a}{ arg \,  min } \frac{1}{N} L ( y^n, f(x^n, \theta)_+\lambda_1 l_1(\theta) + \lambda_2 l_2(\theta)</script><p>其中$\lambda_1, \lambda_2$分别是正则化项的参数。</p><h3 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h3><p><strong>权重衰减（Weight Deacy）</strong> 也是一种有效的正则化方法，在每次调参时，引入一个衰减系数，表示式为：</p><script type="math/tex; mode=display">\theta_t \leftarrow (1-w)\theta_{t-1} - \alpha g_t</script><p>其中$g_t$为第t次更新时的梯度，$\alpha$为学习率，$w$为权重衰减系数，一般取值比较小，比如0.0005。在标准的随机梯度下降中，权重衰减和$l_2$正则达到的效果相同，因此，权重衰减在一些深度学习框架中用$l_2$正则来代替。但是在较为复杂的优化方法中，两者并不等价。</p><h3 id="提前终止"><a href="#提前终止" class="headerlink" title="提前终止"></a>提前终止</h3><p><strong>提前终止（early stop）</strong> 对于深层神经网络而言是一种简单有效的正则化方法，由于深层神经网络拟合能力很强，比较容易在训练集上过拟合，因此在实际操作时往往产出一个和训练集独立的验证集，并用在验证集上的错误来代表期望错误，当验证集上的错误不再下降时，停止迭代。</p><p>然而在实际操作中，验证集上的错误率变化曲线并不是一条平衡的曲线，很可能是先升高再降低，因此提前停止的具体停止标准需要根据实际任务上进行优化。</p><h3 id="丢弃法"><a href="#丢弃法" class="headerlink" title="丢弃法"></a>丢弃法</h3><p>当训练一个深层神经网络时，可以随机丢弃一部分神经元（同时丢弃其对应的连接边）来避免过拟合，这种方法称为 <strong>丢弃法（Dropout Method）</strong>。每次丢弃的神经元为随机的，对于每一个神经元都以一个概率p来判断要不要停留，对于每一个神经层 $y=f(Wx + b)$，我们可以引入一个丢弃函数$d(.)$使得$y=f(Wd(x)+b)$。丢弃函数的定义为：</p><script type="math/tex; mode=display">d(x) = \left\{\begin{matrix}m \odot x, When \, Train\\ px, When \,  Test\end{matrix}\right.</script><p>其中$m \in \{0,1\}^d$是丢弃掩码（dropout mask），通过以概率为p的贝努力分布随机生成，$p$可以通过一个验证集选取一个最优值，也可以设置为0.5， 这样对大部分网络和任务比较有效。在训练时，神经元的平均数量为原来的$p$倍，而在测试时，所有的神经元都可以是激活的，这会造成训练时和测试时的网络结构不一致，为了缓解这个问题，在测试时，需要将每一个神经元的输出乘以$p$，也相当于把不同的神经网络做了一个平均。</p><p>下图给出了一个网络经过dropout的示例。<br><img src="https://img-blog.csdnimg.cn/20190926170817842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="丢弃法示例"></p><p>一般来讲，对于隐藏层的神经元，丢弃率$p=0.5$时最好，这样当训练时有一半的神经元是丢弃的，随机生成的网络结构具有多样性。对于输入层的神经元，其丢弃率往往设置为更接近于1的数，使得输入变化不会太大，对输入层的神经元进行丢弃时，相当于给数据增加噪声，提高网络的鲁棒性。</p><p>丢弃法一般是针对神经元进行随机丢弃，但是也可以扩展到神经元之间的连接进行随机丢弃，或每一层进行随机丢弃。</p><p>丢弃法有两种解释：</p><p>（1）集成学习的解释<br>每做一次丢弃，相当于从原始的网络中采样得到一个子网络，如果一个神经网络有n个神经元，那么可以采样出$2^n$个子网络，每次训练都相当于是训练一个不同的子网络，这些子网络都共享最开始的参数。那么最终的网络可以看成是集成了指数级个不同风格的组合模型。</p><p>（2）贝叶斯学习的解释</p><p>丢弃法也可以解释为一个贝叶斯学习的近似，用$y=f(x,\theta)$表示一个要学习的网络，贝叶斯学习是假设参数$\theta$为随机向量，并且先验分布为$q(\theta)$，贝叶斯方法的预测为：</p><script type="math/tex; mode=display">E_{q(\theta)}[y] = \int_{q}f(x,\theta)q(\theta)d\theta \approx \frac{1}{M}\sum_{m=1}^{M}f(x, \theta_m)</script><p>其中$f(x, \theta_m)$为第m次应用丢弃方法后的网络，其参数$\theta_m$为全部参数$\theta$的一次采样。</p><h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p>深层神经网络的训练需要大量的样本才能取得不错的效果，因为在数据量有限的情况下，可以通过 <strong>数据增强（Data Augmentation）</strong>来增加数据量，提高模型鲁棒性，避免过拟合。目前数据增强主要应用在图像数据上，在文本等其他类型的数据还没有太好的方法。</p><p>图像数据增强主要通过算法对图像进行转换，引入噪声方法增强数据的多样性，增强的方法主要有：</p><ul><li>转换（Rotation）：将图像按照顺时针或者逆时针方向随机旋转一定的角度；</li><li>翻转（Flip）：将图像沿水平或者垂直方向随机翻转一定的角度；</li><li>缩放（Zoom in/out）：将图像放大或者缩小一定的比例；</li><li>平移（Shift）：将图像按照水平或者垂直的方法平移一定步长；</li><li>加噪声（Noise）：加入随机噪声。</li></ul><h3 id="标签平滑"><a href="#标签平滑" class="headerlink" title="标签平滑"></a>标签平滑</h3><p>在数据增强中，可以通过给样本加入随机噪声来避免过拟合，同样也可以给样本的标签引入一定的噪声。假设在训练数据集中，有一些样本的标签是被错误标注的，那么最小化这些样本上的损失函数会导致过拟合。一种改善的正则化方法是<strong>标签平滑（label smothing）</strong>，即在输出标签中随机加入噪声，来避免模型过拟合。</p><p>一个样本$x$的标签一般用onehot向量表示，如下：</p><script type="math/tex; mode=display">y = [0,...,0,1,.....,1]^T</script><p>这种标签可以看作<strong>硬目标（hard targets）</strong>，如果使用softmax分类器并使用交叉熵损失函数，最小化损失函数会使得正确类和其他类权重差异很大。根据softmax函数的性质可以知道，如果要使得某一类的输出概率接近于1，其未归一化的得分要远大于其他类的得分，这样可能会导致其权重越来越大，并导致过拟合。i</p><p>此外如果标签是错误的，会导致严重的过拟合现象，为了改善这种情况，我们可以引入一个噪声会标签进行平滑，即假设样本以$\epsilon$的概率为其他类，平滑后的标签为：</p><script type="math/tex; mode=display">\tilde{y} =[ \frac{ \epsilon }{K-1} ,...,\frac{ \epsilon }{K-1} ,1- \epsilon,\frac{ \epsilon }{K-1},....,\frac{ \epsilon }{K-1}]^T</script><p>其中$K$为标签数量，这种标签可以看作是<strong>软目标（soft targets）</strong>。标签平滑可以避免模型的输出过拟合到硬目标上，并且通常不会降低其分类能力。</p><p>上边的标签平滑方法是给其他$K-1$个标签相同的概率$\frac{\epsilon}{K-1}$，没有考虑目标之间的相关性。一种更好的做法是按照类别相关性来赋予其他标签不同的概率，比如先训练另外一个更复杂的教师网络，并使用大网络的输出作为软目标进行训练学生网络，这种方法也称为知识精炼（Knowledge Distillation）。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>至此，神经网络中的网络优化和正则化（一）（二）（三）（四）篇已经完成，如下：</p><ul><li><a href="https://thinkgamer.blog.csdn.net/article/details/100996744" target="_blank" rel="external">神经网络中的网络优化和正则化（一）之学习率衰减和动态梯度方向</a></li><li><a href="https://thinkgamer.blog.csdn.net/article/details/101026786" target="_blank" rel="external">神经网络中的网络优化和正则化（二）之参数初始化/数据预处理/逐层归一化</a></li><li><a href="https://thinkgamer.blog.csdn.net/article/details/101033047" target="_blank" rel="external">神经网络中的网络优化和正则化（三）之超参数优化</a></li><li><a href="">神经网络中的网络优化和正则化（四）之正则化</a></li></ul><p>神经网络中的网络优化和正则化即是对立又统一的关系，一方面我们希望找到一个最优解使得模型误差最小，另一方面又不希望得到一个最优解，可能陷入过拟合。优化和正则化的目标是期望风险最小化。</p><p>目前在深层神经网络中泛化能力还没有很好的理论支持，在传统的机器学习上比较有效的$l_1,l_2$正则化在深层神经网络中作用也比较有限，而一些经验性的做法，比如随机梯度下降和提前终止，会更加有效。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;神经网络中的网络优化和正则化问题介绍主要分为一，二，三，四篇进行介绍（如下所示），本篇为最后一篇主要介绍神经网络中的网络正则化。&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="神经网络" scheme="http://thinkgamer.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>神经网络中的网络优化和正则化（三）之超参数优化</title>
    <link href="http://thinkgamer.cn/2019/09/25/TensorFlow/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%88%E4%B8%89%EF%BC%89%E4%B9%8B%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
    <id>http://thinkgamer.cn/2019/09/25/TensorFlow/神经网络中的网络优化和正则化（三）之超参数优化/</id>
    <published>2019-09-25T12:53:25.000Z</published>
    <updated>2019-10-14T12:28:36.842Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>公众号标题：神经网络中的优化方法之学习率衰减和动态梯度方向</p></blockquote><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>神经网络中的网络优化和正则化问题介绍主要分为一，二，三，四篇进行介绍。</p><ul><li>第一篇包括<ul><li>网络优化和正则化概述</li><li>优化算法介绍</li></ul></li><li>第二篇包括<ul><li>参数初始化</li><li>数据预处理</li><li>逐层归一化</li></ul></li><li>第三篇包括<ul><li>超参数优化</li></ul></li><li>第四篇包括<ul><li>网络正则化 </li></ul></li></ul><hr><p>无论是神经网络还是机器学习都会存在很多的超参数，在神经网络中，常见的超参数有：</p><ul><li>网络结构：包括神经元之间的连接关系，层数，每层的神经元数量，激活函数的类型等</li><li>优化参数：包括优化方法，学习率，小批量样本数量</li><li>正则化系数</li></ul><p><strong>超参数优化（Hyperparamter Optimization）</strong> 主要存在两方面的困难：</p><ul><li>超参数优化是一个组合优化问题，无法像一般参数那样通过梯度优化的方法来求解，也没有一种通用的优化方法</li><li>评估一组超参数配置时间代价很高，从而导致一些优化算法（比如时间演化算法）在超参数优化中难以应用</li></ul><p>对于超参数的设置，一般有三种比较简单的优化方法，人工搜索，网格搜素，随机搜索</p><hr><h3 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h3><p>网格搜索（grid search）是一种通过尝试所有超参数的组合来寻找一组合适的超参数组合的方法。如果参数是连续，可以将其离散化。比如“学习率”，我们可以根据经验选取几个值:$\alpha \in {0.01, 0.1, 0.5, 1.0}$。</p><p>一般而言，对于连续的超参数，不能采用等间隔的方式进行划分，需要根据超参数自身的特点进行离散化。</p><p>网格搜索根据不同的参数组合在测试集上的表现，选择一组最优的参数作为结果。</p><h3 id="随机搜索"><a href="#随机搜索" class="headerlink" title="随机搜索"></a>随机搜索</h3><p>不同超参数对模型的影响不同，有的超参数（比如正则项系数）对模型的影响有限，有的超参数（比如学习率）对模型的影响比较大，这时候采用网格搜索就会在影响不大的超参数上浪费时间。</p><p>一种在实践中比较有效的方法是对超参数进行随机组合（比如不太重要的参数进行随机抽取，重要的参数可以按照网格搜索的方式选择），选择表现最好的参数作为结果,这就是<strong>随机搜索（random search）</strong></p><blockquote><p>网格搜索和随机搜索没有利用超参数之间的相关性，即如果模型的超参数组合比较类似，其模型的性能表现也是比较接近的，这时候网格搜索和随机搜索就比较低效。下面介绍两种自适应的超参数优化方法：贝叶斯优化和动态资源分配。</p></blockquote><hr><h3 id="动态资源分配"><a href="#动态资源分配" class="headerlink" title="动态资源分配"></a>动态资源分配</h3><p>在超参数优化中，每组超参数配置的评估代价很高，如果我们可以在较早的阶段就估计出该组超参数效果就比较差，然后提前终止该组参数的测试，从而将更多的资源留给其他。这个问题可以归结为<strong>多臂赌博机问题</strong>的一个泛化问题，即<strong>最优臂问题（best-arm problem）</strong>，即在给定有限次数的情况下，如何获取最大收益。</p><p>动态资源分配的一种有效方法是<strong>逐层减半（successive halving）</strong>，将超参数优化看作是一种非随机的最优臂问题。该方法出自2015年的一篇论文，论文下载地址为：<a href="https://arxiv.org/pdf/1502.07943.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1502.07943.pdf</a></p><p>假设要尝试N组超参数配置，总共可利用的摇臂资源次数为B，我们可以通过$T= [log_2N]-1$轮逐次减半的方法来选取最优的配置，具体计算过程如下：</p><p><img src="https://img-blog.csdnimg.cn/20190919191933874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="逐次减半"></p><blockquote><p>在逐次减半方法中，N的设置十分重要，如果N越大，得到最佳配置的机会也越大，但每组配置分配到的资源就越少，这样早期的评估结果可能不准确，反之，如果N越小，每组超参数配置的评估就会越准确，但也有可能无法得到最优的参数配置。因此如何设置N是评估“利用-探索”的一个关键因素，一种改进的方法是：HyperBrand方法，通过尝试不同的N来寻找最优的参数配置。对应的论文下载地址为：<a href="https://openreview.net/pdf?id=ry18Ww5ee" target="_blank" rel="external">https://openreview.net/pdf?id=ry18Ww5ee</a></p></blockquote><hr><h3 id="贝叶斯优化"><a href="#贝叶斯优化" class="headerlink" title="贝叶斯优化"></a>贝叶斯优化</h3><h4 id="贝叶斯优化背后的思想"><a href="#贝叶斯优化背后的思想" class="headerlink" title="贝叶斯优化背后的思想"></a>贝叶斯优化背后的思想</h4><p>贝叶斯优化（Bayesian optimization）是一种自适应的超参数优化方法，根据当前已经试验的超参数组合，来预测下一个可能带来最大收益的组合。</p><blockquote><p>对于同一个算法来讲，不同的超参数组合其实是对应不同的模型，而贝叶斯优化可以帮助我们在众多模型中寻找性能最优的模型，虽然我们可以使用交叉验证的思想寻找更好的超参数组合，但是不知道需要多少样本才能从一系列候选模型中选择出最优的模型。这就是为什么贝叶斯优化能够减少计算任务加速优化过程的进程，同样贝叶斯优化不依赖于人为猜测需要样本量的多少，这种优化计算是基于随机性和概率分布得到的。<br><br><br>简单来说，当我们把第一条样本送到模型中的时候，模型会根据当前的样本点构建一条直接，当把第二天样本送到模型中的时候，模型将结合这两个点并从前面的线出发绘制一条修正的线，当输送第三个样本的时候，模型绘制的就是一条非线性曲线，当样本数据增加时，模型所结合的曲线就会变得更多，这就像统计学里的抽样定理，即我们从样本参数出发估计总体参数，且希望构建出的估计量与总体参数相合，无偏估计。<br><br><br>下图为非线性目标函数曲线图，对于给定的目标函数，在输送了所有的观察样本之后，它将搜寻到最大值，即寻找令目标函数最大的参数（arg max）。<br><img src="https://img-blog.csdnimg.cn/20190920122716823.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="非线性目标函数曲线图"><br>我们的目标并不是使用尽可能多的样本去完全推断未知的目标函数，而是希望能求得使目标函数最大化的参数，所以我们将注意力从曲线上移开，当目标函数组合能提升曲线形成分布时，其就可以称为采集函数（Acquisition funtion），这就是<strong>贝叶斯优化背后的思想</strong>。（灰色区域部分参考：<a href="https://www.jiqizhixin.com/articles/2017-08-18-5）" target="_blank" rel="external">https://www.jiqizhixin.com/articles/2017-08-18-5）</a></p></blockquote><h4 id="时序模型优化"><a href="#时序模型优化" class="headerlink" title="时序模型优化"></a>时序模型优化</h4><p>一种常用的贝叶斯优化方法为时序模型优化（Sequential Model-Based Optimization，SMBD），假设超参数优化的函数f(x)服从高斯过程，则$p(f(x)|x)$为一个正态分布。贝叶斯优化过程是根据已有的N组实验结果$H={x_n,y_n}, n\in(1,N)$（$y_n$为$f(x_n)$的观测值）来建模高斯过程，并计算$f(x)$的后验分布$p(f(x)|x,H)$。</p><p>为了使得$p(f(x)|x,H)$接近其真实分布，就需要对样本空间进行足够多的采样，但是超参数优化中每一个样本的生成成本都很高，需要使用尽可能少的样本来使得$p_\theta(f(x)|x,H)$接近于真实分布。因此需要定义一个收益函数（Acquisition funtion）$\alpha (x, H)$来判断一个样本能否给建模$p_\theta(f(x)|x,H)$提供更多的收益。收益越大，其修正的高斯过程会越接近目标函数的真实分布。</p><p>收益函数的定义有很多方式，一个常用的是期望改善（Expected Improvement，EI）。假设$y^* = min \left \{  y_n, 1 \leq n \leq N \right \}$是当前已有样本中的最优值，期望改善函数为：</p><script type="math/tex; mode=display">EI(x, H) = \int_{-\infty }^{ +\infty } max (y^* - y, 0) p(y|x, H) dy</script><p>期望改善是定义一个样本$x$在当前模型$p(f(x)|x,H)$下，$f(x)$超过最好结果$y^*$的期望。除了期望改善函数之外，收益函数还有其他函数的定义，比如改善概率（Probability Of Improvement），高斯过程置信上界（GP Up Confidence Bound，GP-UCB）等。</p><p>时序模型优化过程如下所示：<br><img src="https://img-blog.csdnimg.cn/20190920150457198.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="时序模型优化过程"></p><p>贝叶斯优化的缺点是高斯建模过程需要计算矩阵的逆，时间复杂度为$O(n^3)$，因此不能很好的处理高维过程，深层神经网络的参数一般比较多，需要更加高效的高斯过程建模，也有一些方法将时间复杂度从$O(n^3)$降到了$O(n)$。</p><blockquote><p>至此，超参数优化部分已经介绍完成，这里并没有对超参数优化进行实现，有很多Python库已经对其进行了封装，感兴趣的可以关注下，另外贝叶斯优化在日常实践中用的比较多但是不太好理解，可以多看几遍，对比一些文章什么看下理解下。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;公众号标题：神经网络中的优化方法之学习率衰减和动态梯度方向&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;神经网络中的
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="神经网络" scheme="http://thinkgamer.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>神经网络中的网络优化和正则化（二）之参数初始化/数据预处理/逐层归一化</title>
    <link href="http://thinkgamer.cn/2019/09/22/TensorFlow/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%88%E4%BA%8C%EF%BC%89%E4%B9%8B%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96:%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86:%E9%80%90%E5%B1%82%E5%BD%92%E4%B8%80%E5%8C%96/"/>
    <id>http://thinkgamer.cn/2019/09/22/TensorFlow/神经网络中的网络优化和正则化（二）之参数初始化:数据预处理:逐层归一化/</id>
    <published>2019-09-22T13:32:55.000Z</published>
    <updated>2019-10-14T12:28:36.843Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>神经网络中的网络优化和正则化问题介绍主要分为一，二，三，四篇进行介绍。</p><ul><li>第一篇包括<ul><li>网络优化和正则化概述</li><li>优化算法介绍</li></ul></li><li>第二篇包括<ul><li>参数初始化</li><li>数据预处理</li><li>逐层归一化</li></ul></li><li>第三篇包括<ul><li>超参数优化</li></ul></li><li>第四篇包括<ul><li>网络正则化 </li></ul></li></ul><h3 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h3><h4 id="对称权重现象"><a href="#对称权重现象" class="headerlink" title="对称权重现象"></a>对称权重现象</h4><p>在上一篇文章中我们提到神经网络中的参数学习是基于梯度下降的，而梯度下降需要赋予一个初始的参数，所以这个参数的初始化就显得特别重要。</p><p>在感知器和逻辑回归中，一般将参数初始化为0，但是在神经网络中如果把参数初始化为0，就会导致在第一次前向计算时，所有隐藏层神经元的激活值都相同，这样会导致深层神经元没有区分性，这种现象称为<strong>对称权重现象</strong></p><p>因此如果要高质量的训练一个网络，给参数选择一个合适的初始化区间是非常重要的，一般而言，参数初始化的区间应该根据神经元的性质进行差异化的设置，如果一个神经元的输入过多，权重就不要设置太大，以避免神经元的的输出过大（当激活函数为ReLU时）或者过饱和（激活函数为Sigmoid函数时）。<br>关于神经网络中的激活函数介绍可参考：</p><blockquote><p><a href="https://blog.csdn.net/Gamer_gyt/article/details/89440152" target="_blank" rel="external">https://blog.csdn.net/Gamer_gyt/article/details/89440152</a></p></blockquote><p>常见的参数初始化方法包括以下两种。</p><h4 id="Gaussian初始化"><a href="#Gaussian初始化" class="headerlink" title="Gaussian初始化"></a>Gaussian初始化</h4><p>高斯初始化是最简单的初始化方法，参数服从一个固定均值和固定方差的高斯分布进行随机初始化。</p><p>初始化一个深度网络时，一个比较好的初始化方案是保持每个神经元输入的方差是一个常量，当一个神经元的输入连接数量为n时，可以考虑其输入连接权重以$N(0,\sqrt{\frac{1}{n}})$的高斯分布进行初始化，如果同时考虑神经元的输出连接数量为m时，可以按照$N(0,\sqrt{\frac{2}{m+n}})$进行高斯分布初始化。</p><h4 id="均匀分布初始化"><a href="#均匀分布初始化" class="headerlink" title="均匀分布初始化"></a>均匀分布初始化</h4><blockquote><p>均匀初始化是指在一个给定的区间[-r,r]内采用均匀分布来初始化参数，超参数r的设置也可以根据神经元的连接数量来进行自适应调整。</p></blockquote><p><strong>Xavier初始化方法</strong>是一种自动计算超参数r的方法，参数可以在[-r,r]之间采用均匀分布进行初始化。</p><p>如果神经元激活函数为logistic函数，对于第l-1层到第l层的权重参数区间可以设置为：</p><script type="math/tex; mode=display">r = \sqrt{ \frac{6}{ n^{l-1} + n^l}}</script><p>$n^l$ 表示第l层神经元的个数，$n^{l-1}$表示l-1层神经元的个数。</p><p>如果是tanh激活函数，权重参数区间可以设置为：</p><script type="math/tex; mode=display">r =4 \sqrt{ \frac{6}{ n^{l-1} + n^l}}</script><blockquote><p>在实际经验中，Xavier初始化方法用的比较多。</p></blockquote><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><h4 id="为什么要进行数据预处理"><a href="#为什么要进行数据预处理" class="headerlink" title="为什么要进行数据预处理"></a>为什么要进行数据预处理</h4><p>一般情况下，在原始数据中，数据的维度往往不一致，比如在电商数据中，某个商品点击的次数往往要远大于购买的次数，即<strong>特征的分布范围差距很大</strong>，这样在一些使用余弦相似度计算的算法中，较大的特征值就会起到绝对作用，显然这样做是极其不合理的。同样在深度神经网络中，虽然可以通过参数的调整来自适应不同范围的输入，但是这样训练的效率也是很低的。</p><p>假设一个只有一层的网络 $y=tanh(w_1x_1 + w_2 x_2 +b)$，其中$x_1 \in [0,10], x_2 \in [0,1]$。因为激活函数 tanh的导数在[-2,2]之间是敏感的，其余的值域导数接近0，因此$w_1x_1 + w_2 x_2 +b$过大或者过小都会影响训练，为了提高训练效率，我们需要把$w_1x_1 + w_2 x_2 +b$限定在[-2,2]之间，因为$x_1,x_2$的取值范围，需要把$w_1$设置的小一些，比如在[-0.1, 0.1]之间，可以想象，如果数据维度比较多的话，我们需要精心的去设置每一个参数，<strong>但是如果把特征限定在一个范围内，比如[0,1]</strong>，我们就不需要太区别对待每一个参数。</p><p>除了参数初始化之外，不同特征取值范围差异比较大时也会影响梯度下降法的搜索效率，下图（图1-1）给出了数据归一化对梯度的影响，对比等高线图可以看出，归一化后，梯度的位置方向更加接近于最优梯度的方向。</p><p><img src="https://img-blog.csdnimg.cn/20190919111801183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="数据归一化对梯度的影响"></p><h4 id="数据预处理的方法"><a href="#数据预处理的方法" class="headerlink" title="数据预处理的方法"></a>数据预处理的方法</h4><p>关于原始数据归一化的方法有很多，可以参考《推荐系统开发实战》中第四章节部分内容，写的很全面，而且有对应的代码实现。该书的购买链接：</p><blockquote><p><a href="https://item.jd.com/12671716.html" target="_blank" rel="external">点击查看详情-京东链接</a></p></blockquote><h3 id="逐层归一化"><a href="#逐层归一化" class="headerlink" title="逐层归一化"></a>逐层归一化</h3><h4 id="深层神经网络中为什么要做逐层归一化"><a href="#深层神经网络中为什么要做逐层归一化" class="headerlink" title="深层神经网络中为什么要做逐层归一化"></a>深层神经网络中为什么要做逐层归一化</h4><p>在深层神经网络中，当前层的输入是上一层的输出，因此之前层参数的变化对后续层的影响比较大，就像一栋高楼，低层很小的变化就会影响到高层。</p><p>从机器学习的角度去看，如果某个神经网络层的输入参数发生了变化，那么其参数需要重新学习，这种现象叫做<strong>内部协变量偏移（Internal Covariate Shift）</strong>。</p><blockquote><p>这里补充下机器学习中的协变量偏移（Covariate Shift）。协变量是一个统计学的概念，是影响预测结果的统计变量。在机器学习中，协变量可以看作是输入，一般的机器学习都要求输入在训练集和测试集上的分布是相似的，如果不满足这个假设，在训练集上得到的模型在测试集上表现就会比较差。<br><img src="https://img-blog.csdnimg.cn/20190919130030578.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="协变量偏移"></p></blockquote><p>为了解决内部协变量偏移问题，需要对神经网络层的每一层输入做归一化，下面介绍几种常见的方法：</p><ul><li>批量归一化</li><li>层归一化</li><li>其他方法</li></ul><h4 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h4><p>为了减少内部协变量偏移的影响，需要对神经网络每一层的净输入$z^l$进行归一化，相当于每一层都要做一次数据预处理，从而加快收敛速度，但是因为对每一层都进行操作，所以要求归一化的效率要很高，一般使用标准归一化，将净输入$z^l$的每一维都归一到标准正态分布，其公式如下：</p><script type="math/tex; mode=display">\hat{z}^l = \frac{ z^l - E[z^l] }{ \sqrt{var(z^l) + \epsilon } }</script><p>$E[z^l]，var(z^l)$表示在当前参数下$z^l$的每一维在整个训练集上的期望和方差，因为深度神经网络采用的是下批量的梯度下降优化方法，基于全部样本计算期望和方差是不可能的，因为通常采用小批量进行估计。给定一个包含K个样本的集合，第$l$层神经元的净输入$z^{(1,l)},….z^{(K,l)}$的均值和方差为：</p><script type="math/tex; mode=display">\mu _\beta = \frac{1 }{ K } \sum_{k=1}^{K } z^{(k,l)}\\\sigma^2 _\beta = \frac{1 }{ K }\sum_{ k=1}^{K} (z^{(k,l)} - \mu _\beta)^2</script><p>对净输入$z^l$的标准归一化会使其取值集中在0附近，这样当使用sigmoid激活函数时，这个取值空间刚好接近线性变换的空间，减弱了神经网络的非线性性质。因此为了不使归一化对网络产生影响，需要对其进行缩放和平移处理，公式如下：</p><script type="math/tex; mode=display">\hat{z}^l = \frac{ z^l - \mu _\beta }{ \sqrt{\sigma^2 _\beta+ \epsilon } } \odot \gamma  + \beta</script><p>其中$\gamma  , \beta$分别代表缩放和平移的向量。</p><blockquote><p>这里需要注意的是每次小批量样本的均值和方差是净输入$z^l$的函数，而不是常量因此在计算梯度时要考虑到均值和方差产生的影响，当训练完成时，用整个数据集上的均值和方差来代替每次小样本计算得到的均值和方差。在实际实践经验中，小批量样本的均值和方差也可以使用移动平均来计算。</p></blockquote><h4 id="层归一化"><a href="#层归一化" class="headerlink" title="层归一化"></a>层归一化</h4><p>批量归一化的操作对象是单一神经元，因此要求选择样本批量的时候，不能太小，否则难以计算单个神经元的统计信息，另外一个神经元的输入是动态变化的，比如循环神经网络，那么就无法应用批量归一化操作。</p><p><strong>层归一化（Layer Normalization）</strong> 是和批量归一化非常类似的方法，但层归一化的操作对象是某层全部神经元。</p><p>对于深层神经网络，第$l$层神经元的净输入为$z^l$，其均值和方差为：</p><script type="math/tex; mode=display">u^l = \frac{1}{n^l} \sum_{i=1}^{ n^l} z_i^l\\\sigma ^2_l = \frac{1}{n^l} \sum_{i=1}^{ n^l} (z_i^l - u^l )</script><p>其中$n^l$为第$l$层神经元的数量。则层归一化定义为：</p><script type="math/tex; mode=display">\hat{z^l} = \frac{z^l - u^l }{ \sqrt {\sigma^2 _l + \epsilon } } \odot \gamma  + \beta</script><p>其中$\gamma ,\beta$分别代表缩放和平移的向量，和$z^l$的维度相同。</p><p><strong>循环神经网络中的层归一化</strong>为：</p><script type="math/tex; mode=display">z_t = U h_{t-1} + W x_t\\h_t = f(\hat{z^l})</script><p>其中隐藏层为$h_t$，$x_t$为第$t$时刻的净输入，$U,W$为参数。</p><blockquote><p>在标准循环网络中，循环神经层的输入一般就随着时间慢慢变大或者变小，从而引起梯度爆炸或者梯度消失，而层归一化的神经网络可以有效的缓解这种状况。</p></blockquote><h4 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h4><p>除了上面介绍的两种归一化方法之外，还有一些其他的一些归一化方法，感兴趣的可以自行搜索查看。</p><ul><li>权重归一化(Weight Normalization)</li><li>局部响应归一化</li></ul><blockquote><p>至此，神经网络中的优化方法第二部分介绍完成，主要包好了三部分内容：参数初始化，数据预处理和逐层归一化。再下一篇将会重点介绍超参数优化的方法不仅适用于深度神经网络，也适用于一般的机器学习任务。如果你觉得不错，分享一下吧！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;神经网络中的网络优化和正则化问题介绍主要分为一，二，三，四篇进行介绍。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一篇包括&lt;ul&gt;
&lt;li&gt;网络优化和正则
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="神经网络" scheme="http://thinkgamer.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>神经网络中的网络优化和正则化（一）之学习率衰减和动态梯度方向</title>
    <link href="http://thinkgamer.cn/2019/09/22/TensorFlow/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8B%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F%E5%92%8C%E5%8A%A8%E6%80%81%E6%A2%AF%E5%BA%A6%E6%96%B9%E5%90%91/"/>
    <id>http://thinkgamer.cn/2019/09/22/TensorFlow/神经网络中的网络优化和正则化（一）之学习率衰减和动态梯度方向/</id>
    <published>2019-09-22T13:25:01.000Z</published>
    <updated>2019-10-14T12:28:36.841Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>神经网络中的网络优化和正则化问题介绍主要分为一，二，三，四篇进行介绍。</p><ul><li>第一篇包括<ul><li>网络优化和正则化概述</li><li>优化算法介绍</li></ul></li><li>第二篇包括<ul><li>参数初始化</li><li>数据预处理</li><li>逐层归一化</li></ul></li><li>第三篇包括<ul><li>超参数优化</li></ul></li><li>第四篇包括<ul><li>网络正则化 </li></ul></li></ul><hr><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>虽然神经网络有比较强的表达能力，但是应用神经网络到机器学习任务时仍存在一些问题，主要分为：</p><ol><li>网络优化<blockquote><p>神经网络模型是一个非凸函数，再加上神经网络中的梯度消失和梯度爆炸，很难进行优化，另外网络的参数比较多，且数据量比较大导致训练效率比较低。</p></blockquote></li><li>正则化<blockquote><p>神经网络拟合能力强，容易在训练集上产生过拟合，需要一些正则化的方法来提高网络的泛化能力。</p></blockquote></li></ol><p>从大量的实践经验看主要是从网络优化和正则化两个方面提高学习效率并得到一个好的网络模型。</p><p>在低维空间的非凸优化问题中主要是存在一些局部最优点，基于梯度下降优化算法会陷入局部最优点，因此低维空间的非凸优化的难点在于如何选择合适的参数和逃离局部最优点。</p><p>深层神经网络中参数较多，其是在高维空间的非凸优化问题中，和低维空间的非凸优化有些不同，其主要难点在于如何逃离鞍点（Saddle Point），鞍点的梯度为0，但是在一些维度上是最高点，在另一些维度上是最低点，如下图所示（图1-1）：<br><img src="https://img-blog.csdnimg.cn/2019091814412421.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="鞍点示例"></p><p>在高维空间中，局部最优点要求在每一维度上都是最低点，这种概率很低，假设网络有1000<br>个参数，每一维上取得局部最优点的最小概率为p，则在整个参数空间中取得局部最优点的最小概率为$p^{1000}$，这种概率很小，也就是说在整个参数空间中，大部分梯度为0的点都是鞍点。</p><hr><h3 id="优化算法介绍"><a href="#优化算法介绍" class="headerlink" title="优化算法介绍"></a>优化算法介绍</h3><p>深层神经网络的参数学习主要是通过梯度下降算法寻找一组最小结构的风险参数，梯度下降分为：</p><ul><li>批量梯度下降</li><li>随机梯度下降</li><li>小批量梯度下降</li></ul><p>根据不同的数据量和参数量，可以选择一种合适的梯度下降优化算法，除了在收敛效果和效率上的区别，这三种梯度下降优化算法还存在一些共同问题（<strong>具体会在下一篇进行详细介绍</strong>）：</p><ul><li>如何初始化参数</li><li>预处理数据</li><li>如何选择合适的学习率，避免陷入局部最优</li></ul><p>在训练深层神经网络时，通常采用小批量梯度下降算法。令$f(x,\theta)$为一个深层神经网络，$\theta$为网络参数，使用小批量梯度优化算法时，每次选择K个训练样本$I_t =\left \{ (x^t,y^t)  \right \} , t \in (1,T)$，第t次迭代时损失函数关于$\theta$的偏导数为（公式1-1）：</p><script type="math/tex; mode=display">g_t(\theta ) = \frac{ 1 }{ K } \sum_{ (x^t,y^t) \in I_t} \frac{ \partial L(y^t,f(x^t, \theta)) }{ \partial \theta }</script><p>第t次更新的梯度$g’_t$定义为（公式1-2）：</p><script type="math/tex; mode=display">g_t'(\theta)= g_t(\theta_{t-1})</script><p>使用梯度下降来更新参数（公式1-3）：</p><script type="math/tex; mode=display">\theta_t = \theta_{t-1} - \alpha g'(\theta)</script><p>一般批量较小时，需要选择较小的学习率，否则模型不会收敛。下图（图1-2）给出了在Mnist数据集上批量大小对梯度的影响。从图1-2(a)可以看出，批量大小设置的越大，下降的越明显，并且下降的比较平滑，当选择批量的大小为1时，整体损失呈下降趋势，但是局部比较震荡。从图1-2(b)可以看出，如果按整个数据集上的迭代次数（Epoch）来看损失变化情况，则是批量样本数越小，下降效果越明显。</p><p><img src="https://img-blog.csdnimg.cn/20190918153354525.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="批量的大小对梯度的影响"></p><p>为了更加有效的训练深层神经网络，在标准的小批量梯度下降算法中，经常使用一些改进方法加快优化速度，常见的改进方法有两种：</p><ul><li>学习率衰减</li><li>梯度方向优化</li></ul><blockquote><p>这些改进的优化方法也同样可以应用在批量梯度下降算法和随机梯度下降算法。</p></blockquote><hr><h3 id="学习率衰减"><a href="#学习率衰减" class="headerlink" title="学习率衰减"></a>学习率衰减</h3><p>在梯度下降中，学习率的设置很重要，设置过大，则不会收敛，设置过小，则收敛太慢。从经验上看，学习率在一开始要设置的大些来保证收敛速度，在收敛到局部最优点附近时要小些来避免震荡，因此比较简单的学习率调整可以通过学习率衰减（Learning Rate Decay）的方式来实现。假设初始学习率为$\alpha_0$，第t次迭代的学习率为$a_t$，常用的衰减方式为按照迭代次数进行衰减，例如</p><ul><li>逆时衰减（公式1-4）</li></ul><script type="math/tex; mode=display">a_t = a_0 \frac{1 }{ 1 + \beta t}</script><ul><li>指数衰减（公式1-5）</li></ul><script type="math/tex; mode=display">a_t = a_0\beta^t</script><ul><li>自然指数衰减（公式1-6）</li></ul><script type="math/tex; mode=display">a_t = a_0 exp(-\beta * t)</script><p>其中$\beta$为衰减率，一般为0.96</p><h4 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h4><p>AdaGrad（Adaptive Gradient）算法是借鉴L2正则化的思想，每次迭代时自适应的调整每个参数的学习率。AdaGrad的参数更新公式为（公式1-7）：</p><script type="math/tex; mode=display">G_t = \sum_{t=1}^{T} g_t \odot g_t\\\bigtriangleup \theta_t = - \frac{\alpha }{ \sqrt{G_t + \epsilon  } } \odot g_t\\g'_t(\theta) = g_t(\theta_{t-1}) + \bigtriangleup \theta_t</script><p>其中$\alpha$为学习率，$\epsilon$是为了保证数据稳定性而设置的非常小的常数，一般取值是 $e^{-7}$到$e^{-10}$，这里的开平方，加，除运算都是按照元素进行的操作。</p><p>在AdaGrad算法中，如果某个参数的偏导数累积比较大，其学习率相对较小，相反，如果其偏导数累积比较大，其学习率相对较大。但是整体上随着迭代次数的增加，学习率逐渐减小。</p><p>AdaGrad算法的缺点是在经过一定次数的迭代后依然没有找到最优点，由于这时候的学习率已经很小了，就很难找到最优点。</p><h4 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h4><p>RMSProp是Geoff Hinton提出的一种自适应学习率的方法，可以在有些情况下避免AdaGrad的学习率单调递减以至于过早衰减的缺点。</p><p>RMSProp算法首先计算的是每次迭代速度$g_t$平方的指数衰减移动平均，如下所示（公式1-8）：</p><script type="math/tex; mode=display">G_t = \beta G_{t-1}  + (1-\beta) g_t \odot g_t = (1- \beta) \sum_{t=1}^{T} \beta ^{T-t} g_t \odot g_t</script><p>其中$\beta$为衰减率，一般取值为0.9，RMSProp算法参数更新公式为（公式1-9）：</p><script type="math/tex; mode=display">\bigtriangleup \theta_t = - \frac{\alpha }{ \sqrt{G_t + \epsilon  } } \odot g_t\\g'_t(\theta) = g_t(\theta_{t-1}) + \bigtriangleup \theta_t</script><p>其中$\alpha$为学习率，通常为0.001。</p><blockquote><p>从公式1-8 可以看出，RMSProp和AdaGrad的区别在于$G_t$的计算由累积方式变成了指数衰减移动平均，在迭代过程中，每个参数的学习率并不是呈衰减趋势，即可以变大，也可以变小。</p></blockquote><h4 id="AdaDelta"><a href="#AdaDelta" class="headerlink" title="AdaDelta"></a>AdaDelta</h4><p>AdaDelta算法也是AdaGrad算法的一个改进，和RMSProp算法类似，AdaDelta算法通过梯度平方的指数衰减移动平均来调整学习率，除此之外，AdaDelta算法还引入了每次参数更新差$\bigtriangleup \theta$的平方的指数衰减移动平均。</p><p>第t次迭代时，每次参数更新差$\bigtriangleup \theta_t , 1&lt;t&lt;T-1$的指数衰减移动平均为（公式1-10）：</p><script type="math/tex; mode=display">\bigtriangleup X^2_{t-1} =\beta _1 \bigtriangleup X^2_{t-2} + (1 - \beta) \bigtriangleup \theta_{t-1} \odot \bigtriangleup \theta_{t-1}</script><p>其中$\beta_1$为衰减率，AdaDelta算法的参数更新差值为（公式1-11）：</p><script type="math/tex; mode=display">\bigtriangleup \theta_t = - \frac{\sqrt {\bigtriangleup X^2_{t-1} + \epsilon }}{ \sqrt {G_t + \epsilon}} g_t</script><blockquote><p>其中$G_t$的计算方式和RMSProp算法一样。从公式1-11可以看出，AdaDelta算法将RMSProp算法中的初始学习率$\alpha$改为动态计算的$\sqrt {\bigtriangleup X^2_{t-1} + \epsilon }$，在一定程度上减缓了学习旅率的波动。</p></blockquote><hr><h3 id="梯度方向优化"><a href="#梯度方向优化" class="headerlink" title="梯度方向优化"></a>梯度方向优化</h3><p>除了调整学习率外，还可以使用最近一段时间内的平均梯度来代替当前时刻的梯度来作为参数的更新方向，从图1-2中可以看出，在小批量梯度下降中，如果每次选取样本数量比较小，损失就会呈现震荡的方式下降，有效的缓解梯度下降中的震荡的方式是通过用梯度的移动平均来代替每次的实际梯度。并提高优化速度，这就是<strong>动量法</strong>。</p><h4 id="动量法"><a href="#动量法" class="headerlink" title="动量法"></a>动量法</h4><p>动量法（Momentum Method）是用之前积累的动量来替代真正的梯度，每次替代的梯度可以看作是加速度。</p><p>在第t次迭代时，计算负梯度的“加权移动平均”作为参数的更新方向，如下所示（公式1-12）：</p><script type="math/tex; mode=display">\bigtriangleup \theta_t = \rho \bigtriangleup \theta_{t-1}-\alpha g_t</script><p>其中$\rho$为动量因子，通常设置为0.9，$\alpha$为学习率。</p><blockquote><p>参数的实际更新值取决于最近一段时间内梯度的加权平均值。当某个参数在最近一段时间内梯度方向不一致时，参数更新的幅度变小，相反，参数更新的幅度变大，起到加速的作用。</p><p>一般而言，在迭代初期，梯度的更新方向比较一致，动量法会起到加速作用，可以更快的起到加速的作用，可以更快的到达最优点，在迭代后期，梯度的更新方向不一致，在收敛时比较动荡，动量法会起到减速作用，增加稳定性。从某种程度来讲，当前梯度叠加上部分的上次梯度，一定程度上可以看作二次梯度。</p></blockquote><h4 id="Nesterov加速梯度"><a href="#Nesterov加速梯度" class="headerlink" title="Nesterov加速梯度"></a>Nesterov加速梯度</h4><p>Nesterov加速梯度（Nesterov Accelerated Gradient， NAG）也叫Nesterov动量法（Nesterov Momentum），是一种对动量法的改进。</p><p>在动量法中，实际的参数更新方向$\bigtriangleup \theta_t$为上一步的参数更新方向$\bigtriangleup \theta_{t-1}$和当前的梯度 $-g_t$的叠加，这样，$\bigtriangleup \theta_t$可以拆分为两步进行，先根据$\bigtriangleup \theta_{t-1}$更新一次得到参数$\tilde{\theta }$，再用$g_t$进行更新，如下所示（公式1-13）：</p><script type="math/tex; mode=display">\tilde{\theta } = \theta_{t-1} + \rho \bigtriangleup \theta_{t-1} \\\theta_t = \tilde{\theta } - \alpha g_t</script><p>其中$g_t$为点$\theta_{t-1}$上的梯度，所以第二步不太合理，更合理的更新方向为$\tilde{\theta }$上的梯度，这样合并后的更新方向为（公式1-14）：</p><script type="math/tex; mode=display"> \bigtriangleup \theta_t =  \rho \bigtriangleup \theta_{t-1} -\alpha g_t(\theta_{t-1} + \rho \bigtriangleup \theta_{t-1} )</script><p>其中$g_t(\theta_{t-1} + \rho \bigtriangleup \theta_{t-1} )$表示损失函数在$\tilde{\theta } = \theta_{t-1} + \rho \bigtriangleup \theta_{t-1}$上的偏导数。</p><p>下图（图1-3）给出了动量法和 Nesterov 加速梯度在参数更新时的比较：</p><p><img src="https://img-blog.csdnimg.cn/20190918192321930.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="动量法和 Nesterov 加速梯度在参数更新时的比较"></p><h4 id="AdaM算法"><a href="#AdaM算法" class="headerlink" title="AdaM算法"></a>AdaM算法</h4><p>自适应动量估计算法（Adaptive Moment Estimation，Adam）可以看作是动量法和RMSprop的结合，不但使用动量作为参数更新，而且可以自适应调整学习率（公式1-15）。</p><script type="math/tex; mode=display">M_t = \beta _1M_{t-1} + (1-\beta _1)g_t\\ G_t = \beta _2 G_{t-1} + (1-\beta _2)g_t \odot g_t</script><p>其中$\beta_1 ，\beta_2$分别为两个移动平均的衰减率，通常取值：$\beta_1=0.9,\beta_2=0.99$。</p><p>$M_t$可以看作是梯度的均值（一阶矩），$G_t$可以看作是梯度的未减去均值的方差（二阶矩）。</p><p>假设$M_t =0,G_t=0$，那么在迭代初期，$M_t，G_t$的值会比真实的均值和方差要小，特别是当$\beta_1 ，\beta_2$都接近1时，偏差会很大，因此需要对偏差进行修正，如下所示（公式1-16）：</p><script type="math/tex; mode=display">\tilde{M_t} = \frac{M_t}{ 1 - \beta^t _1}\\\tilde{G_t} = \frac{G_t}{ 1 - \beta^t _2}</script><p>Adam算法的更新差值为（公式1-17）：</p><script type="math/tex; mode=display">\bigtriangleup \theta_t = - \frac{\alpha }{\sqrt{ \tilde{G_t} + \varepsilon  }} \tilde{M_t}</script><p>其中学习率$\alpha$通常设置为0.001，并且也可以进行衰减，比如$a_t = \frac{a_0} { \sqrt{t}}$。</p><blockquote><p>Adam算法是RMSprop与动量法的结合，因此一种自然的Adam改进方法是引入Nesterov加速梯度，称为Nadam算法。</p></blockquote><h4 id="梯度截断"><a href="#梯度截断" class="headerlink" title="梯度截断"></a>梯度截断</h4><p>在深层神经网络或者循环网络中，除了梯度消失之外，梯度爆炸是影响学习效率的主要隐私，在基于梯度下降的优化过程中，如果梯度突然增大，用较大的梯度更新参数，反而会使结果远离最优点，为了避免这种情况，当梯度达到一定值的时候，要进行梯度截断（gradient clipping）。</p><p>梯度截断是一种比较简单的启发式方法，把梯度的模限定在一个范围内，当梯度的模大于或者小于某个区间时，就进行截断，一般截断的方式有以下几种：</p><ul><li>按值截断</li></ul><p>在第t次迭代时，梯度为$g_t$，给的一个区间[a,b]，如果梯度小于a时，令其为a，大于b时，令其为b。</p><ul><li>按模截断<br>将梯度的模截断到一个给定的截断阈值b。如果$||g_t||^2 \leq b$保持梯度不变，如果$||g_t||^2 &gt; b$，则$g_t= \frac{ b}{||g_t||} g_t$。</li></ul><p>截断阈值 b 是一个超参数,也可以根据一段时间内的平均梯度来自动调整。实验中发现,训练过程对阈值 b 并不十分敏感,通常一个小的阈值就可以得到很好的结果。</p><blockquote><p>在训练循环神经网络时，按模截断是避免梯度爆炸的有效方法。</p></blockquote><hr><h3 id="优化算法总结"><a href="#优化算法总结" class="headerlink" title="优化算法总结"></a>优化算法总结</h3><p>本文介绍了神经网络中的网络优化和正则化概述，以及网络优化中的加快网络优化的两种方法，这些方法大体分为两类：</p><ul><li>调整学习率，使得优化更稳定<blockquote><p>比如：AdaGrad，RMSprop，AdaDelta</p></blockquote></li><li>调整梯度方向，优化训练速度<blockquote><p>比如：动量法，Nesterov加速梯度，梯度截断</p></blockquote></li></ul><p>Adam则是RMSprop 和 动量法的结合。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;神经网络中的网络优化和正则化问题介绍主要分为一，二，三，四篇进行介绍。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一篇包括&lt;ul&gt;
&lt;li&gt;网络优化和正则
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="神经网络" scheme="http://thinkgamer.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>常见的五种神经网络(3)-循环神经网络（下）篇</title>
    <link href="http://thinkgamer.cn/2019/09/18/TensorFlow/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E7%A7%8D%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(3)-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8B%EF%BC%89%E7%AF%87/"/>
    <id>http://thinkgamer.cn/2019/09/18/TensorFlow/常见的五种神经网络(3)-循环神经网络（下）篇/</id>
    <published>2019-09-18T00:14:54.000Z</published>
    <updated>2019-10-14T12:28:36.839Z</updated>
    
    <content type="html"><![CDATA[<p>转载请注明出处：<a href="https://thinkgamer.blog.csdn.net/article/details/100943664" target="_blank" rel="external">https://thinkgamer.blog.csdn.net/article/details/100943664</a><br>博主微博：<a href="http://weibo.com/234654758" target="_blank" rel="external">http://weibo.com/234654758</a><br>Github：<a href="https://github.com/thinkgamer" target="_blank" rel="external">https://github.com/thinkgamer</a><br>公众号：搜索与推荐Wiki</p><hr><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>常见的五种神经网络系列第三篇，主要介绍循环神经网络，由于循环神经网络包含的内容过多，分为上中下三篇进行介绍，本文主要是循环神经网络（下）篇，主要介绍以下内容：</p><ul><li>长短期记忆网络（LSTM）</li><li>门控循环单元网络（GRU）</li><li>递归循环神经网络（RecNN）</li><li>图网络（GN）</li></ul><p>该系列的其他文章：</p><ul><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/89459131" target="_blank" rel="external">常见的五种神经网络(1)-前馈神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100531593" target="_blank" rel="external">常见的五种神经网络(2)-卷积神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100600661" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(上篇)</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100709422" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(中篇)</a></li><li><a href="https://thinkgamer.blog.csdn.net/article/details/100943664" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(下篇)</a></li><li>常见的五种神经网络(4)-深度信念网络</li><li>常见的五种神经网络(5)-生成对抗网络</li></ul><hr><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>长短期记忆（Long Short-Term Memory，LSTM）网络是循环神经网络的一个变体，可以有效的解决简单循环神经网络的梯度爆炸和梯度消失问题。</p><p>LSTM的改进包含两点：</p><ul><li>新的内部状态</li><li>门机制</li></ul><h4 id="新的内部状态"><a href="#新的内部状态" class="headerlink" title="新的内部状态"></a>新的内部状态</h4><p>LSTM网络引入一个新的内部状态（internal state）$c_t$专门进行线性的循环传递，同时（非线性）输出信息给隐藏层的外部状态$h_t$（公式3-1）。</p><script type="math/tex; mode=display">c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c_t}\\h_t = o_t \odot tanh(c_t)</script><p>其中 $f_t$，$i_t$，$o_t$为三个门来控制信息传递的路径，$\odot$为向量元素乘积，$c_{t-1}$为上一时刻的记忆单元，$\tilde{c_t}$是通过非线性函数得到的候选状态（公式3-2）:</p><script type="math/tex; mode=display">\tilde{c_t} = tanh( W_c x_t + U_c h_{t-1} + b_c )</script><p>在每个时刻t，LSTM网络的内部状态$c_t$记录了到当前时刻为止的历史信息。</p><h4 id="门机制"><a href="#门机制" class="headerlink" title="门机制"></a>门机制</h4><p>LSTM网络引入门机制来控制信息的传递， $f_t，i_t，o_t$分别为遗忘门，输入门，输出门。电路中门是0或1，表示关闭和开启，LSTM网络中的门是一种软门，取值在(0,1)，表示以一定比例的信息通过，其三个门的作用分别为：</p><ul><li>$f_t$：控制上一个时刻的内部状态 $c_{t-1}$需要遗忘多少信息 </li><li>$i_t$：控制当前时刻的候选状态$\tilde{c_t}$有多少信息需要保存</li><li>$o_t$：控制当前时刻的状态$c_t$有多少信息需要输出为$h_t$</li></ul><p>三个门的计算如下（公式3-3）：</p><script type="math/tex; mode=display">i_t=\sigma (W_i x_t+U_i h_{t-1} + b_i)\\f_t=\sigma (W_f x_t+U_f h_{t-1}+ b_f )\\o_t=\sigma (W_o x_t+U_o h_{t-1}+b_o)</script><p>其中$\sigma$为logsitic函数，其输出区间为(0,1)，$x_t$为当前输入，$h_{t-1}$为上一时刻的外部状态。 </p><p>下图（图3-1）给出了LSTM的循环单元结构，其计算分为三个过程：</p><ol><li>利用当前时刻的输入$x_t$和上一时刻的外部状态$h_{t-1}$计算出三个门和候选状态$\tilde{c_t}$</li><li>结合遗忘门$f_t$和输入门$i_t$来更新记忆单元$c_t$</li><li>结合输出门$o_t$将内部状态信息传递给外部状态$h_t$</li></ol><p><img src="https://img-blog.csdnimg.cn/20190917210304438.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="LSTM循环单元结构"></p><p>通过LSTM循环单元，整个网络可以建立长距离的时序依赖关系，公式3-1～3-3可以简单的描述为（公式3-4）：</p><script type="math/tex; mode=display">\begin{bmatrix}\tilde{c_t}\\ o_t\\ i_t\\ f_t\end{bmatrix} = \begin{bmatrix}tanh\\ \sigma \\ \sigma \\ \sigma \end{bmatrix} (W\begin{bmatrix}x_t\\ h_{t-1}\end{bmatrix} + b)\\c_t = f_t \odot c_{t-1}+ i_t \odot \tilde{c_t}\\h_t = o_t  \odot tanh(c_t)</script><p>其中$x_t$为当前时刻的输入，$W$和$b$为网络参数。</p><blockquote><p>循环神经网络中的隐状态h存储了历史信息，可以看作是一种记忆（Memeory）。在简单循环网络中，隐状态每个时刻都会被重写，因此可以看作一种短期记忆（Short-term Memeory）。在神经网络中，长期记忆（Long-term Memory）可以看作是网格参数，隐含了从训练数据中学到的经验，其更新周期要远远慢于短期记忆。而在LSTM网络中，记忆单元c可以在某个时刻捕捉到某个关键信息，并有能力将该信息保存一段时间，记忆单元c中保存的信息要远远长于隐状态h，但又远远短于长期记忆，因此被成为长短期记忆网络（Long Short-term Memory）。</p></blockquote><hr><h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p>门控单元（Gate Recurrent Unit，GRU）网络是一种比LSTM更加简单的循环神经网络。在LSTM中遗忘门和输入门是互补关系，比较冗余，GRU将遗忘门和输入门合并成一个门：更新门。同时GRU也不引入额外的记忆单元，直接在当前的状态$h_t$和上一个时刻的状态$h_{t-1}$之间引入线性依赖关系。</p><p>在GRU网络中，当前时刻的候选状态$\tilde{h_t}$为（公式3-5）：</p><script type="math/tex; mode=display">\tilde{h_t} = tanh( W_h x_h + U_h(r_t\odot h_{t-1}) + b_h )</script><blockquote><p>计算$\tilde{h_t}$时，选用tanh激活函数是因为其导数有比较大的值域，缓解梯度消失问题。</p></blockquote><p>其中$r_t \in [0,1]$ 为重置门（reset gate），用来控制候选状态$\tilde {h_t}$的计算是否依赖上一时刻的状态$h_{t-1}$，公式如下（公式3-6）：</p><script type="math/tex; mode=display">r_t = \sigma ( W_r x_t  + U_r h_{t-1} + b_r)</script><p>当 $r_t$为0 时，候选状态$\tilde{h_t}$只和当前输入$x_t$有关，和历史状态无关，当$r_t$为1时，候选状态$\tilde{h_t}$和当前输入$x_t$，历史状态$h_{t-1}$都有关，和简单循环网络一致。</p><p>GRU网络隐状态$h_t$的更新方式为（公式3-7）：</p><script type="math/tex; mode=display">h_t = z_t \odot h_{t-1}+ (1-z_t) \odot \tilde {h_t}</script><p>其中$z \in [0,1]$为更新门（update gate），用来控制当前状态需要从历史状态中保留多少信息（不经过非线性变换），以及需要从候选状态中获取多少信息。$z_t$公式如下（公式3-8）：</p><script type="math/tex; mode=display">z_t = \sigma (W_z x_t + U_z h_{t-1} + b_z)</script><ul><li>若$z_t=0$，当前状态$h_t$和历史状态$h_{t-1}$之间为非线性函数。</li><li>若$z_t=0，r=1$，GRU退化为简单循环网络</li><li>若$z_t=0，r=0$，当前状态$h_t$只和当前输入$x_t$有关，和历史状态$h_{t-1}$无关</li><li>若$z_t=1$，当前时刻状态$h_t=h_{t-1}$，和当前输入$x_t$无关</li></ul><p>GRU网络循环单元结构如下（图3-2）：</p><p><img src="https://img-blog.csdnimg.cn/20190917231241261.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="GRU网络循环单元结构"></p><hr><h3 id="RecNN"><a href="#RecNN" class="headerlink" title="RecNN"></a>RecNN</h3><blockquote><p>如果将循环神经网络按时间展开，每个时刻的隐状态$h_t$看做是一个节点，那么这些节点构成一个链式结构，而链式结构是一种特殊的图结构，很容易将这种消息传递的思想扩展到任意的图结构上。</p></blockquote><p>递归神经网络（Recursive Neurnal Network，RecNN）是循环神经网络在有向无循环图上的控制，递归神经网络一般结构为树状的层次结构，如下图所示（图3-3）：</p><p><img src="https://img-blog.csdnimg.cn/20190917232047624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="递归神经网络"></p><p>以上图(a)为例，包含3个隐藏层$h_1,h_2,h_3$，其中$h_1$由两个输入$x_1,x_2$计算得到，$h_2$由两个输入$x_3,x_4$计算得到，$h_3$由两个隐藏层$h_1,h_2$计算得到。</p><p>对于一个节点$h_i$，它可以接受来自子节点集合$\pi_i$中所有节点的消息，并更新自己的状态，如下所示（公式3-9）：</p><script type="math/tex; mode=display">h_i = f(h_{\pi_i})</script><p>其中$h_{\pi_i}$表示$\pi_i$集合中所有节点状态的拼接，$f(.)$是一个和节点状态无关的非线性函数，可以为一个单层的前馈神经网络，比如图3-3(a)所表示的递归神经网络可以表示为（公式3-10）：</p><script type="math/tex; mode=display">h_1 = \sigma (W \begin{bmatrix}x_1\\ x_2\end{bmatrix}+ b) \\h_2 = \sigma (W \begin{bmatrix}x_3\\ x_4\end{bmatrix}+ b) \\h_3 = \sigma (W \begin{bmatrix}h_1\\ h_2\end{bmatrix}+ b)</script><p>其中$\sigma$表示非线性激活函数，W和b为可学习的参数，同样输出层y可以为一个分类器，比如（公式3-11）：</p><script type="math/tex; mode=display">h_3 = g (W' \begin{bmatrix}h_1\\ h_2\end{bmatrix}+ b')</script><p>其中$g(.)$为分类器，$W’$和$b’$为分类器的参数。当递归神经网络的结构退化为图3-3(b)时，就等价于简单神经循环网络。</p><p>递归神经网络主要用来建模自然语言句子的语义，给定一个句子的语法结构，可以使用递归神经网络来按照句法的组合关系来合成一个句子的语义，句子中每个短语成分可以分成一些子成分，即每个短语的语义可以由它的子成分语义组合而来，进而合成整句的语义。</p><p>同样也可以使用门机制来改进递归神经网络中的长距离依赖问题，比如树结构的长短期记忆模型就是将LSTM的思想应用到树结构的网络中，来实现更灵活的组合函数。</p><hr><h3 id="GN"><a href="#GN" class="headerlink" title="GN"></a>GN</h3><p>在实际应用中，很多数据是图结构的，比如知识图谱，社交网络，分子网络等。而前馈网络和反馈网络很难处理图结构的数据。</p><p><strong>图网络（Graph Network，GN）</strong>是将消息传递的思想扩展到图结构数据上的神经网络。</p><p>对于一个图结构$G(V,\varepsilon )$，其中$V$表示节点结合，$\varepsilon$表示边集合。每条边表示两个节点之间的依赖关系，节点之间的连接可以是有向的，也可以是无向的。图中每个节点v都用一组神经元来表示其状态$h^{(v)}$ ，初始状态可以为节点v的输入特征$x^{(v)}$，每个节点接受相邻节点的信息，来更新自己的状态，如下所示（公式3-12）：</p><script type="math/tex; mode=display">m^{(v)}_t = \sum_{u \in N(v)} f( h^{(v)}_{t-1},h^{(u)}_{t-1},e^{(u,v)} )\\h^{(v)}_t = g(h^{(v)}_{t-1},m^{(u)}_t)</script><p>其中$N(v)$表示节点v的邻居节点，$m^{(v)}_t$ 表示在t时刻节点v接受到的信息，$e^{(u,v)}$为边(v,u)上的特征。</p><p>公式3-12是一种同步更新方式，所有结构同时接受信息并更新自己的状态，而对于有向图来说，使用异步的更新方式会更有效率，比如循环神经网络或者递归神经网络，在整个图更新T次后，可以通过一个读出函数g(.)来得到整个网络的表示。</p><blockquote><p>至此，循环神经网络（上）（中）（下）篇已经介绍完毕。</p></blockquote><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转载请注明出处：&lt;a href=&quot;https://thinkgamer.blog.csdn.net/article/details/100943664&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://thinkgamer.blog.csdn.
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="神经网络" scheme="http://thinkgamer.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>常见的五种神经网络(3)-循环神经网络（中）篇</title>
    <link href="http://thinkgamer.cn/2019/09/11/TensorFlow/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E7%A7%8D%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(3)-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%AD%EF%BC%89%E7%AF%87/"/>
    <id>http://thinkgamer.cn/2019/09/11/TensorFlow/常见的五种神经网络(3)-循环神经网络（中）篇/</id>
    <published>2019-09-10T17:16:12.000Z</published>
    <updated>2019-10-14T12:28:36.840Z</updated>
    
    <content type="html"><![CDATA[<p>转载请注明出处：<a href="https://thinkgamer.blog.csdn.net/article/details/100709422" target="_blank" rel="external">https://thinkgamer.blog.csdn.net/article/details/100709422</a><br>博主微博：<a href="http://weibo.com/234654758" target="_blank" rel="external">http://weibo.com/234654758</a><br>Github：<a href="https://github.com/thinkgamer" target="_blank" rel="external">https://github.com/thinkgamer</a><br>公众号：搜索与推荐Wiki</p><hr><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>常见的五种神经网络系列第三种，主要介绍循环神经网络，分为上中下三篇进行介绍，本文主为（中）篇，涉及内容如下：</p><ul><li>循环神经网络中的参数学习</li><li>RNN中的长期依赖问题</li><li>常见的循环神经网络结构</li></ul><p>该系列的其他文章：</p><ul><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/89459131" target="_blank" rel="external">常见的五种神经网络(1)-前馈神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100531593" target="_blank" rel="external">常见的五种神经网络(2)-卷积神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100600661" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(上篇)</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100709422" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(中篇)</a></li><li><a href="https://thinkgamer.blog.csdn.net/article/details/100943664" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(下篇)</a></li><li>常见的五种神经网络(4)-深度信念网络</li><li>常见的五种神经网络(5)-生成对抗网络</li></ul><hr><h3 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h3><p>循环神经网络的参数可以通过梯度下降方法来学习。给定一个样本(x,y)，其中$x_{1:T}=(x_1, x_2, … ,x_T)$为长度是T的输入序列，其中$y_{1:T}=(y_1, y_2, … ,y_T)$是长度为T的标签序列，在每个时刻t，都有一个监督信息$y_t$，定义时刻t的损失函数为（公式1-1）：</p><script type="math/tex; mode=display">L_t = L(y_t, g(h_t))</script><p>其中$g(h_t)$为第t时刻的输出，L为可微分的损失函数，比如交叉熵，整个序列上的损失函数为（公式1-2）：</p><script type="math/tex; mode=display">L = \sum_{t=1}^{T} L_t</script><p>整个序列的损失函数L关于参数U的梯度为（公式1-3）：</p><script type="math/tex; mode=display">\frac{\partial L}{\partial U} = \sum _{t=1}^{T}\frac{\partial L_t}{ \partial U }</script><p>即每个时刻的损失函数$L_t$对参数U的偏导数之和。</p><p>在循环神经网络中主要有两种计算梯度的方式：</p><ul><li>随时间反向传播算法（Backpropagation Through Time，BRTT）</li><li>实时循环学习（Real-Time Recurrent Learning，RTRL）</li></ul><h4 id="随时间反向传播算法"><a href="#随时间反向传播算法" class="headerlink" title="随时间反向传播算法"></a>随时间反向传播算法</h4><p>主要通过类似前馈神经网络的错误反向传播算法来进行计算梯度。随时间反向传播算法将循环神经网络看作是一个展开的多层前馈网络，其中“每一层”对应循环网络中的每个时刻，这样循环神经网络就可以按照前馈神经网络中的反向传播算法来计算梯度。与前馈神经网络不同的是，循环神经网络中各层的参数是共享的，因此参数的真实梯度是各个层的参数梯度之和。</p><p>先计算公式1-3中第t时刻损失对参数U的偏导数 $\frac {\partial L_t}{\partial U}$，参数U和每个时刻k的净输入$z_k = Uh_{k-1} + Wx_{k} + b$有关，因此第t个时刻损失函数$L_t$关于参数$U_ij$的梯度为（公式1-4）：</p><script type="math/tex; mode=display">\frac{\partial L_t}{ \partial U_{ij}} = \sum_{k=1}^{t} tr( ( \frac{\partial L_t}{ \partial z_k} )^T \frac{\partial^+ z_k}{ \partial U_{ij}}    )\\= \sum_{k=1}^{t}  ( \frac{\partial^+ z_k}{ \partial U_{ij}}    )^T  \frac{\partial L_t}{ \partial z_k}</script><p>其中$\frac{\partial^+ z_k}{ \partial U_{ij}}$ 表示“直接”偏导数，即公式$z_k = Uh_{k-1} + Wx_{k} + b$中保持$h_{k-1}$不变，对$U_{ij}$进行求偏导数，得到（公式1-5）：</p><script type="math/tex; mode=display"> \frac{\partial^+ z_k}{ \partial U_{ij}}  = \begin{bmatrix}0\\ ... \\ [h_{k-1}]_j \\ ... \\ 0\end{bmatrix} \triangleq I_i([h_{k-1}]_j)</script><p>其中$[h_{k-1}]_j$为第$k-1$时刻隐状态的第j维，$I_i(x)$除了第j行值为x，之外全为0的向量。</p><p>定义$\delta _{t,k} = \frac{\partial L_t}{ \partial z_k }$为第t时刻损失函数对第k时刻隐藏层神经元净输入$z_k$的导数，则（公式1-6）：</p><script type="math/tex; mode=display">\delta _{t,k} = \frac{\partial L_t}{ \partial z_k }\\= \frac{ \partial h_k }{ \partial z_k} \frac{\partial z_{k+1}}{ \partial h_k } \frac{ \partial L_t }{ \partial z_{k+1} }\\= diag(f'(z_k))U^T \delta _{t,k+1}</script><p>将（公式1-6） 和 （公式 1-5） 代入（公式1-4）得到（公式1-7）：</p><script type="math/tex; mode=display">\frac{\partial L_t}{ \partial U_{ij} } = \sum_{k=1}^{ t } [\delta _{t,k}]_i [h_{k-1}]_j</script><p>将（公式1-7）写成矩阵形式为（公式1-8）：</p><script type="math/tex; mode=display">\frac{\partial L}{ \partial U } = \sum_{k=1}^{ t } \delta _{t,k} h^T_{k-1}</script><p>下图为随时间反向传播算法示例：</p><p><img src="https://img-blog.csdnimg.cn/20190910191047315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="随时间反向传播算法示例"></p><p>将（公式1-8）代入（公式1-3）得到整个序列的损失函数$L$关于参数$U$的梯度（公式1-9）:</p><script type="math/tex; mode=display">\frac{\partial L}{ \partial U } = \sum_{t=1}^{ T}\sum_{k=1}^{ t } \delta _{t,k} h^T_{k-1}</script><p>同理可得到$L$关于参数$W$的梯度（公式1-10）：</p><script type="math/tex; mode=display">\frac{\partial L}{ \partial W } = \sum_{t=1}^{ T}\sum_{k=1}^{ t } \delta _{t,k} x^T_k</script><p>$L$关于参数$b$的梯度（公式1-11）：</p><script type="math/tex; mode=display">\frac{\partial L}{ \partial b } = \sum_{t=1}^{ T}\sum_{k=1}^{ t } \delta _{t,k}</script><blockquote><p>在 随时间反向传播算法中，参数的梯度需要在一个完整的“向前”计算和“向后”计算后才能得到并参数更新。</p></blockquote><h4 id="实时循环学习"><a href="#实时循环学习" class="headerlink" title="实时循环学习"></a>实时循环学习</h4><p>与随时间反向传播算法不同的是：实时循环学习（Real-Time Recurrent Learning）是通过前向传播的方式来计算梯度。</p><p>假设RNN中第 $t+1$时刻的状态$h_{t+1}$为（公式1-12）：</p><script type="math/tex; mode=display">h_{t+1} = f(z_{t+1}) = f(Uh_k + Wx_{k+1} + b)</script><p>其关于参数$U_{ij$的偏导数为（公式1-13）：</p><script type="math/tex; mode=display">\frac{ h_{t+1} }{ \partial U_{ij} } = \frac{ \partial h_{t+1} }{ \partial z_{t+1} } ( \frac{ \partial^+z_{t+1} }{ \partial  U_{ij}}   + U \frac{ \partial h_t}{ \partial U_{ij} } )\\= diag( f'(z_{t+1}) ) ( I_i ([h_t]_j)+ U \frac{ \partial h_t}{ \partial U_{ij} }  )\\=f'(z_{t+1}) \odot  ( I_i ([h_t]_j)+ U \frac{ \partial h_t}{ \partial U_{ij} }  )</script><p>其中$I_i(x)$为除了第i行之外元素全为0的向量。</p><p>RTRL自从第一个时刻开始，除了计算RNN的隐状态之外，还利用（公式1-13）依次前向计算偏导数$\frac{\partial h_1}{ \partial U_{ij}},\frac{\partial h_2}{ \partial U_{ij}},\frac{\partial h_3}{ \partial U_{ij}}…$</p><p>这样假设第t个时刻存在一个监督信息，其损失函数为$L_t$，就可以同时计算损失函数对$U_{ij}$的偏导数（公式1-14）：</p><script type="math/tex; mode=display">\frac{\partial L_t}{ \partial U_{ij}} =( \frac{\partial h_t}{ \partial U_{ij} } )^T \frac{\partial L_t}{ \partial h_t}</script><p>这样在第t个时刻就可以实时计算$L_t$关于参数U的梯度，并更新参数。参数W和b的梯度也可以按照上述方法进行计算。</p><blockquote><p>两种算法比较：RTRL算法和BPTT算法都是基于梯度求解参数，分别通过前向模式和反向模式应用链式法则来计算梯度。在RNN中一般输出维度要比输入维度少，因此BPTT算法的计算量会很小，但要保存计算过程中的梯度值，空间复杂度较高。RTRL算法不需要进行空间回传，比较适合用在在线学习或无限序列的任务中。</p></blockquote><h3 id="长期依赖"><a href="#长期依赖" class="headerlink" title="长期依赖"></a>长期依赖</h3><p>在BRTT算法中，将（公式1-6）展开得到（公式1-15）：</p><script type="math/tex; mode=display">\delta _{t,k}=\prod_{i=k}^{t-1} ( diag('f(z_i ))U^T  )\delta _{t,t}</script><p>如果定义$\gamma \approx || diag(‘f(z_i ))U^T   ||$，则（公式1-16）：</p><script type="math/tex; mode=display">\delta _{t,k}=\gamma ^{t-k} \delta _{t,t}</script><p>若$\gamma &gt;1$，当$t-k \rightarrow +\infty$，$\gamma ^{t-k} \rightarrow +\infty$，会造成系统不稳定，称之为梯度爆炸（Gradient Exploding Problem），反之，若$\gamma &lt; 1$，当$t-k \rightarrow +\infty$，$\gamma ^{t-k} \rightarrow 0$，会出现和前馈神经网络类似的梯度消失问题（Gradient Vanishing Problem）。</p><blockquote><p>注意：在循环神经网络中，梯度消失指的是并不是说$\frac{ \partial L_t}{ \partial U}$的梯度消失了，而是$\frac{ \partial L_t}{ \partial h_k}$的梯度消失，当$t-k$很大时，即参数U的更新主要靠最近的几个状态来更新，长距离的状态对参数U没有影响。</p></blockquote><p>当循环神经网络中使用的激活函数是Logistic或者tanh的时候，由于其导数小于1，并且权重矩阵$||U||$也不会太大，因此，如果时间间隔t-k过大的话，也会出现梯度消失问题。所以一般采用 ReLU激活函数（关于激活函数的介绍可参考：<a href="https://blog.csdn.net/Gamer_gyt/article/details/89440152" target="_blank" rel="external">神经网络中的激活函数介绍</a>）。</p><p>虽然简单循环网络理论上可以建立长时间间隔的状态之间的依赖关系，但是由于梯度爆炸和梯度消失问题，实际上只能学习到短期的依赖关系，这样如果t时刻的输出$y_t$依赖于$t-k$时刻的输入$x_{t-k}$，当间隔k比较大时，简单神经网络很难建模这种长距离的依赖关系，称之为长期依赖问题（Long-Term Dependences Problem）。</p><p>改进措施：</p><ul><li>选取合适的参数</li><li>使用非饱和的激活函数</li></ul><p>循环网络的梯度爆炸问题比较容易解决，一般通过梯度截断和权重衰减来避免。而梯度消失很难解决，通常是对模型进行调优来解决。</p><h3 id="常见的循环神经网络结构"><a href="#常见的循环神经网络结构" class="headerlink" title="常见的循环神经网络结构"></a>常见的循环神经网络结构</h3><p>主要包含四种：</p><ul><li>N：N</li><li>1：N</li><li>N：1</li><li>N：M</li></ul><h4 id="N比N结构"><a href="#N比N结构" class="headerlink" title="N比N结构"></a>N比N结构</h4><p>N维输入对应N维输出，大致结构如下所示：</p><p><img src="https://img-blog.csdnimg.cn/20190910211158381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="循环神经网络N比N结构"></p><p>其常常用于处理以下问题：</p><ul><li>视频理解中获取视频每一帧标签，输入为视频解码后的图像，通过此结构，获取每一 帧的标签信息。这种场景一般用作视频理解的初期，对视频做初步的处理后， 后续可以基于这些标签信息进行语义分析，构建更为复杂的需求场景。</li><li>股票价格预测。基于历史的股票信息输入，预测下一时刻或者未来的股票走势信息。</li></ul><h4 id="1比N结构"><a href="#1比N结构" class="headerlink" title="1比N结构"></a>1比N结构</h4><p>一维输入，N维输出，大致结构如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190910211546198.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="循环神经网络1比N结构"></p><p>还有一种结构是在同一信息在不同时刻输入到网络中，如下所示：<br><img src="https://img-blog.csdnimg.cn/20190910211800194.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="循环神经网络1比N结构"></p><p>其常常用于处理以下问题：</p><ul><li>看图写描述 : 根据输入的 一张图 片，生成对这张图片的描述信息 </li><li>自动作曲 : 按照类别生成音乐 </li></ul><h4 id="N比1结构"><a href="#N比1结构" class="headerlink" title="N比1结构"></a>N比1结构</h4><p>N维输入，一维输出，大致结构如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190910211426311.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="循环神经网络N比1结构"></p><p>其常常用于处理以下问题：</p><ul><li>视频理解中的获取视频每个场景的描述信息，或者获取整个影片的摘要信息。 </li><li>获取用户评价的情感信息，即根据用户的一句话的评论，来判断用户的喜好等情感信息 。</li></ul><h4 id="N比M结构"><a href="#N比M结构" class="headerlink" title="N比M结构"></a>N比M结构</h4><p>N维输入，M维输出，这种结构又被称为Encoder-Decoder模型，也可以称为Seq2Seq模型，这种模型的输入和输出可以不相等，该模型由两部分组成：编码部分和解码部分，大致结构如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190910212035184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="循环神经网络N比M结构"></p><p> c的前半部分循环神经网络为编码部分，称之为Endcoder, c可以是s3的直接输出，或者 是对s3输出做一定的变换，也可以对编码部分所有的s1、s2、s3进行变换得到，这样c中就包 含了对X1、 Xz、码的编码信息 。c的后半部分循环神经网络为解码部分，称之为Decoder。c作为之前的状态编码，作为初始值，输入到Decoder当中。 Decoder经过循环处理，最终将信息解码输出。</p><p> 除了上边所示的解码结构外，还有下图所示的结构：<br> <img src="https://img-blog.csdnimg.cn/20190910212711689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="循环神经网络N比M结构"></p><p> N比M的循环神经网络结构更具有普遍性，现实环境中有很多基于该结构落地的场景，他可以解决如下问题：</p><ul><li>机器翻译：将不同语言作为输入，输出为非输入语言的类型，这也是Encoder-Decoder的经典用法</li><li>文本摘要：输入一篇文章，输出这篇文章的摘要信息</li><li>语音识别：输入一段语音，输出这段语音信息的文字</li></ul><blockquote><p>至此，循环神经网络（中）篇已经介绍完了，在下篇中会展开介绍更多的内容，欢迎关注。</p></blockquote><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转载请注明出处：&lt;a href=&quot;https://thinkgamer.blog.csdn.net/article/details/100709422&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://thinkgamer.blog.csdn.
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="神经网络" scheme="http://thinkgamer.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>常见的五种神经网络(3)-循环神经网络（上）篇</title>
    <link href="http://thinkgamer.cn/2019/09/08/TensorFlow/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E7%A7%8D%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(3)-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8A%EF%BC%89%E7%AF%87/"/>
    <id>http://thinkgamer.cn/2019/09/08/TensorFlow/常见的五种神经网络(3)-循环神经网络（上）篇/</id>
    <published>2019-09-08T08:37:58.000Z</published>
    <updated>2019-10-14T12:28:36.838Z</updated>
    
    <content type="html"><![CDATA[<p>转载请注明出处：<a href="https://thinkgamer.blog.csdn.net/article/details/100600661" target="_blank" rel="external">https://thinkgamer.blog.csdn.net/article/details/100600661</a><br>博主微博：<a href="http://weibo.com/234654758" target="_blank" rel="external">http://weibo.com/234654758</a><br>Github：<a href="https://github.com/thinkgamer" target="_blank" rel="external">https://github.com/thinkgamer</a><br>公众号：搜索与推荐Wiki</p><hr><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>常见的五种神经网络系列第三种，主要介绍循环神经网络，由于循环神经网络包含的内容过多，分为上中下三篇进行介绍，本文主要是循环神经网络（上）篇，主要介绍以下内容：</p><ul><li>循环神经网络概述</li><li>如何给神经网络增加记忆能力<ul><li>延时神经网络</li><li>有外部输入的非线性自回归模型</li><li>循环神经网络</li></ul></li><li>一般的循环神经网络<ul><li>单向循环神经网络</li><li>双向循环神经网络</li><li>深度循环神经网络</li></ul></li><li>循环神经网络应用到机器学习任务</li></ul><p>该系列的其他文章：</p><ul><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/89459131" target="_blank" rel="external">常见的五种神经网络(1)-前馈神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100531593" target="_blank" rel="external">常见的五种神经网络(2)-卷积神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100600661" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(上篇)</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100709422" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(中篇)</a></li><li><a href="https://thinkgamer.blog.csdn.net/article/details/100943664" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(下篇)</a></li><li>常见的五种神经网络(4)-深度信念网络</li><li>常见的五种神经网络(5)-生成对抗网络</li></ul><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>在前馈神经网络中，信息在神经元之间的传递是单向，网络的输出只依赖于当前的输入，这样限制虽然使网络变得容易学习，但是却减弱了网络的表达能力。在很多现实任务中，网络的输出不仅和当前的输入有关，也和过去一段时间的输出相关，比如一个<strong>有限状态自动机</strong>不仅和当前的输入有关，也和当前的状态（上一步的输出）有关。如下图（图-1）</p><p><img src="https://img-blog.csdnimg.cn/2019090716181761.png" alt="有限状态自动机"></p><blockquote><p>有限状态自动机称为FSM（finite state machine）或者FSA（finite state automaton）</p></blockquote><p>此外，前馈神经网络难以处理时序数据，比如视频，语音，文本等。因为时序数据的长度是不固定的，而前馈神经网络要求输入和输出的维度是固定的。因此当处理这种复杂的时序数据时，就需要一种表达能力能强的模型。</p><p><strong>循环神经网络(Recurrent Neural Network,RNN)</strong> 是一类具有短期记忆能力的神经网络，在循环神经网络中，神经元不仅可以接受其他神经元的信息，还可以接受自身的信息，形成一个环路结构。RNN的参数学习可以通过随时间反向传播算法进行学习（下文会具体介绍），随时间反向传播算法按照时间的逆序将错误信息一步步的向前传递，当输入序列时间较长时，会存在梯度消失和梯度爆炸问题（也叫长期依赖问题），为了解决这个问题，人们对RNN进行了许多改进，其中最有效的是引入门控制，比如长短期记忆网络（LSTM）和门控循环单元网络（GRU），将在（下）篇进行介绍。</p><h3 id="如何给网络增加记忆能力"><a href="#如何给网络增加记忆能力" class="headerlink" title="如何给网络增加记忆能力"></a>如何给网络增加记忆能力</h3><p>上边提到前馈神经网络是一个静态网络，不能处理时序数据，那么可以通过以下三种方法给网络增加记忆能力：</p><ul><li>延时神经网络</li><li>有外部输入的非线性自回归模型</li><li>循环神经网络</li></ul><h4 id="延时神经网络"><a href="#延时神经网络" class="headerlink" title="延时神经网络"></a>延时神经网络</h4><p>一种简单的利用利用历史信息的方法是建立一个额外的延时单元，用来存储网络的历史信息（比如输入，输出，隐状态等），这其中比较有代表性的就是延时神经网络（TDNN，Time Delay Neural Network）。</p><p>延时神经网络是在前馈神经网络的非输出层都添加一个延时器，记录最近几次神经元的输出，在第t个时刻，第（l+1）层的神经元和第（l）层神经元的最近p次输出有关，即（公式-1）:</p><script type="math/tex; mode=display">h_t^{l+1} = f(h_t^l,h_{t-1}^l,....,h_{t-p+1}^l)</script><p>通过延时器，前馈神经网络就具有了短期记忆的能力。</p><h4 id="有外部输入的非线性自回归模型"><a href="#有外部输入的非线性自回归模型" class="headerlink" title="有外部输入的非线性自回归模型"></a>有外部输入的非线性自回归模型</h4><p><strong>自回归模型（Autoregressive Model）</strong> 是统计学中常用一类时间序列模型，用一个变量 $y_t$ 的历史信息来预测自己（公式-2）。</p><script type="math/tex; mode=display">y_t = w_0 + \sum_{i=1}^{p}w_p * y_{t-i} + \varepsilon_t</script><p>其中p为超参数，$w_p$ 为参数，$\varepsilon_t～N(0,\sigma ^2)$ 为第t个时刻的噪声，方差$\sigma^2$和时间t无关。</p><p>有外部输入的非线性自回归模型（Nonlinear Autoregressive Model）是自回归模型的扩展，在每个时刻t都有一个外部输入$x_t$，产出一个输出$y_t$，NART通过一个延时器来记录最近几次的外部输入和输出，第t个时刻的输出$y_t$为（公式-3）：</p><script type="math/tex; mode=display">y_t = f(x_t, x_{t-1},..,x_{t-p}, y_{t-1},y_{t-2},....,y_{t-q})</script><p>其中f(.)为非线性函数，可以是前馈神经网络，p和q为超参数。</p><h4 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h4><p>给定一个输入序列，$x_{1:T}=( x_1, x_2, … , x_T )$ 循环神经网络通过以下公式（公式-4）更新带反馈边的隐藏层的活性值$h_t$：</p><script type="math/tex; mode=display">h_t = (h_{t-1}, x_t)</script><p>循环神经网络示例如下（图-2）：<br><img src="https://img-blog.csdnimg.cn/20190907182513443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="循环神经网络示例"></p><h3 id="一般的循环神经网络"><a href="#一般的循环神经网络" class="headerlink" title="一般的循环神经网络"></a>一般的循环神经网络</h3><p>在（图-2）中展示了一个简单的循环神经网络，其整个结构分为3层：输入层，隐藏层和输出层。其中t时刻，隐藏层的状态$h_t$不仅与输入$x_t$有关，还与上一个时刻的隐藏层状态$h_{t-1}$有关。</p><p>由于隐藏层多了一个自身到自身的输入，因此该层被称为循环层，（图-2）所示的为一个简单循环神经网络。循环神经网络还有多种类型，基于循环的方向划分为：</p><ul><li>单向循环神经网络</li><li>双向循环神经网络</li></ul><p>基于循环的深度分为：</p><ul><li>循环神经网络</li><li>深度循环神经网络</li></ul><h4 id="单向循环神经网络"><a href="#单向循环神经网络" class="headerlink" title="单向循环神经网络"></a>单向循环神经网络</h4><p>（图-2）所示即为一个单向的循环神经网络，对其展开后的效果图如下（图-3）：<br><img src="https://img-blog.csdnimg.cn/2019090809043298.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="单向循环神经网络"></p><p>上图可以理解为网络的输入通过时间往后传递，当前隐藏层的输出$h_t$取决于当前层的输入$x_t$和上一层的输出$h_{t-1}$，因此当前隐藏层的输出信息包含了之前时刻的信息，表达出对之前信息的记忆能力。单向循环神经网络表达如下（公式-5）：</p><script type="math/tex; mode=display">o_t = g(V*h_t)\\h_t = f(U*x_t + W*h_{t-1})</script><p>其中$o_t$为输出层的计算公式， $h_t$为隐藏层的计算公式，g(.) 和 f(.)为激活函数。值得说明的是在循环神经网络中U，V，W权重矩阵值每次循环都是一份，因此循环神经网络的每次循环步骤中，这些参数都是共享的，这也是循 环神经网络 的结构特征之一。</p><h4 id="双向循环神经网络"><a href="#双向循环神经网络" class="headerlink" title="双向循环神经网络"></a>双向循环神经网络</h4><p>在日常的信息推断中，当前信息不仅仅依赖之前的内容，也有可能会依赖后续的内容，比如英语的完形天空。这时候单向的循环神经网络就不能很好的处理，就需要 <strong> 双向循环神经网络(Bi-directional Recurrent Neural Network)</strong> 。</p><p>其主要思想是训练一个分别向前和分别向后的循环神经网络，表示完整的上下文信息，两个循环 网络对应同一个输出层，因此可以理解为两个循环神经网络的叠加，对应的输出结果根据两个神经网络输出状态计算获得，将双向循环神经网络按照时间序列结构展开，如下图所示（图-4）：<br><img src="https://img-blog.csdnimg.cn/20190908145624762.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="双向循环神经网络"></p><p>从上图可以看出，隐藏层需要保留两部分，一部分为由前向后的正向传递$h_t$，一部分为由后向前的反向传递$h’_t$，最新的信息输出$o_t$。双向循环神经网络的表达公式如下（公式-6）：</p><script type="math/tex; mode=display">o_t = g(V*h_t + V'*h'_t)\\h_t = f(U*x_t + W*h_{t-1})\\h'_t = f(U'*x_t + W'*h'_{t-1})</script><h4 id="深度循环神经网络"><a href="#深度循环神经网络" class="headerlink" title="深度循环神经网络"></a>深度循环神经网络</h4><p>上边介绍的单向训练神经网络和双向循环神经网络都只有一个隐藏层，但是在实际应用中，为了增强表达能力，往往引入多个隐藏层，即深度循环神经网络，如下图所示（图-5）：<br><img src="https://img-blog.csdnimg.cn/20190908151530509.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="深度循环神经网络"></p><p>同样可以得到深度循环神经网络的表达式（公式-7）：</p><script type="math/tex; mode=display">o_t = g(V^{(i)}*h^{(i)}_t + V'^{(i)}*h'^{(i)}_t)\\h^{(i)}_t = f(U^{(i)}*h^{(i-1)}_t + W^{(i)}*h_{t-1})\\h'^{(i)}_t = f(U'^{(i)}*h'^{(i-1)}_t + W'^{(i)}*h'_{t+1})\\...\\h^{(1)}_t = f(U^{(1)} * h_t + W^{(1)}*h_{t-1})\\h'^{(1)}_t = f(U'^{(1)} * h_t + W'^{(1)}*h'_{t+1})\\</script><p>从上述公式可以看出，最终的输出依赖两个维 度的计算，横向上内部前后信息的 叠加，即按照时间的计算；纵向上是每一时刻的输入信息在 逐层之间的传递，即按照 空间结构的计算。</p><h3 id="循环神经网络应用到机器学习任务"><a href="#循环神经网络应用到机器学习任务" class="headerlink" title="循环神经网络应用到机器学习任务"></a>循环神经网络应用到机器学习任务</h3><p>循环神经网络可以应用到很多不同类型的机器学习任务，根据这些任务的特点，可以分为以下几种模式：</p><ul><li>序列到类别模式</li><li>同步的序列到序列模式</li><li>异步的序列到序列模式</li></ul><h4 id="序列到类别模式"><a href="#序列到类别模式" class="headerlink" title="序列到类别模式"></a>序列到类别模式</h4><p>主要应用在序列数据的分类问题，其输入为序列，输出为类别。比如在文本分类中，输入为单词序列，输出为文本的类别。</p><p>假设一个样本 $x_{1:T}=(x_1, x_2, … , x_T)$为一个长度为T的序列，输出为类别 $y \in (1, …, C)$，可以将样本x按不同的时刻输入到循环神经网络中，并得到不同时刻的隐含状态$h_t$，可以将 $h_t$ 看作是整个序列的最终表示，并输入给分类器 g(.) 进行分类，如下所示（公式-8）：</p><script type="math/tex; mode=display">\hat{y} = g(h_T)</script><p>其中g(.) 为简单的线性分类器（比如LR）或者复杂的分类器（前馈神经网络）。</p><p>除了将最后时刻的状态作为序列表示之外，我们还可以对整个序列的状态进行平均，并用整个状态的最终平均作为整个序列的表示（公式-9）：</p><script type="math/tex; mode=display">\hat{y} = g( \frac{1}{T} \sum_{t=1}^{T} h_t )</script><p>公式-8 和公式-9 分别对应下图（图-6）的（a）和（b）:<br><img src="https://img-blog.csdnimg.cn/20190908154219364.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="序列到类别模式"></p><h4 id="同步的序列到序列模式"><a href="#同步的序列到序列模式" class="headerlink" title="同步的序列到序列模式"></a>同步的序列到序列模式</h4><p>主要用于序列标注（Sequence Labeling）任务，即每一时刻都有输入和输出，输入序列和输出序列的长度相同。比如词性标注（Part-of-Speech Tagging）中，每一个单词都需要标注其对应的词性标签。</p><p>假设一个样本 $x_{1:T}=(x_1, x_2, … , x_T)$为一个长度为T的序列，输出为序列 $y_{1:T}=(y_1, y_2, … , y_T)$，可以将样本x按不同的时刻输入到循环神经网络中，并得到不同时刻的隐含状态$h_t$，每个时刻的 $h_t$ 代表了当前时刻和历史的信息，并输入给分类器 g(.) 进行分类，得到当前的标签 $\hat{y}_t$，如下所示（公式-8）：</p><script type="math/tex; mode=display">\hat{y} = g(h_T), \forall_t \in [1,T]</script><p><img src="https://img-blog.csdnimg.cn/20190908154735645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="同步的序列到序列模式"></p><h4 id="异步的序列到序列模式"><a href="#异步的序列到序列模式" class="headerlink" title="异步的序列到序列模式"></a>异步的序列到序列模式</h4><p>异步的序列到序列模式也成为编码器-解码器，输入序列和输出序列不需要有严格的对应关系，也不需要保持相同的长度，比如在机器翻译中，输入为源语音的单词序列，输出为目标语言的单词序列。</p><p>假设输入为一个长度为T的序列 $x_{1:T}=(x_1, x_2, … , x_T)$，输出为长度为M的序列$y_{1:M}=(x_1, x_2, … , x_M)$，经常通过先编码后解码的形式实现。</p><p>先将样本x按不同时刻输入到一个循环神经网络（编码器）中，并得到其编码$h_T$，然后再使用另外一个循环神经网络（解码器）中，得到输出序列$\hat {y}_{1:M}$。为了建立输出序列之间的依赖关系，在解码器中通常使用非线性的自回归模型。如下所示（公式-9）：</p><script type="math/tex; mode=display">h_t = f_1(h_{t-1},x_t), \forall_t \in [1,T]\\h_{T+t} = f_2(h_{T+t-1},x_t), \forall_t \in [1,M]\\\hat{y} _t = g(h_{T+t}), \forall_t \in [1,M]</script><p>其中 $f_1(.)$，$f_2(.)$分别为用作编码器和解码器的循环神经网络，g(.)为分类器，$\hat{y}_t$ 为输出预测$\hat{y}_t$的表示。</p><p><img src="https://img-blog.csdnimg.cn/20190908160323234.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><blockquote><p>至此，循环神经网络（上）篇已经介绍完了，在（中）篇和下篇中会展开介绍更多的内容，欢迎关注。</p></blockquote><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转载请注明出处：&lt;a href=&quot;https://thinkgamer.blog.csdn.net/article/details/100600661&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://thinkgamer.blog.csdn.
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="神经网络" scheme="http://thinkgamer.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>常见的五种神经网络(2)-卷积神经网络</title>
    <link href="http://thinkgamer.cn/2019/09/05/TensorFlow/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E7%A7%8D%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(2)-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://thinkgamer.cn/2019/09/05/TensorFlow/常见的五种神经网络(2)-卷积神经网络/</id>
    <published>2019-09-05T10:05:24.000Z</published>
    <updated>2019-10-14T12:28:36.837Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/2019090518010966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><hr><p>该系列的其他文章：</p><ul><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/89459131" target="_blank" rel="external">常见的五种神经网络(1)-前馈神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100531593" target="_blank" rel="external">常见的五种神经网络(2)-卷积神经网络</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100600661" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(上篇)</a></li><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/100709422" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(中篇)</a></li><li><a href="https://thinkgamer.blog.csdn.net/article/details/100943664" target="_blank" rel="external">常见的五种神经网络(3)-循环神经网络(下篇)</a></li><li>常见的五种神经网络(4)-深度信念网络</li><li>常见的五种神经网络(5)-生成对抗网络</li></ul><hr><blockquote><p>卷积神经网络（Convolutional Neural Network）是一种具有局部连接，权重共享等特性的深层前馈神经网络。一般是由卷积层，汇聚层，全连接层交叉堆叠而成，使用反向传播算法进行训练。其有三个结构上的特征：局部连接，权重共享以及汇聚。这些特征使得卷积神经网络具有一定程度上的平移，缩放和旋转不变性。较前馈神经网络而言，其参数更少。</p></blockquote><p>卷积神经网络目前主要应用在图像和视频分析的各种任务上，比如图像分类，人脸识别，物体识别，图像分割等，其准确率也远远超过了其他的人工神经网络。近年来，卷积神经网络也应用到自然语言处理和推荐系统等领域。</p><h1 id="卷积的概念"><a href="#卷积的概念" class="headerlink" title="卷积的概念"></a>卷积的概念</h1><p>卷积（Convolution）也叫摺积，是分析数学中一种重要的运算。在信号处理或者图像处理中，会经常使用一维或二维卷积。</p><h2 id="一维卷积"><a href="#一维卷积" class="headerlink" title="一维卷积"></a>一维卷积</h2><p>一维卷积经常用在信号处理上，用来计算信号的累积。假设一个信号发生器每个时刻t发生一个信号 $x_t$，其信号衰减率维$w_k$，即在$k-1$时刻后，信息变为原来的$w_k$倍，假设$w_1 = 1, w_2=1/2,w_3=1/4$那么在t时刻收到的信号$y_t$为当前时刻产生的信息之前时刻产生的延迟信息的叠加(公式1.1)。</p><script type="math/tex; mode=display">y_t = 1 * x_t + 1/2 * x_{t-1} + 1/4 * x_{t-2}\\=w_1 * x_t + w_2 * x_{t-1} + w_3 * x{t-2}\\= \sum_{k=1}^{3} w_k * x_{t-k+1}</script><p>我们把$w_1, w_2, ….$称为滤波器（Filter）或者卷积核（Convolution Kernel）。假设滤波器长度为m，它和一个信号序列$x_1,x_2,…$的卷积为(公式1.2)：</p><script type="math/tex; mode=display">\sum_{k=1}^{m} w_k * x_{t-k+1}</script><p>信号序列x和滤波器w的卷积定义为(公式1.3)：</p><script type="math/tex; mode=display">y = w \otimes  x</script><p>一维卷积示例如下：<br><img src="https://img-blog.csdnimg.cn/20190904075135300.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="一维卷积神经网络"></p><h2 id="二维卷积"><a href="#二维卷积" class="headerlink" title="二维卷积"></a>二维卷积</h2><p>卷积也常用在图像处理中，因为图像是一个二维结构，需要对一维卷积进行扩展。给定一个图像$X \in R^{M<em>N}$和滤波器$W \in R^{m</em>n}$，一般$m &lt;&lt; M, n &lt;&lt;N$，其卷积为(公式1.4)：</p><script type="math/tex; mode=display">y_{ij}=\sum_{u=1}^{M}\sum_{v=1}^{N} w_{uv} * x_{i-u+1,j-v+1}</script><p>二维卷积示例如下：<br><img src="https://img-blog.csdnimg.cn/20190904080806425.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="二维卷积示例"></p><blockquote><p>注意：上图中的展示的卷积核（3*3矩阵）和二维结构数据相乘时需要逆时针旋转180度！对照着卷积公式可以理解。</p></blockquote><h2 id="互相关"><a href="#互相关" class="headerlink" title="互相关"></a>互相关</h2><p>在计算卷积过程中，需要进行卷积核翻转，在具体实现上一般会以互相关操作来代替卷积，从而会减少一些不必要的操作或者开销。互相关是一个衡量两个序列相关性的函数，通常是用滑动窗口的点积计算来实现。给定一个图像$X \in R^{M<em>N}$和卷积核$W \in R^{m</em>n}$，他们的互相关为(公式1.5)：</p><script type="math/tex; mode=display">y_{ij}=\sum_{u=1}^{M}\sum_{v=1}^{N} w_{uv} * x_{i+u-1,j+v-1}</script><p>和公式1.4相比，互相关和卷积的区别在于是否对卷积核进行翻转，因此互相关也称为不翻转卷积。</p><p>在神经网络中使用卷积是为了进行特征抽取，卷积核是否进行核翻转与其特征抽取能力无关。特别是当卷积核是可学习的参数时，卷积和互相关是等价的，因此为了实现方便，通常使用互相关来代替卷积。事实上很多深度学习工具中卷积操作都是用互相关来代替的。</p><p>公式1.5可以表示为：</p><script type="math/tex; mode=display">Y = W \otimes X</script><hr><h1 id="常见的卷积核及特征"><a href="#常见的卷积核及特征" class="headerlink" title="常见的卷积核及特征"></a>常见的卷积核及特征</h1><h2 id="常见的卷积核"><a href="#常见的卷积核" class="headerlink" title="常见的卷积核"></a>常见的卷积核</h2><ol><li>对图像无任何影响的卷积核<script type="math/tex; mode=display">\begin{bmatrix}0  & 0 & 0 \\ 0 &  1 & 0 \\ 0 & 0  & 0\end{bmatrix}</script></li><li>对图像进行锐化的滤波器<script type="math/tex; mode=display">\begin{bmatrix}-1  & -1 & -1 \\ -1 &  9 & -1 \\ -1 & -1  & -1\end{bmatrix}</script></li><li>浮雕滤波器<script type="math/tex; mode=display">\begin{bmatrix}-1  & -1 & 0 \\ -1 &  0 & 1 \\ 0 & 1  & 1\end{bmatrix}</script></li><li><p>均值模糊滤波器</p><script type="math/tex; mode=display">\begin{bmatrix}0  & 0.2 & 0 \\ 0.2 &  0.2 & 0.2 \\ 0 & 0.2  & 0\end{bmatrix}</script><blockquote><p>均值模糊是对像素点周围的像素进行均值化处理，将上下左右及当前像素点分文5份，然后进行平均，每份占0.2，即对当前像素点周围的点进行均值化处理。</p></blockquote></li><li><p>高斯模糊滤波器</p><blockquote><p>均值模糊是一种简单的模糊处理方式，但是会现实模糊不够平滑，而高斯模糊可以很好的处理，因此高斯模糊经常用于图像的降噪处理上，尤其是在边缘检测之前，进行高斯模糊，可以移除细节带来的影响。</p></blockquote></li></ol><ul><li>一维高斯模糊<script type="math/tex; mode=display">G(x)=\frac{1}{ \sqrt{2 \pi \sigma ^2}} e^{( -\frac{x^2}{2\sigma ^2} )}</script></li><li>二维高斯模糊<script type="math/tex; mode=display">G(x)=\frac{1}{ \sqrt{2 \pi \sigma ^2}} e^{( -\frac{x^2+y^2}{2\sigma ^2} )}</script></li></ul><h2 id="卷积核的特征"><a href="#卷积核的特征" class="headerlink" title="卷积核的特征"></a>卷积核的特征</h2><blockquote><p>这里的滤波器就是卷积核</p></blockquote><ul><li>当滤波器矩阵中的值相加为0甚至更小时，被滤波器处理之后的图像相对会比原始图像暗，值越小越暗</li><li>当滤波器矩阵中的值相加和为1时，被滤波器处理之后的图像与原始图像的亮度相比几乎一致</li><li>当滤波器矩阵中的值相加和大于1时，被滤波器处理之后的图像相对会比原始图像的亮度更亮</li></ul><hr><h1 id="卷积的变种"><a href="#卷积的变种" class="headerlink" title="卷积的变种"></a>卷积的变种</h1><p>在卷积的标准定义基础上，还可以引入滤波器的滑动步长和零填充来增加卷积的多样性，可以更加灵活的提取特征。</p><ul><li>滤波器的步长（Stride）是指滤波器在滑动时的时间间隔</li><li>零填充（Zero Padding）是在输入向量两端进行补零</li></ul><p>下图展示为步长为2和零填充的示例：<br><img src="https://img-blog.csdnimg.cn/20190904081641651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="步长为2和零填充示例"></p><p>假设卷积层的输入神经元个数为n，卷积大小为m，步长为s，输入神经元两端各补p各零，那么该卷积对应的神经元数量为：(n+2p-m)/s + 1。</p><p>一般的卷积分为以下三种：</p><ul><li>窄卷积（Narrow Convolution）：步长s=1，两端不补零即p=0，卷积后输出长度为：n-m + 1</li><li>宽卷积（Wide Convolution）：步长s=1，两端补零p=m-1，卷积后输出长度为：n+m-1</li><li>等宽卷积（Equal-Width Convolution）：步长s = 1,两端补零p = (m −1)/2,卷积后输出长度 n。</li></ul><hr><h1 id="卷积的数学性质"><a href="#卷积的数学性质" class="headerlink" title="卷积的数学性质"></a>卷积的数学性质</h1><p>卷积有很多比较好的数学性质，这里主要介绍一些二维的数学性质，同样针对一维卷积也同样适用。</p><h2 id="交换性"><a href="#交换性" class="headerlink" title="交换性"></a>交换性</h2><p>如果不限制两个卷积的长度，卷积是具有交换性的。即 $x \otimes  y = y \otimes  x$，当输入信息和卷积核有固定长度时，他们的宽卷积依然具有交换性。对于两维图像$X \in R^{M<em>N}$和卷积核$W \in R^{m</em>n}$，对图像X的两个维度进行零填充，两端各补m-1和n-1个零，得到全填充（Full Padding）的图像$\tilde{X} \in R^{(M+2m-2)(N+2n-2)}$。图像X和卷积核W的宽卷积（Wide Convolution）定义为：$W \tilde{\otimes } X \triangleq X \tilde{\otimes } W$<br>，其中$\tilde{\otimes }$为宽卷积操作。宽卷积具有交换性，即：$W \tilde{\otimes } X = X \tilde{\otimes } W$</p><h2 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h2><p>假设$Y = W \otimes X$，其中$X \in R^{M<em>N}$，$W \in R^{m</em>n}$，$Y \in R^{(M-m+1)*(N-n+1)}$，函数$f(Y) \in R$为一个标量函数，则(公式1.6)</p><script type="math/tex; mode=display">\frac{\partial f(Y)}{\partial w_{uv}} = \sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1} \frac{\partial f(Y)}{\partial y_{ij}} \frac{\partial y_{ij}}{\partial w_{uv}}\\= \sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1}  \frac{\partial f(Y)}{\partial y_{ij}}x_{ {i+u-1},{j+v-1}}  \\= \sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1}  \frac{\partial f(Y)}{\partial y_{ij}}x_{ {u+i-1},{v+j-1}}</script><p>从公式1.6可以看出，f(Y)关于W的偏导数为X和$\frac{\partial f(Y)}{\partial Y}$的卷积（公式1.7）</p><script type="math/tex; mode=display">\frac{\partial f(Y)}{\partial W} = \frac{\partial f(Y)}{ \partial Y } \otimes X</script><p>同理得到（公式1.8）：</p><script type="math/tex; mode=display">\frac{\partial f(Y)}{\partial x_{st}} = \sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1} \frac{\partial f(Y)}{\partial y_{ij}} \frac{\partial y_{ij}}{\partial x_{st}}\\= \sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1}  \frac{\partial f(Y)}{\partial y_{ij}}w_{ {s-i+1},{t-j+1}}</script><p>其中当$(s-i+1) &lt; 1$，或$(s-i+1)&gt;m$，或$(t-j+1) <1$，或$(t-j+1)>n$，或$w_{s-i+1,t-j+1}=0$时，即相当于对W进行了 p=(M-m,N-n)的零填充。</1$，或$(t-j+1)></p><p>从公式1.8可以看出，f(Y)关于X的偏导数为W和$\frac{\partial f(Y)}{ \partial Y }$，公式1.8中的卷积是真正的卷积而不是互相关，为了一致性，我们用互相关的卷积，即(公式1.9)：</p><script type="math/tex; mode=display">\frac{\partial f(Y)}{\partial X} = rot180(\frac{\partial f(Y)}{\partial X}) \tilde{\otimes }W=rot180(W) \tilde{\otimes }\frac{\partial f(Y)}{\partial X}</script><p>其中rot180(.)表示旋转180度。</p><hr><h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p>卷积神经网络一般由卷积层，汇聚层和全连接层构成。</p><h2 id="用卷积代替全连接"><a href="#用卷积代替全连接" class="headerlink" title="用卷积代替全连接"></a>用卷积代替全连接</h2><p>在全连接前馈神经网络中，如果第$l$层有$n^l$个神经元，第$l-1$层有$n^{l-1}$个神经元，连接边就有$n^l * n^{l-1}$也就是权重参数有这么多个，当m和n都很大时，权重矩阵的参数会非常多，训练的效率会非常低。</p><p>如果用卷积代替全连接，第$l$层的净输入$z^l$与$l-1$层活性值$a^{l-1}$和滤波器$w^l \in R^m$的卷积，即$z^l = w^l * a^{l-1} + b^l$,其中滤波器$w^l$<br>为可学习的权重向量，$b^l \in R^{l-1}$为可学习的偏置。</p><p>根据卷积的定义，卷积层有两个很重要的性质：</p><ul><li>局部连接：在卷积层(假设是第$l$层)中的每一个神经元都只和下一层(第$l − 1$层)中某个局部窗口内的神经元相连,构成一个局部连接网络。</li><li>全局共享：作为参数的滤波器 $w^l$，对于第 $l$层的所有的神经元都是相同的。</li></ul><h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>卷积层的作用是提取一个局部区域的特征，不同大小的卷积相当于不同的特征提取器。上文介绍的卷积和神经元都是一维的，但卷积神经网络主要是针对图像处理而言的，而图像通常是二维的，为了充分利用图像的局部特征，通常将神经元组织为三维结构的神经层，其大小 M <em> 宽度 W </em> 深度 D，即D个M*N的特征映射组成。</p><p>对于输入层的而言，特征映射就是图像本身，如果是灰色图像，则深度为1，如果为彩色图像（分别是RGB三个通道的颜色特征映射），则深度为3。</p><h2 id="汇聚层"><a href="#汇聚层" class="headerlink" title="汇聚层"></a>汇聚层</h2><p>汇聚层（Pooling Layer）也叫子采样层（Subsampling Layer），其作用是进行特征选择，降低特征数量，从而减少参数数量。</p><p>卷积层虽然可以明显减少网络中的连接数量，但是特征映射中的神经元个数并未显著减少。如果后边接一个分类器的话，分类器的输入维数依然很高，很容易出现过拟合。因此有了汇聚层的产生，在卷积后边加一个汇聚层，从而降低特征维数，避免过拟合。</p><p>假设汇聚层的输入特征映射组为$X \in R^{M <em> N </em> D}$，对于其中每一个映射$X^d$，将其划分为很多区域$R^d_{m,n}$，1 &lt;= m &lt;= M’，1&lt;= n &lt;= N’，这些区域可以重叠，也可以不重叠。汇聚（Pooling）是指对每个区域进行下采样（Down Sampling）得到一个值，作为这个区域的概括。常见的汇聚方式有两种：</p><ul><li>最大汇聚（Maximum Pooling）：一个区域内所有神经元的最大值</li><li>平均汇聚（Mean Pooling）：一个区域内所有神经元的平均值</li></ul><p>典型的汇聚层是将每个特征映射划分为2<em>2大小的不重叠区域，然后使用最大汇聚的方式进行下采样。汇聚层也可以看作是一个特殊的卷积层，卷积核大小为m </em> m，步长为s * s，卷积核为 max函数或者mean函数。过大的采样区域会急剧减少神经元的数量，会造成过多的信息损失。</p><p>下图所示为最大汇聚示例：<br><img src="https://img-blog.csdnimg.cn/20190905133224389.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="最大汇聚实例"></p><h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><p>在全连接层中，将最后一层的卷积输出展开，并将当前层的每个节点与下一层的另一个节点连接起来。全连接层只是人工神经网络的另一种说法，如下图所示，全连接层中的操作与一般神经网络中的操作完全相同。</p><p><img src="https://img-blog.csdnimg.cn/20190904171044639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="image"></p><p>对于output layer中的的每个神经元，其表达式可以记做为(公式1.10)：</p><script type="math/tex; mode=display">y = \sigma (\sum_{i=1}^{m} w_i ^T x_i + b)</script><p>如果outptu有多个神经元，最终可以通过softmax进行最终类别的判断。</p><hr><h1 id="典型的卷积网络结构"><a href="#典型的卷积网络结构" class="headerlink" title="典型的卷积网络结构"></a>典型的卷积网络结构</h1><p>一个典型的卷积网络是有卷积层，汇聚层，全连接层交叉堆叠而成。目前常用的卷积神经网络结构如下图所示：<br><img src="https://img-blog.csdnimg.cn/2019090413573373.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="卷积神经网络"></p><p>卷积块是由M个卷积层b个汇聚层（M通常在2～之间，b为0或1），一个卷积网络中可以堆叠N个连续的卷积块，然后再接着K个全连接层（N的取值空间比较大，一般是1～100或者更大，K通常为0～2）。</p><p>目前整个网络倾向于使用更小的卷积核（比如1<em>1或者3</em>3）以及更深的结构（比如层数大于50），此外，卷积操作的灵活性越来越大，汇聚层的作用变得越来越小，因此目前流行的卷积网络中，汇聚层的比例也在逐渐降低，倾向于全连接网络。</p><hr><h1 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h1><p>在卷积神经网络中，参数为卷积核中的权重和偏置，和全连接前馈神经网络一样，使用误差反向传播算法来进行参数学习。梯度主要通过每一层的误差项$\delta$进行反向传播，并进一步计算每一层的梯度。在卷积神经网络中主要有两种功能不同的网络层：卷积层和汇聚层。而参数为卷积核中权重和偏置，因此只需要计算卷积层中参数梯度。</p><p>不失一般性，对第$l$层卷积层,第$l-1$层的输入特征映射为$X^{(l-1)} \in R^{M<em>N</em>D}$，通过卷积计算得到第$l$层净输入为$Z^{(l)}\in  R^{M’<em>N’</em>P}$，第$l$层的第p(1&lt;= p &lt;= P)个特征净输入为(公式1.11)</p><script type="math/tex; mode=display">Z^{(l,p)} = \sum_{d=1}^{D} W^{(l,p,d)} \otimes X^{(l-1,d)}+ b^{(l,p)}</script><p>其中$W^{(l,p,d)} ,b^{(l,p)}$为卷积核以及偏置。第$l$层共有P * D 个卷积和P个偏置，可以分别使用链式法则计算其梯度。</p><p>根据公式1.7 和 1.11，损失函数关于第$l$层的卷积核$W^{(l,p,d)}$的偏导数为为(公式1.12)：</p><script type="math/tex; mode=display">\frac{\partial L (Y,\hat{Y})}{ \partial W^{(l,p,d)} } = \frac{\partial L (Y,\hat{Y})}{ \partial Z^{(l,p)} } \otimes X^{(l-1,d)}=\delta ^{(l,p)} \otimes X^{(l-1,d)}</script><p>其中为(公式1.13)</p><script type="math/tex; mode=display">\delta ^{(l,p)} = \frac{\partial L (Y,\hat{Y})}{ \partial Z^{(l,p)} }</script><p>为损失函数关于第$l$层的第p个特征映射净输入$Z^{(l,p)}$的偏导数。</p><p>同理可得，损失函数关于第$l$层的第p个偏置$b^{(l,p)}$的偏导数为为(公式1.14)：</p><script type="math/tex; mode=display">\frac{ \partial L (Y,\hat{Y}) }{ \partial b^{(l,p)} } = \sum_{i,j} [\delta ^{(l,p)}]_{i,j}</script><p>卷积网络中，每层参数的梯度依赖其所在层的误差项$\delta ^{(l,p)}$</p><h2 id="误差项的计算"><a href="#误差项的计算" class="headerlink" title="误差项的计算"></a>误差项的计算</h2><p>卷积层和汇聚层的误差项计算不同。</p><h3 id="卷积层-1"><a href="#卷积层-1" class="headerlink" title="卷积层"></a>卷积层</h3><p>当$l+1$层为卷积层时，假设特征映射净输入(公式1.15)</p><script type="math/tex; mode=display">Z^{(l+1,p)} = \sum_{d=1}^{D} W^{(l+1,p,d)} \otimes X^{(l,d)} + b^{(l+1,p)}</script><p>其中$W^{(l+1,p,d)},b^{(l+1,p)}$为第$l$层的卷积核和偏置。第$l+1$层共有 P *D 个卷积核和P个偏置。</p><p>第 $l$层的第 $d$个特征映射的误差项$\delta ^{(l,d)}$的具体推导过程如下(公式1.16):</p><script type="math/tex; mode=display">\delta ^{(l,d)} \triangleq  \frac{\partial L (Y,\hat{Y})}{ \partial Z^{(l,d)} }\\=\frac{\partial X^{(l,d)} } { \partial Z^{(l,d)}} \cdot \frac{\partial L (Y,\hat{Y})}{ \partial X^{(l,d)} } \\= f'_l (Z^{(l,p)})  \odot \sum_{p=1}^{P}( rot180(W^{(l+1,p,d)} ) \tilde{\otimes  } \frac{\partial L(Y,\hat{Y})}{ \partial Z^{(+1,p)}})\\=  f'_l (Z^{(l,p)})  \odot \sum_{p=1}^{P}(rot180(W^{(l+1,p,d)} ) \tilde{\otimes  }\delta ^{(l+1,p)})</script><p>其中$\tilde{\otimes}$表示宽卷积。</p><h3 id="汇聚层-1"><a href="#汇聚层-1" class="headerlink" title="汇聚层"></a>汇聚层</h3><p>当第$l+1$层为汇聚层时, 因为汇聚层是下采样操作, $l+1$层的每个神经元的误差项 $\delta$对应于第$l$层的相应特征映射的一个区域。$l$层的第$p$个特征映射中的每个神经元都有一条边和$l+1$层的第$p$个特征映射中的一个神经元相连。</p><p>根据链式法则,第$l$层的一个特征映射的误差项$\delta ^{(l,p)}$，只需要将 $l+1$层对应特征映射的误差项$\delta ^{(l+1,p)}$进行上采样操作(和第 $l$层的大小一样) ,再和 $l$层特征映射的激活值偏导数逐元素相乘,就得到了 $\delta ^{ (l,p)}$</p><p>第 $l$层的第$p$个特征映射的误差项$\delta ^{(l,p)}$的具体推导过程如下(公式1.17)：</p><script type="math/tex; mode=display">\delta ^{(l,p)} \triangleq  \frac{\partial L (Y,\hat{Y})}{ \partial Z^{(l,p)} }\\=\frac{\partial X^{(l,p)} } { \partial Z^{(l,p)}} \cdot \frac{\partial Z^{(l+1,p)} } { \partial X^{(l,p)}} \cdot \frac{\partial L (Y,\hat{Y})}{ \partial Z^{(l+1,p)} }\\ = f'_l (Z^{(l,p)})  \odot up(\delta ^{(l+1,p)})</script><p>其中$f’_l$为第l层使用的激活函数导数，up为上采样函数(upsampling)，与汇聚层中使用的下采样函数刚好相反，如果下采样是最大汇聚（max pooling），误差项$\delta ^{(l+1,p)}$中每个值都会传递到上一层对应区域中的最大值所对应的神经元，该区域中其他位置的神经元的误差都设为0，如果下采样是平均汇聚(mean pooling) ,误差项 $\delta ^{(l+1,p)}$中每个值会被平均分配到上一层对应区域中的所有神经元上。</p><hr><h1 id="几种典型的卷积神经网络"><a href="#几种典型的卷积神经网络" class="headerlink" title="几种典型的卷积神经网络"></a>几种典型的卷积神经网络</h1><h2 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h2><p>LeNet-5 虽然提出的时间比较早（LeCun et al., 1998），但是一个非常成功的卷积神经网络模型，90年代在许多银行进行使用，用来识别手写数字，其网络结构如下：<br><img src="https://img-blog.csdnimg.cn/20190904141123853.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="LeNet-5"></p><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>AlexNet是第一个现代深度卷积网络模型，其首次使用了现在深度卷积网络的一些技巧，比如GPU并行训练，采用ReLU作为非线性激活函数，使用DropOut防止过拟合，使用数据增强来提高模型准确率。AlexNet获得了2012年ImageNet图像分类比赛的冠军，其网络结构如下：<br><img src="https://img-blog.csdnimg.cn/20190904141502612.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="AlexNet"></p><h2 id="Inception"><a href="#Inception" class="headerlink" title="Inception"></a>Inception</h2><p>在卷积网络中，如何定义一个卷积的大小是一个十分关键的问题，在Inception网络中，一个卷积层包含多个不同大小的卷积操作，称为Inception模块， Inception网络是由多个inception模块和汇聚层堆叠而成。</p><p>Inception模块同时使用1<em>1，3</em>3，5<em>5等大小不同的卷积核，并将得到的特征映射在深度上拼接（堆叠）起来作为输出特征映射。下图给出了v1版本的inception模块结构图，采用了4组平行的特征抽取方式，分别为1</em>1，3<em>3，5</em>5的卷积和3<em>3的最大汇聚，同时为了提高计算效率，减少参数数量，inception模块在进行3</em>3，5<em>5的卷积之前，3</em>3的最大汇聚之后，进行一次1*1的卷积来减少特征映射的深度。<br><img src="https://img-blog.csdnimg.cn/20190904142716385.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="v1版本的inception模块"></p><p>Inception网络最早的v1版本就是非常著名的GoogleNet，获得了2014年ImageNet图像分类竞赛的冠军。其结构图如下所示：<br><img src="https://img-blog.csdnimg.cn/20190904142927193.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="GoogleLeNet"></p><p>当然Inception网络有多个改进版本，比如Inception-v3网络，Inception-ResNet v2网络和改进版的Inception-v4模型。</p><h2 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h2><p>残差网络（Residual Network，ResNet）是通过给非先行的卷积层增加直连边的方式来提高信息的传播效率。</p><p>假设在一个深度网络中，我们期望一个非线性单元$f(x,\theta)$去逼近一个目标函数为h(x)。如果将目标函数拆分为两部分：恒等函数（Identity）和残差函数（Reside Function）h(x)-x。</p><script type="math/tex; mode=display">h(x) = \underset{IdentityFunc}{\underbrace{x}} +( \underset{ResidueFunc}{\underbrace{h(x)-x}})</script><p>根据通用近似定理，一个由神经网络构成的非线性单元有足够的能力来近似逼近原始目标函数或残差函数，但实际中后者更容易血虚。因此原来的优化问题可以转化为：让非线性单元$f(x,\theta)$去近似残差h(x)-x,并用$f(x,\theta) +x$去逼近h(x)。</p><p>下图给出了一个典型的残差单元示例，残差单元由多个级联的（等长）卷积层和一个跨层的直连边组成，再经过ReLU激活后得到输出。残差网络就是将很多个残差单元串联起来构成的一个非常深的网络。<br><img src="https://img-blog.csdnimg.cn/20190904144622317.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="残差单元示例"></p><hr><h1 id="其他卷积方式"><a href="#其他卷积方式" class="headerlink" title="其他卷积方式"></a>其他卷积方式</h1><h2 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h2><p>我们一般通过卷积操作来实战高维特征到低维特征的转换，但在一些任务中需要把低维特征映射到高维特征，并且希望通过卷积操作来实现。</p><p>卷积操作可以通过仿射变换的形式。假设一个5维的向量x，经过大小为3的卷积核w=[w1,w2,w2]^T来进行卷积，得到3维向量z，卷积操作可以写为：</p><p><img src="https://img-blog.csdnimg.cn/20190904154849239.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="5维向量x与大小为3的卷积核进行卷积"></p><p>其中C是一个稀疏矩阵，其非零元素来自于卷积核w中的元素。如果实现3维向量z到5维向量x的映射，可以通过仿射矩阵转置来实现。</p><p><img src="https://img-blog.csdnimg.cn/20190904155151517.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="仿射矩阵转置"></p><p>其中rot180(.)表示旋转180度。</p><blockquote><p>我们将低维特征映射到高维特征的卷积操作称之为转置卷积（Transposed Convolution），也叫反转卷积（Deconvolution）。</p></blockquote><h2 id="空洞卷积"><a href="#空洞卷积" class="headerlink" title="空洞卷积"></a>空洞卷积</h2><p>对于一个卷积层，如果希望增加输出单元的感受野，一般可以通过三种方式实现：</p><ul><li>增加卷积核的大小</li><li>增加层数</li><li>在卷积之前进行汇聚操作</li></ul><p>前两种会增加参数数量，最后一种会丢失一些信息。</p><p>空洞卷积（Atrous Convolution）也成为膨胀卷积（Dilated Convolution），是一种不增加参数数量，同时增加输出单元感受野的一种方法。</p><p>空洞卷积通过给卷积核插入“空洞”来变相的增加其大小，如果在卷积核的每两个元素之间插入d-1个空洞，卷积核的有效大小维：<br>$m’=m+ (m-1) * (d-1)$<br>其中d称为膨胀率（Dilation Rate）。当d=1时卷积核维普通的卷积核。<br><img src="https://img-blog.csdnimg.cn/20190904160154440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="不同膨胀率的卷积核"></p><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2019090518010966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6
      
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="神经网络" scheme="http://thinkgamer.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>【论文】RecSys18-序列推荐模型TransFM(Translation-based Factorization Machines for Sequential Recommendation)</title>
    <link href="http://thinkgamer.cn/2019/08/31/%E8%AE%BA%E6%96%87/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91RecSys18-%E5%BA%8F%E5%88%97%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8BTransFM(Translation-based%20Factorization%20Machines%20for%20Sequential%20Recommendation)/"/>
    <id>http://thinkgamer.cn/2019/08/31/论文/【论文】RecSys18-序列推荐模型TransFM(Translation-based Factorization Machines for Sequential Recommendation)/</id>
    <published>2019-08-31T01:14:39.000Z</published>
    <updated>2019-11-14T02:26:37.481Z</updated>
    
    <content type="html"><![CDATA[<p>序列推荐模型 Translation-based Recommendation，参考：<a href="https://thinkgamer.blog.csdn.net/article/details/100129827" target="_blank" rel="external">点击阅读</a></p><a id="more"></a><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>论文是由Rajiv Pasricha和Julian McAuley两位大佬提出的发表在RecSys18 上的，是TransRec和FM的结合版本（论文下载地址：<a href="https://cseweb.ucsd.edu/~jmcauley/pdfs/recsys18a.pdf）。在下面会简单介绍TransRec和FM。" target="_blank" rel="external">https://cseweb.ucsd.edu/~jmcauley/pdfs/recsys18a.pdf）。在下面会简单介绍TransRec和FM。</a></p><p>对于电商网站（如亚马逊），媒体网站（如Netflix，Youtube）等而言，推荐系统是其中至关重要的一环。传统的推荐方法尝试对用户和物品的全局交互进行建模。例如矩阵分解和其派生模型，虽然能够有效的捕获到用户的偏好，但是未考虑到时序特征，其忽略了用户的最近交互行为，提供了一个静态的推荐列表。</p><p>序列推荐的目的是基于用户的历史行为序列去预测用户将来的行为。Julian McAuley作为主要作者的另一篇论文（Translation-based Recommendation）提出了“翻译”空间的概念，将物品作为一个点嵌入到“翻译”空间内，用户的序列行为则作为一个翻译向量存在于该空间，然后通过距离计算便根据用户u的当前行为物品i，预测其接下来可能有行为的物品，具体可参考：<a href="https://mp.weixin.qq.com/s/YovZKGd2BDqnpW5BBGLA-A。TransRec的主要思路如下图所示：" target="_blank" rel="external">https://mp.weixin.qq.com/s/YovZKGd2BDqnpW5BBGLA-A。TransRec的主要思路如下图所示：</a></p><center><img src="https://img-blog.csdnimg.cn/20190831085905828.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="500px"></center><p>本论文中提出了TransFM，其结合了FM和TransRec的思想，将其应用在序列推荐中，这样做的好处是使用简单的模型对复杂的交互之间进行建模并能取得不错的效果。</p><blockquote><p>FM能够对任意的实值特征向量进行操作，并通过参数分解对特征之间的高阶交互进行建模。他可以应用在一般的预测任务里，并可以通过特征替换，取代常见的推荐算法模型。</p></blockquote><p>TransFM的主要思路如下图所示：</p><center><img src="https://img-blog.csdnimg.cn/20190831085920392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="500px"></center><p>TransFM是对所有观察到的行为之间可能的交互进行建模，对于每一个特征i，模型学习到两部分：一个低维的embedding向量$\overrightarrow{v_i}$和一个翻译向量$\overrightarrow{v_i’}$</p><p>特征之间的交互强度使用平方欧几里德距离来进行计算，在上图中，展示了user，item，time的embedding特征和翻译向量，交互行为之间的权重由起始点和结束点之间的平方欧几里德距离进行计算。与FM一样，TransFM可以在参数和特征纬度的线性时间内进行计算，从而有效的实现大规模数据集的计算。</p><h1 id="相关研究"><a href="#相关研究" class="headerlink" title="相关研究"></a>相关研究</h1><h2 id="序列推荐"><a href="#序列推荐" class="headerlink" title="序列推荐"></a>序列推荐</h2><p>已经存在了许多基于MC（马尔可夫链，Markov Chains）的序列推荐模型，比如FPMC（Factorized Personalized Markov Chains），使用独立分解矩阵对三阶交互行为进行分解，继而来模拟成对的相互作用。PRME使用欧几里德距离替换内积对用户-物品之间的交互行为进行建模。TransRec同样也是一个序列推荐模型，通过共享物品的embedding向量空间，将用户行为转化为翻译向量，其计算公式如下：</p><center><img src="https://img-blog.csdnimg.cn/20190831085937428.png" width="200px"></center>这些对于给定的用户历史行为序列十分有效，但是在不改变模型结构的前提下，并不能捕获时间，地理和其他的上下文特征。## 因子分解机FM对于任意的机器学习任务来讲是一个通用的学习框架，他模型任意任意特征之间的二阶交互，并很容易扩招到更高阶，每个特征的交互通过参数之间的内积来权衡。其公式如下（这里讨论的是FM的二阶形式）：<center><img src="https://img-blog.csdnimg.cn/20190831085947201.png" width="200px"></center>通过选择合适的损失函数，FM可以应用在任意的分类，回归或者排序任务中，在这篇文章里主要是针对隐式反馈结合BPR算法框架去优化预测的结果。## 混合推荐混合推荐结合了协同和conetnt-based，目的在于提升效果并且为行为很较少的用户提供有效的选择，在一定程度上缓解了用户冷启动。这里可以利用的潜在的信息包括：时间特征，地理特征，社交特征等。最近的一些关于混合推荐的工作结合了图像特征，或者是使用深度学习自动生成有用的内容特征。虽然这些方法都取得了不错的表现，但依赖于专门的模型和技术。相比之间，论文里提出的TransFM是一种更广义的办法，可以对任意的特征向量和预测任务进行操作，通过适当的特征工程，TransFM模型可以结合时间，地理，人口统计和其他内容特征，而无需更改模型本身结构。# TransFM模型## 问题定义<center><img src="https://img-blog.csdnimg.cn/20190831085958369.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="500px"></center><p>TransFM使用平方欧几里德距离替换FM中的内积计算，并用embedding 向量和翻译向量之和表示特征v_i的向量，其公式如下：</p><center><img src="https://img-blog.csdnimg.cn/20190831090026658.png" width="300px"></center>其中距离计算方式为：<center><img src="https://img-blog.csdnimg.cn/20190831090035517.png" width="230px"></center><p>使用平方欧几里德距离替换内积的好处是：提高模型的泛化能力，更有效的捕获embedding之间的传递性。比如(a,b)，(b,c)之间有很高的交互权重，那么(a,c)之间的相关性也会更强。</p><p>下图展示了TransFM和其他几种算法的预测方法，从中可以看出PRME学习的是两个用户的embedding向量之间的距离，FM学习的是任意特征与相应参数之间的内积，TransRec学习的是物品的embedding向量和用户行为的翻译序列，TransFM学习的是每个特征的embedding向量和翻译向量，使用平方欧几里德距离去度量特征之间的交互。</p><center><img src="https://img-blog.csdnimg.cn/20190831090058665.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="500px"></center>## 模型计算FM是可以将计算复杂度降低到nk的，同样TransFM也可以降低其计算负责度。首先：<center><img src="https://img-blog.csdnimg.cn/20190831090139230.png" width="300px"></center><p>其次进行化简得：</p><center><img src="https://img-blog.csdnimg.cn/20190831090151717.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="400px"></center><p>上面的第一个总和可以分成六个单独项，每一项又可以继续进行化简：</p><center><img src="https://img-blog.csdnimg.cn/20190831090204314.png" width="300px"></center><p>假设输入的特征是n维，隐向量长度为k，那么时间复杂度就是O(nk)，而不是O(n^2k)。</p><h2 id="参数优化"><a href="#参数优化" class="headerlink" title="参数优化"></a>参数优化</h2><p>模型使用S-BPR（Sequential Bayesian Personalized Ranking）进行优化，其优化方式如下：</p><center><img src="https://img-blog.csdnimg.cn/20190831090239744.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="350px"></center>其中Ω(Θ)为L2正则。## 实践和推断作者等人在TensorFlow中对TransFM进行了实现，用的是mini-batch gradient descent 和 Adam进行模型的训练（adam对于有大量参数且稀疏的数据集上表现良好）。作者这里也罢代码进行了开源，包括数据集，已经不同算法实现实现对比，其地址为：https://github.com/rpasricha/TransFM# 实验作者结合了一些算法在亚马逊和谷歌数据集上进行测试，其中评价的指标是AUC，效果如下：<center><img src="https://img-blog.csdnimg.cn/20190831090454914.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="500px"></center><center><img src="https://img-blog.csdnimg.cn/20190831090503108.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="350px"></center><p>上边的Table 3是指从Amazon选取top5 品类 ，从Google Local 中选取6个城市作为实验依据。</p><h1 id="FM模型和其他模型的融合"><a href="#FM模型和其他模型的融合" class="headerlink" title="FM模型和其他模型的融合"></a>FM模型和其他模型的融合</h1><p>PRME（Personalized Ranking Metric Embedding）</p><center><img src="https://img-blog.csdnimg.cn/2019083109063261.png" width="300px"></center><blockquote><p>和TransFM对比的不同在于TransFM中i的向量是embedding向量和translation向量和，而这里没有translation向量。实时证明TransFM效果要好很多。</p></blockquote><p>HRM（Hierarchical Representation Model ）</p><center><img src="https://img-blog.csdnimg.cn/20190831090640757.png" width="300px"></center><p>对比的实验结果如下：</p><center><img src="https://img-blog.csdnimg.cn/20190831090647827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="500px"></center><h1 id="我的总结"><a href="#我的总结" class="headerlink" title="我的总结"></a>我的总结</h1><ol><li>TransFM结合了TransRec 和 FM和优势，在大量，稀疏的数据集上取得了不错的效果。</li><li>在参数和特征纬度下，计算时间线性增大（nk）</li><li>改变FM中的内积计算方式，使用平方欧几里德距离，提高了模型的泛化能力，和样本特征之间的传递性</li><li>在不改变模型结构的前提下，可以轻易将时间，地域或者其他内容特征加入到模型中</li><li>数据集拆分时避免了从整体数据集中的随机拆分，而是按照时间先后的顺序进行拆分。保证了一定的时间连续性，很多论文中划分训练集和测试集时都是这样做的，在工业界中模型的训练和评估大部分也是这样做的。</li><li>根据经验将参数限定在一个范围内，根据网格搜索法寻找最佳参数</li><li>实验对比的丰富性，使结论更具有说服力</li></ol><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;序列推荐模型 Translation-based Recommendation，参考：&lt;a href=&quot;https://thinkgamer.blog.csdn.net/article/details/100129827&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;点击阅读&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="论文" scheme="http://thinkgamer.cn/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="TransFM" scheme="http://thinkgamer.cn/tags/TransFM/"/>
    
  </entry>
  
  <entry>
    <title>【论文】RecSys17-序列推荐模型 Translation-based Recommendation</title>
    <link href="http://thinkgamer.cn/2019/08/29/%E8%AE%BA%E6%96%87/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91RecSys17-%E5%BA%8F%E5%88%97%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%20Translation-based%20Recommendation/"/>
    <id>http://thinkgamer.cn/2019/08/29/论文/【论文】RecSys17-序列推荐模型 Translation-based Recommendation/</id>
    <published>2019-08-29T00:19:12.000Z</published>
    <updated>2019-10-14T06:42:35.690Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>序列推荐模型 TransFM（Translation-based Factorization Machines for Sequential Recommendation）参考：<a href="https://thinkgamer.blog.csdn.net/article/details/100168818" target="_blank" rel="external">点击阅读</a></p></blockquote><a id="more"></a><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>这篇论文是由 Ruining He，Wang-Cheng Kang和Julian McAuley三位大佬提出的，在2017年的ACM推荐系统会议（RecSys’17）上获得了最佳论文奖（在大佬主页可以下载该论文中涉及的代码和数据集，可惜代码是C++写的，不懂C++的童鞋挑战性很大～）</p><ul><li>第一作者的Ruining He主页为<a href="https://sites.google.com/view/ruining-he/" target="_blank" rel="external">https://sites.google.com/view/ruining-he/</a></li><li>RecSys历届最佳论文地址：<a href="https://recsys.acm.org/best-papers/" target="_blank" rel="external">https://recsys.acm.org/best-papers/</a></li><li>本论文下载地址：<a href="https://arxiv.org/pdf/1707.02410.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1707.02410.pdf</a></li></ul><p>论文的两个研究点：</p><ul><li>用户的序列推荐（用户在浏览了一些items之后给他推荐物品j）</li><li>物品到物品的推荐（用户购买了一个牛仔裤，给他推荐一个衬衫）</li></ul><hr><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>对用户和物品以及物品和物品之间的关系进行建模是设计一个成功推荐系统的核心。一种经典的做法是预测用户行为序列（或者是下一个物品的推荐），其挑战在于对用户，用户历史行为物品和用户接下来有行为的物品之间的三阶交互关系进行建模。现有的方法是对这些高阶的交互分解为成对的关系组合，通过不同的模型去对用户的偏好（用户和物品的交互）和序列匹配（物品和物品的交互）进行建模。</p><p>比如MF（Matrix Factorization，矩阵分解）只对用户和物品之间的交互行为进行建模；MC（Markov Chain，马尔可夫链）只对用交互过程中的物品对进行建模，通常通过对转移矩阵进行分解提高其泛化能力。</p><p>对于序列推荐，研究者提出了可扩展的张量分解方法，比如FPMC（Factorized Personalized Markov Chains），FPMC通过两个成对的交互关系来模拟u，i，j之间的三阶交互关系，其实这就是MF和MC的结合。对于提升FPMC有两个方向的研究思路，一个思路是在个性化度量嵌入方法用欧几里德距离替换FPMC中的内积，其中度量假设尤其是三角不等式使模型的泛化性更好，然而，这些研究工作采用的仍然是对用户偏好和序列的连续性分别建模的框架，由于这两部分本身存在关系，因此这样做是存在一定的问题的。另一个思路是利用平均/最大池化等操作去聚合用户u和前一项i的向量表示，然后再测量它们与下一个项j的相似度，这种思路虽然部分解决了两个组件之间的相互依赖问题，但很难解释而且不能从度量embedding向量中获得收益。</p><p>为了解决上述存在的问题，提出了Translation-based Recommendation模型，具体解释往下看。</p><hr><h1 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h1><h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>涉及的相关字符含义如下图所示：</p><center><img src="https://img-blog.csdnimg.cn/20190829080844419.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="400px"></center><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>TransRec的主要思路如下图：</p><center><img src="https://img-blog.csdnimg.cn/20190829080909516.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="400px"></center><p>物品作为一个点被嵌入到翻译空间内，用户的序列行为则作为一个翻译向量存在于该空间，然后，通过个性化翻译操作捕获前面提到的三阶交互，其基本思路就是用户的翻译向量和上一个行为物品的翻译向量之和，确定下一个有行为的物品j，如下所示</p><script type="math/tex; mode=display">\underset{ \gamma _i }{\rightarrow} + \underset{t_u}{\rightarrow}  \approx  \underset{ \gamma _j }{\rightarrow}</script><p>其中距离的计算可以采用L1-distance或者L2-distance。<br>由于生产环境中数据的稀疏性，很难为每个用户学习到一个向量，因此添加了一个全局翻译向量来初始化所有的用户，这样也能够有效的缓解用户冷启动。如下所示</p><script type="math/tex; mode=display">\underset{ T_u }{\rightarrow} = \underset{t}{\rightarrow}  + \underset{ t_u }{\rightarrow}</script><p>在一个生产系统中，往往会存在头部物品（即热门物品），这些物品的流行度很高，那么如果仅仅采用简单的距离计算的话，那些头部物品就很可能出现在每个用户的推荐结果中。因此在计算时增加了一个偏置项beta_j来对热门物品进行降权。最终对于给定的用户u和之前的行为物品i可以由以下的计算公式为其推荐物品j。</p><center><img src="https://img-blog.csdnimg.cn/20190829080953218.png" width="200px"></center>物品j的热度越高，则beta_j越小，这样当两个物品计算出来的距离一致时，倾向于推荐那些热度小的物品，这样也能够在一定程度上提高推荐物品的多样性。***这里有一点需要注意的是：为了避免“维度诅咒”问题，将r_j限定在整个翻译空间的一个子集上，例如一个单位球体的空间范围。***对于给定过的用户和历史行为序列，模型的目标是对集合中的物品进行排序，这里采用的是pairwise方法的S-BPR（Sequential Bayesian Personalized Ranking）。其优化的公式如下：<center><img src="https://img-blog.csdnimg.cn/20190829081100913.png" width="300px"></center>其中j是真实的下一个交互的物品，j'是除j之外的集合中的任意一个物品。omega为L2正则项。## 参数学习物品i和用户对应的全局翻译向量随机初始化为单元向量，每个物品的偏置向量和每个用户的翻译向量初始化为0。目标函数通过随机梯度上升进行优化，随机从集合中抽取用户u，正例j和负例j'，通过下面的计算公式进行迭代：<center><img src="https://img-blog.csdnimg.cn/20190829081139397.png" width="300px"></center>其中ε为学习率，λ为正则项参数。重复该公式，直到收敛或者效果达到最优或者达到最大迭代次数。## 最近邻查找在测试时，可以通过最近邻搜索进行推荐，一个小的挑战就是物品的偏差。这里分为两部分去解决这个问题。第一使用：$$\beta _j ' \leftarrow  \beta _j - max_{k\in I}\beta _k$$ 表示$\beta _j$对偏置项进行转换，不会改变计算结果的排序。第二使用L2范数计算$$\overrightarrow{\gamma _j}' = (\overrightarrow{\gamma _j}';\sqrt{-\beta _j'})$$或者使用L1范数计算$$\overrightarrow{\gamma _j}' = (\overrightarrow{\gamma _j}';-\beta _j')$$实验证明L2范数效果更好。对于给定的用户u和物品i，在整个向量空间内为其计算寻找最近的$\overrightarrow{\gamma _j}'$---# 实验为了充分验证TransRec的优势，使用了大量的公开数据集，如下图所示：<center><img src="https://img-blog.csdnimg.cn/20190829081637879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="400px"></center><p>在算法选择上以PopRec为baseline，BPR-MF，FMC，FPMC，PRME，HRM作为对比算法模型，在上表中的数据集上对比实验如下：</p><center><img src="https://img-blog.csdnimg.cn/2019082908164614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="400px"></center><p>在进行实验寻找最佳参数时，使用的是网格搜索法，使用随机提督上升优化模型的学习率为0.05，正则项参数的测试范围是：{0, 0.001, 0.01, 0.1, 1}。在TransRec中尝试了L2-ball 和 L2-sphere计算距离，L2-ball的效果更好一些。</p><p>在最开始我们提到本论文主要有两点<br>用户的序列推荐（用户在浏览了一些items之后给他推荐物品j）<br>物品到物品的推荐（用户购买了一个牛仔裤，给他推荐一个衬衫）</p><p>在TransRec中，通过删除个性化向量部分，TransRec可以直接进行物品到物品的推荐，这和知识图谱中的推荐有点相似，因为需要对不同项之间的关系进行建模。其中实现的结果类似于下图这样。</p><center><img src="https://img-blog.csdnimg.cn/20190829081659946.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="400px"></center><p>同样也对该部分进行了单独的实验，采用的数据集，对比的算法和实验的结论如下：</p><center><img src="https://img-blog.csdnimg.cn/20190829081707975.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="400px"></center><hr><h1 id="我的总结"><a href="#我的总结" class="headerlink" title="我的总结"></a>我的总结</h1><ol><li>文章中介绍了TransRec的优势<br>（1）只用一个模型来模拟用户，物品之间的三阶交互<br>（2）可以从隐式假设度量中获益<br>（3）轻易的解决数据量大的问题</li><li>论文中不仅提出了使用一个模型来对用户物品之间的三阶关系进行建模，还借鉴知识图谱中的思想提出了物品道物品之间的推荐。</li><li>文中实验时将数据集拆分成了三部分，训练集，验证集，和测试集。其比例为8:1:1。</li><li>数据集拆分时避免了从整体数据集中的随机拆分，而是按照时间先后的顺序进行拆分。保证了一定的时间连续性，这一点值得借鉴。</li><li>在寻找最佳参数时使用的是网格搜索法。</li><li>用户的翻译向量采用了全局翻译向量和个性化的翻译向量之和。一定程度上解决了用户的冷启动。</li><li>样本偏置项，减小物品本身热度对模型的影响。</li><li>为了避免“维度诅咒”问题，将样本限定在整体样本空间的一个子集上。</li><li>基于TransRec的思路，作者又提出了和FM的结合，其论文是Translation-based Factorization Machines for Sequential Recommendation，接下来会对其进行介绍。</li></ol><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;序列推荐模型 TransFM（Translation-based Factorization Machines for Sequential Recommendation）参考：&lt;a href=&quot;https://thinkgamer.blog.csdn.net/article/details/100168818&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;点击阅读&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="论文" scheme="http://thinkgamer.cn/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="TransRec" scheme="http://thinkgamer.cn/tags/TransRec/"/>
    
  </entry>
  
  <entry>
    <title>Spark排序算法系列之ALS模型实现</title>
    <link href="http://thinkgamer.cn/2019/08/13/RecSys/Spark%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/Spark%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%E4%B9%8BALS%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/"/>
    <id>http://thinkgamer.cn/2019/08/13/RecSys/Spark排序算法/Spark排序算法系列之ALS模型实现/</id>
    <published>2019-08-13T06:27:45.000Z</published>
    <updated>2019-10-14T06:42:35.663Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在上一篇文章中介绍了ALS算法的原理（<a href="https://blog.csdn.net/Gamer_gyt/article/details/98897829" target="_blank" rel="external">点击阅读</a>），在这篇文章中主要介绍一下ALS算法在Spark中的实现。</p></blockquote><a id="more"></a><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>协同过滤(Collaborative Filtering)在推荐系统中应用的非常广，该算法的目标是去填充用户-物品评分矩阵中的缺失值，即未评分。该算法的Spark的ML包和MLlib包中均有实现。</p><p>其中涉及的参数如下：</p><ul><li>numBlocks：数据分区的数目，默认为10</li><li>rank：隐向量的长度，默认是10（m <em> n =&gt; m </em> k - k * n）</li><li>maxIter：最大迭代次数，默认为10</li><li>regParam：正则化参数系数，默认为1.0</li><li>implicitPrefs：控制使用显式反馈还是隐式反馈，默认是false即显式反馈。</li><li>alpha：隐式反馈时的置信度参数，默认为1.0</li><li>nonnegative：是否对最小二乘使用非负约束，默认为false</li></ul><h3 id="隐式反馈与显式反馈"><a href="#隐式反馈与显式反馈" class="headerlink" title="隐式反馈与显式反馈"></a>隐式反馈与显式反馈</h3><p>基于矩阵分解的协同过滤标准方法将用户-物品矩阵中的rate视为用户对项目给出的显式偏好，例如：用户对电影进行评分。</p><p>在许多实际的用例中，通常只能获取隐式反馈数据（例如：观看，点击，购买，喜欢，分享等）。spark.ml中用于处理此类数据的方法取自Collaborative Filtering for Implicit Feedback Datasets。本质上，这种方法不是试图直接对评级矩阵进行建模，而是将数据视为表示用户操作观察强度的数字（例如点击次数或某人花在观看电影上的累积持续时间）。然后，这些数字与观察到的用户偏好的置信水平相关，而不是与项目的明确评级相关。然后，该模型试图找到可用于预测用户对项目的预期偏好的潜在因素。</p><h3 id="正则化参数"><a href="#正则化参数" class="headerlink" title="正则化参数"></a>正则化参数</h3><p>通过用户-物品的评分矩阵中用户的评分物品数和物品收到的评分个数来作为正则项，解决最小二乘更新过程中的问题。 这种方法被命名为“ALS-WR”，可以参考论文： Collaborative Filtering for Implicit Feedback Datasets。它减小来regParam对数据集规模的依赖，因此我们可以将从采样子集中学习的最佳参数应用于完整数据集，并获得较好的结果。</p><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>Spark ALS算法支持输出item 或者user的隐向量，据此我们可以计算出用户或者物品的相似度，继而进行排序得到用户或者item的top N相似user或者item。这样在数据进行召回时便可以进行召回了。</p><p>比如根据用户用行为的物品召回，当用户浏览了若干了item时，便将这些item相似的item加入到召回池中，进行rank排序。</p><h3 id="ML中的ALS实现"><a href="#ML中的ALS实现" class="headerlink" title="ML中的ALS实现"></a>ML中的ALS实现</h3><figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">object ALSML &#123;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">def main(args</span>: Array[String]): Unit = &#123;</span><br><span class="line">        val spark = SparkSession<span class="variable">.builder</span>()<span class="variable">.master</span>("local[5]")<span class="variable">.appName</span>("ALSML")<span class="variable">.enableHiveSupport</span>()<span class="variable">.getOrCreate</span>()</span><br><span class="line">        Logger<span class="variable">.getRootLogger</span><span class="variable">.setLevel</span>(Level<span class="variable">.WARN</span>)</span><br><span class="line"></span><br><span class="line">        val input = "data/sample_movielens_ratings<span class="variable">.txt</span>"</span><br><span class="line">        val model_param = "maxIters:10,rank:5,numBlocks:10,regParam:0.01,alpha:0.618,userCol:userId,itemCol:movieId,rateCol:rating,implicitPrefs:true"</span><br><span class="line">        val output_model = "model/als_ml"</span><br><span class="line">        // 训练模型 找到合适的参数</span><br><span class="line">        runBasedML(spark,input,model_param,output_model)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    def runBasedML(spark: SparkSession, input: String, param: String,output_model_path: String) = &#123;</span><br><span class="line">        import spark<span class="variable">.sqlContext</span><span class="variable">.implicits</span><span class="variable">._</span></span><br><span class="line">        val ratings = spark<span class="variable">.read</span><span class="variable">.textFile</span>(input)<span class="variable">.map</span>(parseRating)<span class="variable">.toDF</span>()</span><br><span class="line">        val Array(training, test) = ratings<span class="variable">.randomSplit</span>(Array(0.8, 0.2))</span><br><span class="line"></span><br><span class="line">        println("创建并训练ALS模型 ...")</span><br><span class="line">        val als = ALSMLUtil<span class="variable">.createModel</span>(param)</span><br><span class="line">        val model = als<span class="variable">.fit</span>(training)</span><br><span class="line">        println("模型的效果评估 ...")</span><br><span class="line">        ALSMLUtil<span class="variable">.evaluateModel</span>(model, test)</span><br><span class="line"></span><br><span class="line">        println("为用户进行item推荐 ...")</span><br><span class="line">        model<span class="variable">.recommendForAllUsers</span>(10)<span class="variable">.show</span>(10)</span><br><span class="line"></span><br><span class="line">        println("为指定用户进行top N item推荐 ...")</span><br><span class="line">        val users = ratings<span class="variable">.select</span>(als<span class="variable">.getUserCol</span>)<span class="variable">.distinct</span>()<span class="variable">.limit</span>(3)</span><br><span class="line">        model<span class="variable">.recommendForUserSubset</span>(users,10)<span class="variable">.show</span>(10)</span><br><span class="line"></span><br><span class="line">        println("为item进行用户推荐 ...")</span><br><span class="line">        model<span class="variable">.recommendForAllItems</span>(10)<span class="variable">.show</span>(10)</span><br><span class="line">        println("为指定的item进行top N 用户推荐 ...")</span><br><span class="line">        val movies = ratings<span class="variable">.select</span>(als<span class="variable">.getItemCol</span>)<span class="variable">.distinct</span>()<span class="variable">.limit</span>(3)</span><br><span class="line">        model<span class="variable">.recommendForItemSubset</span>(movies, 10)<span class="variable">.show</span>(10)</span><br><span class="line"></span><br><span class="line">        println("输出隐向量 ...")</span><br><span class="line">        model<span class="variable">.itemFactors</span><span class="variable">.rdd</span><span class="variable">.map</span>(f =&gt; (f<span class="variable">.get</span>(0), f<span class="variable">.getList</span>(1)<span class="variable">.toArray</span><span class="variable">.mkString</span>(",")))<span class="variable">.take</span>(10)<span class="variable">.foreach</span>(println)</span><br><span class="line"></span><br><span class="line">        println("保存与加载模型 ...")</span><br><span class="line">        model<span class="variable">.write</span><span class="variable">.overwrite</span>()<span class="variable">.save</span>(output_model_path)</span><br><span class="line">        val newModel = ALSModel<span class="variable">.load</span>(output_model_path)</span><br><span class="line">        newModel<span class="variable">.itemFactors</span><span class="variable">.rdd</span><span class="variable">.map</span>(f =&gt; (f<span class="variable">.get</span>(0), f<span class="variable">.getList</span>(1)<span class="variable">.toArray</span><span class="variable">.mkString</span>(",")))<span class="variable">.take</span>(10)<span class="variable">.foreach</span>(println)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    def parseRating(str: String): Rating = &#123;</span><br><span class="line">        val fields = str<span class="variable">.split</span>("::")</span><br><span class="line">        assert(fields<span class="variable">.size</span> == 4)</span><br><span class="line">        Rating(fields(0)<span class="variable">.toInt</span>, fields(1)<span class="variable">.toInt</span>, fields(2)<span class="variable">.toFloat</span>, fields(3)<span class="variable">.toLong</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    case class Rating(userId: Int, movieId: Int, rating: Float, timestamp: Long)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="MLlib中的ALS实现"><a href="#MLlib中的ALS实现" class="headerlink" title="MLlib中的ALS实现"></a>MLlib中的ALS实现</h3><figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">object ALSMLlib &#123;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">def main(args</span>: Array[String]): Unit = &#123;</span><br><span class="line">        val spark = SparkSession<span class="variable">.builder</span>()<span class="variable">.master</span>("local[5]")<span class="variable">.appName</span>("ALS")<span class="variable">.enableHiveSupport</span>()<span class="variable">.getOrCreate</span>()</span><br><span class="line">        Logger<span class="variable">.getRootLogger</span><span class="variable">.setLevel</span>(Level<span class="variable">.WARN</span>)</span><br><span class="line"></span><br><span class="line">        val input = "data/sample_movielens_ratings<span class="variable">.txt</span>"</span><br><span class="line">        val model_param = "maxIters:10,rank:5,numBlocks:10,regParam:0.01,alpha:0.618,implicitPrefs:true"</span><br><span class="line">        val output_model_path = "model/als_ml"</span><br><span class="line"></span><br><span class="line">        run(spark, input, model_param, output_model_path)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    def run(spark: SparkSession, input: String, model_param: String, output_model_path: String): Unit = &#123;</span><br><span class="line">        println("加载数据 ...")</span><br><span class="line">        val ratings = spark<span class="variable">.sparkContext</span><span class="variable">.textFile</span>(input)</span><br><span class="line">            <span class="variable">.map</span>(_<span class="variable">.split</span>("::")<span class="variable">.slice</span>(0,3) match &#123; case Array(userId, movieId, rating)  =&gt;</span><br><span class="line">                Rating(userId<span class="variable">.toString</span><span class="variable">.toInt</span>, movieId<span class="variable">.toString</span><span class="variable">.toInt</span>, rating<span class="variable">.toString</span><span class="variable">.toDouble</span>)</span><br><span class="line">            &#125;)</span><br><span class="line">        println("训练模型 ...")</span><br><span class="line">        val param = new ALSMLlibParam()</span><br><span class="line">        param<span class="variable">.parseString</span>(model_param)</span><br><span class="line">        val model = ALS<span class="variable">.train</span>(ratings,param<span class="variable">.getRank</span>, param<span class="variable">.getMaxIters</span>,param<span class="variable">.getAlpha</span>,param<span class="variable">.getNumBlocks</span>)</span><br><span class="line"></span><br><span class="line">        println("评估模型 ...")</span><br><span class="line">        val usersProducts = ratings<span class="variable">.map</span> &#123; case Rating(user, product, rate) =&gt; (user, product) &#125;</span><br><span class="line">        val predictions = model<span class="variable">.predict</span>(usersProducts)<span class="variable">.map</span>&#123; case Rating(user, product, rate) =&gt; ((user,product),rate)&#125;</span><br><span class="line">        val rateAndPre = ratings<span class="variable">.map</span> &#123; case Rating(user, product, rate) =&gt; ((user, product), rate) &#125;<span class="variable">.join</span>(predictions)</span><br><span class="line">        val MSE = rateAndPre<span class="variable">.map</span> &#123; case ((user, product), (r1, r2)) =&gt;</span><br><span class="line">            val err = (r1 - r2)</span><br><span class="line">            err * err</span><br><span class="line">        &#125;<span class="variable">.mean</span>()</span><br><span class="line">        println("Mean Squared Error = " + MSE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        println(s"用户（2）对 物品（2）的预测评分为：$&#123;model<span class="variable">.predict</span>(2,2)&#125;")</span><br><span class="line">        println("用户纬度的特征向量为：")</span><br><span class="line">        model<span class="variable">.userFeatures</span><span class="variable">.map</span>(f =&gt; (f<span class="variable">._</span>1,f<span class="variable">._</span>2<span class="variable">.mkString</span>(",")))<span class="variable">.take</span>(10)<span class="variable">.foreach</span>(println)</span><br><span class="line">        println("物品纬度的特征向量为：")</span><br><span class="line">        model<span class="variable">.productFeatures</span><span class="variable">.map</span>(f =&gt; (f<span class="variable">._</span>1,f<span class="variable">._</span>2<span class="variable">.mkString</span>(",")))<span class="variable">.take</span>(10)<span class="variable">.foreach</span>(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.scheduler</span><span class="selector-class">.DAGSchedulerEventProcessLoop</span><span class="selector-class">.onReceive</span>(DAGScheduler<span class="selector-class">.scala</span>:<span class="number">1821</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.scheduler</span><span class="selector-class">.DAGSchedulerEventProcessLoop</span><span class="selector-class">.onReceive</span>(DAGScheduler<span class="selector-class">.scala</span>:<span class="number">1810</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.util</span><span class="selector-class">.EventLoop</span>$<span class="variable">$anon</span>$<span class="number">1</span>.run(EventLoop<span class="selector-class">.scala</span>:<span class="number">48</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.scheduler</span><span class="selector-class">.DAGScheduler</span><span class="selector-class">.runJob</span>(DAGScheduler<span class="selector-class">.scala</span>:<span class="number">642</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.SparkContext</span><span class="selector-class">.runJob</span>(SparkContext<span class="selector-class">.scala</span>:<span class="number">2034</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.SparkContext</span><span class="selector-class">.runJob</span>(SparkContext<span class="selector-class">.scala</span>:<span class="number">2055</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.SparkContext</span><span class="selector-class">.runJob</span>(SparkContext<span class="selector-class">.scala</span>:<span class="number">2074</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rdd</span><span class="selector-class">.RDD</span>$<span class="variable">$anonfun</span><span class="variable">$take</span>$<span class="number">1</span>.apply(RDD<span class="selector-class">.scala</span>:<span class="number">1364</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rdd</span><span class="selector-class">.RDDOperationScope</span>$.withScope(RDDOperationScope<span class="selector-class">.scala</span>:<span class="number">151</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rdd</span><span class="selector-class">.RDDOperationScope</span>$.withScope(RDDOperationScope<span class="selector-class">.scala</span>:<span class="number">112</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rdd</span><span class="selector-class">.RDD</span><span class="selector-class">.withScope</span>(RDD<span class="selector-class">.scala</span>:<span class="number">363</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rdd</span><span class="selector-class">.RDD</span><span class="selector-class">.take</span>(RDD<span class="selector-class">.scala</span>:<span class="number">1337</span>)</span><br><span class="line">at com<span class="selector-class">.kk</span><span class="selector-class">.recommend</span><span class="selector-class">.tools</span><span class="selector-class">.model</span><span class="selector-class">.ALSBasedMLUtil</span>$.evaluateModel(ALSBasedMLUtil<span class="selector-class">.scala</span>:<span class="number">51</span>)</span><br><span class="line">at com<span class="selector-class">.kk</span><span class="selector-class">.recommend</span><span class="selector-class">.topic</span><span class="selector-class">.follow</span><span class="selector-class">.ItemCFV2</span>$.testBasedML(ItemCFV2<span class="selector-class">.scala</span>:<span class="number">104</span>)</span><br><span class="line">at com<span class="selector-class">.kk</span><span class="selector-class">.recommend</span><span class="selector-class">.topic</span><span class="selector-class">.follow</span><span class="selector-class">.ItemCFV2</span>$.main(ItemCFV2<span class="selector-class">.scala</span>:<span class="number">40</span>)</span><br><span class="line">at com<span class="selector-class">.kk</span><span class="selector-class">.recommend</span><span class="selector-class">.topic</span><span class="selector-class">.follow</span><span class="selector-class">.ItemCFV2</span><span class="selector-class">.main</span>(ItemCFV2.scala)</span><br><span class="line">at sun<span class="selector-class">.reflect</span><span class="selector-class">.NativeMethodAccessorImpl</span><span class="selector-class">.invoke0</span>(Native Method)</span><br><span class="line">at sun<span class="selector-class">.reflect</span><span class="selector-class">.NativeMethodAccessorImpl</span><span class="selector-class">.invoke</span>(NativeMethodAccessorImpl<span class="selector-class">.java</span>:<span class="number">62</span>)</span><br><span class="line">at sun<span class="selector-class">.reflect</span><span class="selector-class">.DelegatingMethodAccessorImpl</span><span class="selector-class">.invoke</span>(DelegatingMethodAccessorImpl<span class="selector-class">.java</span>:<span class="number">43</span>)</span><br><span class="line">at java<span class="selector-class">.lang</span><span class="selector-class">.reflect</span><span class="selector-class">.Method</span><span class="selector-class">.invoke</span>(Method<span class="selector-class">.java</span>:<span class="number">498</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.deploy</span><span class="selector-class">.yarn</span><span class="selector-class">.ApplicationMaster</span>$<span class="variable">$anon</span>$<span class="number">2</span>.run(ApplicationMaster<span class="selector-class">.scala</span>:<span class="number">688</span>)</span><br><span class="line">Caused by: java<span class="selector-class">.lang</span><span class="selector-class">.ArrayStoreException</span>: org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.sql</span><span class="selector-class">.catalyst</span><span class="selector-class">.expressions</span><span class="selector-class">.GenericRowWithSchema</span></span><br><span class="line">at scala<span class="selector-class">.runtime</span><span class="selector-class">.ScalaRunTime</span>$.array_update(ScalaRunTime<span class="selector-class">.scala</span>:<span class="number">90</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.IndexedSeqOptimized</span><span class="variable">$class</span>.copyToArray(IndexedSeqOptimized<span class="selector-class">.scala</span>:<span class="number">180</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.mutable</span><span class="selector-class">.WrappedArray</span><span class="selector-class">.copyToArray</span>(WrappedArray<span class="selector-class">.scala</span>:<span class="number">35</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.TraversableOnce</span><span class="variable">$class</span>.copyToArray(TraversableOnce<span class="selector-class">.scala</span>:<span class="number">278</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.AbstractTraversable</span><span class="selector-class">.copyToArray</span>(Traversable<span class="selector-class">.scala</span>:<span class="number">104</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.TraversableOnce</span><span class="variable">$class</span>.toArray(TraversableOnce<span class="selector-class">.scala</span>:<span class="number">286</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.mutable</span><span class="selector-class">.WrappedArray</span><span class="selector-class">.toArray</span>(WrappedArray<span class="selector-class">.scala</span>:<span class="number">73</span>)</span><br><span class="line">at com<span class="selector-class">.kk</span><span class="selector-class">.recommend</span><span class="selector-class">.tools</span><span class="selector-class">.model</span><span class="selector-class">.ALSBasedMLUtil</span>$<span class="variable">$anonfun</span>$<span class="number">2</span>.apply(ALSBasedMLUtil<span class="selector-class">.scala</span>:<span class="number">48</span>)</span><br><span class="line">at com<span class="selector-class">.kk</span><span class="selector-class">.recommend</span><span class="selector-class">.tools</span><span class="selector-class">.model</span><span class="selector-class">.ALSBasedMLUtil</span>$<span class="variable">$anonfun</span>$<span class="number">2</span>.apply(ALSBasedMLUtil<span class="selector-class">.scala</span>:<span class="number">46</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.Iterator</span>$<span class="variable">$anon</span>$<span class="number">12</span>.nextCur(Iterator<span class="selector-class">.scala</span>:<span class="number">434</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.Iterator</span>$<span class="variable">$anon</span>$<span class="number">12</span>.hasNext(Iterator<span class="selector-class">.scala</span>:<span class="number">440</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.Iterator</span>$<span class="variable">$anon</span>$<span class="number">10</span>.hasNext(Iterator<span class="selector-class">.scala</span>:<span class="number">389</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.Iterator</span><span class="variable">$class</span>.foreach(Iterator<span class="selector-class">.scala</span>:<span class="number">893</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.AbstractIterator</span><span class="selector-class">.foreach</span>(Iterator<span class="selector-class">.scala</span>:<span class="number">1336</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.generic</span><span class="selector-class">.Growable</span><span class="variable">$class</span>.<span class="variable">$plus</span><span class="variable">$plus</span><span class="variable">$eq</span>(Growable<span class="selector-class">.scala</span>:<span class="number">59</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.mutable</span><span class="selector-class">.ArrayBuffer</span>.<span class="variable">$plus</span><span class="variable">$plus</span><span class="variable">$eq</span>(ArrayBuffer<span class="selector-class">.scala</span>:<span class="number">104</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.mutable</span><span class="selector-class">.ArrayBuffer</span>.<span class="variable">$plus</span><span class="variable">$plus</span><span class="variable">$eq</span>(ArrayBuffer<span class="selector-class">.scala</span>:<span class="number">48</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.TraversableOnce</span><span class="variable">$class</span>.to(TraversableOnce<span class="selector-class">.scala</span>:<span class="number">310</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.AbstractIterator</span><span class="selector-class">.to</span>(Iterator<span class="selector-class">.scala</span>:<span class="number">1336</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.TraversableOnce</span><span class="variable">$class</span>.toBuffer(TraversableOnce<span class="selector-class">.scala</span>:<span class="number">302</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.AbstractIterator</span><span class="selector-class">.toBuffer</span>(Iterator<span class="selector-class">.scala</span>:<span class="number">1336</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.TraversableOnce</span><span class="variable">$class</span>.toArray(TraversableOnce<span class="selector-class">.scala</span>:<span class="number">289</span>)</span><br><span class="line">at scala<span class="selector-class">.collection</span><span class="selector-class">.AbstractIterator</span><span class="selector-class">.toArray</span>(Iterator<span class="selector-class">.scala</span>:<span class="number">1336</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rdd</span><span class="selector-class">.RDD</span>$<span class="variable">$anonfun</span><span class="variable">$take</span>$<span class="number">1</span>$<span class="variable">$anonfun</span>$<span class="number">28</span>.apply(RDD<span class="selector-class">.scala</span>:<span class="number">1364</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.rdd</span><span class="selector-class">.RDD</span>$<span class="variable">$anonfun</span><span class="variable">$take</span>$<span class="number">1</span>$<span class="variable">$anonfun</span>$<span class="number">28</span>.apply(RDD<span class="selector-class">.scala</span>:<span class="number">1364</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.SparkContext</span>$<span class="variable">$anonfun</span><span class="variable">$runJob</span>$<span class="number">5</span>.apply(SparkContext<span class="selector-class">.scala</span>:<span class="number">2074</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.SparkContext</span>$<span class="variable">$anonfun</span><span class="variable">$runJob</span>$<span class="number">5</span>.apply(SparkContext<span class="selector-class">.scala</span>:<span class="number">2074</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.scheduler</span><span class="selector-class">.ResultTask</span><span class="selector-class">.runTask</span>(ResultTask<span class="selector-class">.scala</span>:<span class="number">87</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.scheduler</span><span class="selector-class">.Task</span><span class="selector-class">.run</span>(Task<span class="selector-class">.scala</span>:<span class="number">109</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.executor</span><span class="selector-class">.Executor</span><span class="variable">$TaskRunner</span>.run(Executor<span class="selector-class">.scala</span>:<span class="number">381</span>)</span><br><span class="line">at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.ThreadPoolExecutor</span><span class="selector-class">.runWorker</span>(ThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">1149</span>)</span><br><span class="line">at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.ThreadPoolExecutor</span><span class="variable">$Worker</span>.run(ThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">624</span>)</span><br><span class="line">at java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.run</span>(Thread<span class="selector-class">.java</span>:<span class="number">748</span>)</span><br></pre></td></tr></table></figure><p>结局办法：</p><p>解决办法：<a href="https://stackoverflow.com/questions/32727518/genericrowwithschema-exception-in-casting-arraybuffer-to-hashset-in-dataframe-to" target="_blank" rel="external">点击阅读</a></p><p>打印的Schema信息：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- <span class="string">userId:</span> integer (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- <span class="string">recommendations:</span> array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- <span class="string">element:</span> struct (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |    |    |-- <span class="string">topicId:</span> integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |    |-- <span class="string">rating:</span> <span class="keyword">float</span> (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></p><blockquote><p>在row 中的这些列取得时候，要根据类型取，简单的像String，Seq[Double] 这种类型就可以直接取出来，但是像 Seq[(Double,Double)] 这种类型直接取得花就会丢失schema信息，虽然值能取到，但是schema信息丢了，在dataFrame中操作的时候就会抛错</p></blockquote><p>ALS测试结果数据的格式如下：</p><div class="table-container"><table><thead><tr><th></th><th>userId</th><th>recommendations</th></tr></thead><tbody><tr><td>  148</td><td>[[1972, 0.0334868…</td></tr></tbody></table></div><p>原始的写法是：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">result.select(<span class="string">"userId"</span>, <span class="string">"recommendations"</span>)</span><br><span class="line">        .filter(<span class="function"><span class="params">row</span> =&gt;</span> !(row.isNullAt(<span class="number">0</span>) || row.isNullAt(<span class="number">1</span>)))</span><br><span class="line">        .rdd.flatMap( <span class="function"><span class="params">l</span>=&gt;</span>&#123;</span><br><span class="line">            val uid = l.get(<span class="number">0</span>).toString</span><br><span class="line">            val itemList = l.getAs[mutable.WrappedArray[(Int,Double)]](<span class="string">"recommendations"</span>)</span><br><span class="line">            <span class="keyword">for</span>(item&lt;- itemList) <span class="keyword">yield</span> (uid, item._1.toString)</span><br><span class="line">        &#125;)</span><br></pre></td></tr></table></figure><p>修改后为：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">result.select(<span class="string">"userId"</span>, <span class="string">"recommendations"</span>)</span><br><span class="line">        .filter(<span class="function"><span class="params">row</span> =&gt;</span> !(row.isNullAt(<span class="number">0</span>) || row.isNullAt(<span class="number">1</span>)))</span><br><span class="line">        .rdd.flatMap( <span class="function"><span class="params">l</span>=&gt;</span>&#123;</span><br><span class="line">            val uid = l.get(<span class="number">0</span>).toString</span><br><span class="line">            val itemList= l.getAs[Seq[Row]](<span class="number">1</span>).map(<span class="function"><span class="params">x</span>=&gt;</span>&#123;(x.getInt(<span class="number">0</span>),x.getFloat(<span class="number">1</span>))&#125;)</span><br><span class="line">            <span class="keyword">for</span>(item&lt;- itemList) <span class="keyword">yield</span> (uid, item._1.toString)</span><br><span class="line">            &#125;)</span><br></pre></td></tr></table></figure></p><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在上一篇文章中介绍了ALS算法的原理（&lt;a href=&quot;https://blog.csdn.net/Gamer_gyt/article/details/98897829&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;点击阅读&lt;/a&gt;），在这篇文章中主要介绍一下ALS算法在Spark中的实现。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="Spark" scheme="http://thinkgamer.cn/tags/Spark/"/>
    
      <category term="CTR" scheme="http://thinkgamer.cn/tags/CTR/"/>
    
  </entry>
  
  <entry>
    <title>基于协同的ALS算法原理介绍与实现</title>
    <link href="http://thinkgamer.cn/2019/08/08/RecSys/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E7%9A%84ALS%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>http://thinkgamer.cn/2019/08/08/RecSys/推荐算法/基于协同的ALS算法原理介绍与实现/</id>
    <published>2019-08-08T15:41:20.000Z</published>
    <updated>2019-10-14T06:42:35.664Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ALS也是一种协同算法，其全称是交替最小二乘法（Alternating Least Squares），由于简单高效，已被广泛应用在推荐场景中，目前已经被集成到Spark MLlib和ML库中，在下一篇文章会对其使用方式进行详细介绍，本篇文章主要介绍ALS的底层算法原理。</p></blockquote><a id="more"></a><h3 id="最小二乘法（Least-Squares）"><a href="#最小二乘法（Least-Squares）" class="headerlink" title="最小二乘法（Least Squares）"></a>最小二乘法（Least Squares）</h3><p>在介绍ALS算法之前，先来了解LS，即最小二乘法。LS算法是ALS的基础，是一种数学优化技术，也是一种常用的机器学习算法，他通过最小化误差平方和寻找数据的最佳匹配，利用最小二乘法寻找最优的未知数据，保证求的数据与已知的数据误差最小。</p><p>LS也被用于拟合曲线，比如所熟悉的线性模型。下面以简单的线性一元线性回归模型说明最小二乘法。<br>假设我们有一组数据{(x1,y1),(x2,y2),(x3,y3)…}其符合线性回归，假设其符合的函数为如下：</p><script type="math/tex; mode=display">y = w_0 + w_1 x</script><p>我们使用一个平方差函数来表达参数的好坏，平方差函数如下：</p><script type="math/tex; mode=display">L_n = (y_n - f(x;w_0,w_1))^2</script><p>其中f(.) 表示我们假设的线性回归函数。显然Ln越小越好，Ln越小表示误差越小。假设有N个样本，则N个样本的平均平方差为：</p><script type="math/tex; mode=display">L = \frac{1}{N} \sum_{n=1}^{N} (y_n - f(x;w_0,w_1))^2</script><p>L越小表示参数w越精确，而这里最关键的就是寻找到最合适的w0和w1，则此时的数学表达式为：</p><script type="math/tex; mode=display">\underset{w_0,w_1}{arg \ min}  \frac{1}{N} \sum_{n=1}^{N} (y_n - f(x;w_0,w_1))^2</script><p>将先行回归函数代入到最小二乘损失函数中，得到的结果为：</p><script type="math/tex; mode=display">L = \frac{1}{N} \sum_{n=1}^{N} (y_n - w_0 - w_1 x_n)^2\\\frac{1}{N} \sum_{n=1}^{N} (w_1 ^2x_n^2 + 2w_1x_n(w_0 - y_n) + w_0^2 - 2w_0y_n + y_n^2)</script><p>L函数取得最小值时，w0和w1的一阶偏导数一定是0（因为误差平方和是一个大于等于0的数，是没有最大值的，所以取得最小值时，一阶偏导数一定为0）。因为对L函数分别求偏导，使其等于0，并对w0和w1求解，即可。</p><h3 id="交替最小二乘法（Alternating-Least-Squares）"><a href="#交替最小二乘法（Alternating-Least-Squares）" class="headerlink" title="交替最小二乘法（Alternating Least Squares）"></a>交替最小二乘法（Alternating Least Squares）</h3><p>ALS算法本质上是基于物品的协同，近年来，基于模型的推荐算法ALS(交替最小二乘)在Netflix成功应用并取得显著效果提升，ALS使用机器学习算法建立用户和物品间的相互作用模型，进而去预测新项。</p><h4 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h4><p>用户对物品的打分行为可以用一个矩阵（R）来表示：<br><img src="https://img-blog.csdnimg.cn/20190808233244547.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>矩阵中的打分值 r_ij表示用户 u_i 对物品 v_j 的打分，其中”?”表示用户没有打分，这也就是要通过机器学习的方法去预测这个打分值，从而达到推荐的目的。</p><h4 id="模型抽象"><a href="#模型抽象" class="headerlink" title="模型抽象"></a>模型抽象</h4><p>根绝协同过滤的思想，R矩阵的行向量对应每个用户U，列向量对应每个物品V。ALS的核心思想是：将用户和物品都投射到k维空间，也就是说假设有k个隐向量特征，至于这个k个隐向量是什么不用关系（可能是标签，年龄，性别等），将每个用户和每个物品都用k维的向量来表示，把他们的内积近似为打分值，这样便可以得到近似的评分。</p><script type="math/tex; mode=display">R \approx UV^T</script><p>其中：</p><ul><li>R为打分矩阵（m*n，m表示用户个数，n表示物品个数）</li><li>U表示用户对隐含特征的偏好矩阵（m*k）</li><li>V表示物品对隐含特征的归属矩阵（n*K）</li></ul><p>上述模型的参数就是U和V，求得U和V之后，就可以近似的得到用户对未评分物品的评分。</p><h4 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h4><p>求上述公式中的U和V，就需要一个代价函数来衡量参数的拟合程度。用户对物品的行为分为显式行为和隐式行为，两种不同类型的行为下，对应的代价函数也是不一样的。</p><blockquote><p>关于显式行为和隐式行为的介绍可以餐考 我的《推荐系统开发实战》一书。</p></blockquote><p><strong>显式反馈代价函数</strong><br>如果用户对物品有明确的评分行为，那么可以对比重构出来的评分矩阵和实际的评分矩阵，便可得到误差。由于用户对物品的评分却失很多，仅以有评分行为的物品去计算误差。下面是显式反馈的代价函数。</p><script type="math/tex; mode=display">J(U,V) = \sum_{i}^{m} \sum_{j}^{n}[(r_{ij} - u_iv_j^T) ^2 + \lambda ( ||u_i||^2 + ||v_j||^2 ) ]</script><p>其中：λ 为正则项系数</p><h4 id="隐式反馈代价函数"><a href="#隐式反馈代价函数" class="headerlink" title="隐式反馈代价函数"></a>隐式反馈代价函数</h4><p><strong><em>隐式反馈对应的ALS算法即：ALS-WR（Alternating Least Squares With Weighted-λ -regularization）</em></strong></p><p>很多情况下，用户并没有明确反馈对物品的偏好，需要通过用户的相关行为去推测其对物品的偏好，比如在电商网站中，用户是否点击物品，点击的话在一定程度上表示喜欢，未点击的话可能是不喜欢，也可能是没有看到该物品。这种形式下的反馈就被称为隐式反馈。即矩阵R为隐式反馈矩阵，引入变量p_ij表示用户u_i对物品v_j的置信度，如果隐式反馈大于0，置信度为，反之置信度为0。</p><script type="math/tex; mode=display">p_{ij} = \left\{\begin{matrix}1  & r_{ij} >0 \\ 0 & r_{ij} =0\end{matrix}\right.</script><p>上文也提到了，隐式反馈为0，不代表用户完全不喜欢，也可能是用户没有看到该物品。另外用户点击一个物品，也不代表是喜欢他，可能是误点，所以需要一个信任等级来显示用户喜欢某个物品，一般情况下，r_ij越大(用户行为的次数)，越能暗示用户喜欢某个物品，因此引入变量c_ij，来衡量p_ij的信任度。</p><script type="math/tex; mode=display">c_{ij} = 1 + \alpha r_{ij}</script><p>α 为置信度系数，那么代价函数变为如下形式：</p><script type="math/tex; mode=display">J(U,V) = \sum_{i}^{m} \sum_{j}^{n}[c_{ij}(p_{ij} - u_iv_j^T) ^2 + \lambda ( ||u_i||^2 + ||v_j||^2 ) ]</script><h4 id="算法求解"><a href="#算法求解" class="headerlink" title="算法求解"></a>算法求解</h4><p>无论是隐式代价函数求解还是显式代价函数求解，他们都是凸函数，而且变量耦合在一起，常规的梯度下降算法不能求解。但是先固定U求V，再固定V求U，如此迭代下去，问题就可以解决了。</p><script type="math/tex; mode=display">U^0 \rightarrow V^1 \rightarrow U^1 \rightarrow V^2 \rightarrow U^2 ....</script><p>固定一个变量，求另外一个变量，用什么方法求解呢？梯度下降？可以，但是比较麻烦。这其实是一个最小二乘的问题，由于一般隐含的特征k不会太大，可以直接当做是正规方程去解决。如此的交替的使用最小二乘去求解，所以名字就叫做交替最小二乘法。</p><p><strong>显氏反馈求解</strong><br>固定V求解U，对公式进行求导化简，可得：</p><script type="math/tex; mode=display">U ^T = \left( V^T V + \lambda I \right)^{-1} V^T R^T</script><p>同理，固定U求解V，对公式进行求导化简，可得：</p><script type="math/tex; mode=display">V ^T = \left( U^T U + \lambda I \right)^{-1} U^T R</script><p><strong>隐式反馈求解</strong><br>固定V求解U，对公式进行求导化简，可得：</p><script type="math/tex; mode=display">U ^T = \left( V^T C_v V + \lambda I \right)^{-1} V^T C_v R^T</script><p>同理，固定U求解V，对公式进行求导化简，可得：</p><script type="math/tex; mode=display">V ^T = \left( U^T C_u U + \lambda I \right)^{-1} U^T C_u R</script><hr><h3 id="面试点"><a href="#面试点" class="headerlink" title="面试点"></a>面试点</h3><ol><li><p>最小二乘法英文名字是什么？解释及其对应的数学原理</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Least</span> Squares</span><br><span class="line">参考上文</span><br></pre></td></tr></table></figure></li><li><p>ALS全称是什么？为什么叫交替最小二乘法？</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Alternaing</span> Least Squares</span><br><span class="line">参考上文</span><br></pre></td></tr></table></figure></li><li><p>隐式反馈和显氏反馈的区别？两种形式下ALS的代价函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">《推荐系统开发实战》中有对其的介绍</span><br><span class="line"> 两种形式下的代价函数参考上文</span><br></pre></td></tr></table></figure></li><li><p>代价函数中的正则项及其含义？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">参考上文</span><br></pre></td></tr></table></figure></li><li><p>过拟合和欠拟合的含义？在ALS中什么情况会出现过拟合和欠拟合？对应的解决办法？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">欠拟合定义：拟合的函数与训练集误差较大，</span><br><span class="line">过拟合定义：拟合的函数与训练集完美匹配（误差很小）</span><br><span class="line">合适拟合定义：拟合的函数与训练集误差较小</span><br><span class="line"></span><br><span class="line">欠拟合出现原因：数据规模太小，特征太多，正则化项系数较小</span><br><span class="line">过拟合出现原因：数据特征太少，正则化项系数较大</span><br><span class="line"></span><br><span class="line">欠拟合解决办法：增大数据规模、减小数据特征数（维数）、增大正则化系数λ</span><br><span class="line">过拟合解决办法：增多数据特征数、添加高次多项式特征、减小正则化系数λ</span><br></pre></td></tr></table></figure></li><li><p>Spark实现ALS可调节的参数有哪些？分别表示什么含义？</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">maxIters <span class="comment">// 最大迭代次数，默认10 </span></span><br><span class="line"><span class="built_in">rank</span> <span class="comment">// 隐向量的长度，默认是10，一般远小于m，n</span></span><br><span class="line">numBlocks <span class="comment">// 数据分区的个数，默认是10</span></span><br><span class="line">regParam <span class="comment">// ALS中的正则化参数，默认是1.0</span></span><br><span class="line">alpha <span class="comment">// ALS隐氏反馈变量的参数，置信度系数，默认是1.0</span></span><br><span class="line">userCol <span class="comment">// 用户列名</span></span><br><span class="line">itemCol <span class="comment">// item列名</span></span><br><span class="line">rateCol <span class="comment">// 评分列名</span></span><br><span class="line">implicitPrefs <span class="comment">// 显氏反馈 还是 隐氏反馈，默认false，意味显氏反馈</span></span><br></pre></td></tr></table></figure></li></ol><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></center><blockquote><p>【搜索与推荐Wiki】专注于搜索和推荐系统，尝试使用算法去更好的服务于用户，包括但不局限于机器学习，深度学习，强化学习，自然语言理解，知识图谱，还不定时分享技术，资料，思考等文章！</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;ALS也是一种协同算法，其全称是交替最小二乘法（Alternating Least Squares），由于简单高效，已被广泛应用在推荐场景中，目前已经被集成到Spark MLlib和ML库中，在下一篇文章会对其使用方式进行详细介绍，本篇文章主要介绍ALS的底层算法原理。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="推荐算法" scheme="http://thinkgamer.cn/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="ALS" scheme="http://thinkgamer.cn/tags/ALS/"/>
    
  </entry>
  
  <entry>
    <title>【技术分享】2019全球人工智能技术峰会PDF资料拿走不谢</title>
    <link href="http://thinkgamer.cn/2019/08/08/Share/%E3%80%90%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB%E3%80%912019%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%B3%B0%E4%BC%9APDF%E8%B5%84%E6%96%99%E6%8B%BF%E8%B5%B0%E4%B8%8D%E8%B0%A2/"/>
    <id>http://thinkgamer.cn/2019/08/08/Share/【技术分享】2019全球人工智能技术峰会PDF资料拿走不谢/</id>
    <published>2019-08-08T04:58:29.000Z</published>
    <updated>2019-10-14T06:42:35.672Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>2019 全球人工智能技术峰会PDF资料免费分享，资料内容涵盖各个方面，全部都是一线互联网公司的产业实践。</p></blockquote><a id="more"></a><h3 id="工业实践"><a href="#工业实践" class="headerlink" title="工业实践"></a>工业实践</h3><ul><li>「百度」源于产业实践的开源深度学习平台飞浆（PaddlePaddle）</li><li>「易观」如何建设大数据中台（从0到1建设大数据中台）</li><li>「华为」云边协同，重新定义AI</li></ul><h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><ul><li>「网易云」AI算法在音乐推荐中的应用</li><li>「VIPKID」在线教育行业中视频理解的应用</li><li>「美团点评」美团外卖商业变现实践<h3 id="搜索推荐"><a href="#搜索推荐" class="headerlink" title="搜索推荐"></a>搜索推荐</h3></li><li>「荔枝」荔枝UGC推荐探索与实践</li><li>「金山」推荐系统在剑网3推栏项目中的落地</li></ul><h3 id="知识图谱"><a href="#知识图谱" class="headerlink" title="知识图谱"></a>知识图谱</h3><ul><li>「瑞士再保险」知识图谱构建（数据，算法与架构）</li><li>「美团点评」基于知识图谱的问答在O2O智能交 互场景中的应用和演进</li><li>「中科院」基于知识图谱的问答关键技术—从答案到自然答案</li></ul><h3 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h3><ul><li>「阿里巴巴」语音对话机器人在阿里小蜜中的相关技术探索</li><li>「追一科技」深度学习在企业智能交互中的应用</li><li>「贝壳找房」4D看房：写稿机器人与VR的美丽邂逅</li></ul><h3 id="智能安防"><a href="#智能安防" class="headerlink" title="智能安防"></a>智能安防</h3><ul><li>「扇贝」A Short Intro: 无处不在的对抗样本攻防</li><li>「友邦安达」AI边缘计算的崛起</li></ul><h3 id="智能金融"><a href="#智能金融" class="headerlink" title="智能金融"></a>智能金融</h3><ul><li>「旷视」旷视AI 在金融风控领域的运用</li><li>「MinTech」MinTech的金融科技 实践与探索</li><li>「百信银行」机器阅读在智能银行中的应用深度剖析与实践</li></ul><h3 id="智慧零售"><a href="#智慧零售" class="headerlink" title="智慧零售"></a>智慧零售</h3><ul><li>「WakeData」唤醒沉睡的数据</li><li>「MobTech」基于创新算法的半监督的 lookalike效果营销</li><li>「京东」新零售时代的智慧中台</li></ul><h3 id="智慧城市"><a href="#智慧城市" class="headerlink" title="智慧城市"></a>智慧城市</h3><ul><li>「哈罗出行」科技推动出行进化-密密织就的出行智能</li></ul><h3 id="智能商业"><a href="#智能商业" class="headerlink" title="智能商业"></a>智能商业</h3><ul><li>「苏宁」苏宁物流 智能决策系统建设与应用</li><li>「贝锐科技」三生万物理论的实践进化</li><li>「科大讯飞」一场客服与AI的融合之旅</li></ul><h3 id="IT架构"><a href="#IT架构" class="headerlink" title="IT架构"></a>IT架构</h3><ul><li>「威佩网络」人工智能和大数据系统在电子竞技数据处理平台中的应用</li><li>「快狗打车」快狗打车智能调度系统架构演进</li><li>「国美」国美Redis集群-国美千亿级Redis集群架构变迁的思考</li></ul><h3 id="AIOps"><a href="#AIOps" class="headerlink" title="AIOps"></a>AIOps</h3><ul><li>「宜信」分布式主动感知在智能运维中的实践</li><li>「F5」无探针实时应用大数据采集引擎最佳实践和AIOps实现</li><li>「日志易」海量日志分析与智能运维</li></ul><h3 id="智能企业赋能"><a href="#智能企业赋能" class="headerlink" title="智能企业赋能"></a>智能企业赋能</h3><ul><li>「百度」企业赋能AI 服务生活 DuerOS的技能服务开发</li><li>「蘑菇街」基于图像技术构建蘑菇街时尚目的地</li><li>「51Talk」人工智能赋能教育-人工智能如何助力K12在线英语</li></ul><hr><p>以上资料，私聊微信获取</p><center><img src="https://img-blog.csdnimg.cn/20190808125509913.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="200px"></center><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="200px"></center><center>打开微信扫一扫，关注微信公众号【搜索与推荐Wiki】 </center><hr><center><font color="red">注：《推荐系统开发实战》已经在京东上线，感兴趣的朋友可以进行关注！</font></center><center><img src="https://img-blog.csdnimg.cn/20190708234949217.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="40%"></center>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;2019 全球人工智能技术峰会PDF资料免费分享，资料内容涵盖各个方面，全部都是一线互联网公司的产业实践。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="技术分享" scheme="http://thinkgamer.cn/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>重庆保时捷女司机揭露了丑恶世道，但终要相信有善有正义有张小敬这样的长安不良帅</title>
    <link href="http://thinkgamer.cn/2019/08/04/%E9%9A%8F%E6%89%8B%E8%AE%B0/%E9%87%8D%E5%BA%86%E4%BF%9D%E6%97%B6%E6%8D%B7%E5%A5%B3%E5%8F%B8%E6%9C%BA%E6%8F%AD%E9%9C%B2%E4%BA%86%E4%B8%91%E6%81%B6%E4%B8%96%E9%81%93%EF%BC%8C%E4%BD%86%E7%BB%88%E8%A6%81%E7%9B%B8%E4%BF%A1%E6%9C%89%E5%96%84%E6%9C%89%E6%AD%A3%E4%B9%89%E6%9C%89%E5%BC%A0%E5%B0%8F%E6%95%AC%E8%BF%99%E6%A0%B7%E7%9A%84%E9%95%BF%E5%AE%89%E4%B8%8D%E8%89%AF%E5%B8%85/"/>
    <id>http://thinkgamer.cn/2019/08/04/随手记/重庆保时捷女司机揭露了丑恶世道，但终要相信有善有正义有张小敬这样的长安不良帅/</id>
    <published>2019-08-04T02:52:43.000Z</published>
    <updated>2019-10-14T06:42:35.694Z</updated>
    
    <content type="html"><![CDATA[<p>世道很好，只是被藏的很好，只有走在那些青石板上，我才能看到石砖墙瓦的流芳百年</p><p>世道很坏，只是很少的存在，只有遇见那些孤立无援，我才能看到人心冷暖的肆无忌惮</p><a id="more"></a><blockquote><p>这是我第一次写对社会事件的看法，当然不是为了蹭热点，而是这件事真的是触动了我。因为最近沉迷于关于西藏的记录片，真心感受到了藏民的质朴无华和亲切友善，然而这个开着保时捷的重庆女司机却再次刷新了我的三观。我以为那些不被人看到的丑恶会被岁月淡化，时光只会记录到存于这世界的美好，然而我失望了…</p><p>PS：最近看的两部藏区纪录片是《冈仁波齐》《阿拉姜色》</p></blockquote><p>7月30日上午，重庆一位驾驶保时捷的女子在斑马线违章掉头时与另一辆车的男司机发生口角。这件事本身没什么，同样作为一名司机，我觉得双方互相道个歉，然后故事就大结局了！不会像《长安十二时辰》中龙波能不能把花萼楼炸掉那样牵动着我的心，时时不能大结局。</p><video src="https://v.qq.com/x/page/y090600y5uh.html" controls="controls"></video><p>然而，女司机的一巴掌直接把她扇到了微博热搜，扇成了人民茶余饭后的谈资，扇出了她的往往种种违章，扇醒了沉迷于和平安乐的普罗大众，扇惊了她身后的派出所所长丈夫。</p><p>再来看下女司机，16年购入保时捷至今，三年中共有29条交通违法记录，违法行为包括闯红灯、乱停车、违反禁止标线、驾驶时拨打接听手持电话等。曾经在郊区无意间闯了一个红灯，被扣了3分+200人民币！说实话对于这钱，这分我挺悔恨的，毕竟我们的驾驶证只有12分，我们也都是平凡人！但是她却不一样，29条违章记录之后依旧在道路上横行霸道？难道人家的本本跟我的不太一样！</p><p>随着事件的发酵，这个江湖人称“月姐”的保时捷女司机被挖出了更多的“不良形象”，头批大波浪，戴白帽，身着喇叭裤，吊带小背心，黑色墨镜，嘴刁中南海，黑道感十足，简直就像黑道中的大嫂。再加上那个标志性的用食指指人的动作，说实话，遇见这种人，我会离她方圆十里开外！</p><p>关于这件事的处理结果还没有公布，不过她的几句霸语倒惊醒了我：</p><ul><li>“我出了名的飙车！红灯从来都是闯，没人敢把我怎么样。”</li><li>“我一个电话，所有记录都可以删除。”</li><li>“信不信，我分分钟找人弄你全家。”</li></ul><center><img src="https://img-blog.csdnimg.cn/20190804105026263.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70"></center>## 世道是怎样的败落，竟没人敢把你怎么样？“这世间的种种繁荣，都只不过是展现在你眼前的假象”，这句话说的有点过了，但是这世道上的一些黑暗是超乎我们想象的。某些拿着国家津贴的管员不作为，贪污受贿，包养小三，当被抓时的那种悔恨懊恼是你触碰法律底线最后的救赎吗某些身穿白大褂原本该济世救人的医生，却也受不了“灰色收入”的诱惑，而丢掉了该有的职业操守某些卖房时说的比唱的都好听的开发商，在收完定金和首付款之后，迟迟不能交房，最后变成烂尾楼这种事情在社会上屡见不鲜，但有法律这条约束线，还能起到警戒和惩罚的作用，我们能做的就是不管他人，约束好自己，不触碰法律的底线，要始终相信那些触犯法律的人终会得到制裁！## 这世上谁可以命令除他之外的所有人，是大唐时高高在上的圣人吗？权利大概是这个世界上最让人崇尚的东西，也是最让人畏惧的东西，没钱的怕有钱的，有钱的怕有权的，有权的天不怕地不怕，就怕权利更大的。不晓得这女司机是何方神圣，但这种通过“权利”可以办成一些平凡人 办不成的事的现象是显然存在的，这就像一个潜规则，只不过我们都是受害者！只要你背靠大树，那你就可以享受枝繁叶茂带来的阴凉。《长安十二时辰》中背靠永王的熊火帮不是烧杀抢掠，无恶不作吗！同样的一些其他潜规则，比如，谁有钱有权更霸道，谁就更有理，这是强者的逻辑。再比如，忍一时风平浪静，退一步海阔天空，这是弱者的借口。有句话说得好：人善被人欺，马善被人骑，柿子专挑软的捏。有些人之所以肆无忌惮、横行霸道，就是看准了老实人心地善良，不敢反抗。## 你的那句“弄死你全家”让我心有余悸。生老病死是人之常情，但欲加之罪何患无词。弱者生存的阶级里最害怕的就是强者的践踏。是你的错，你先动的手，他还了一下，就放话要弄死他全家！说实话真的怕了，能说出这句话的人，肯定处于金字塔的上层，这样她才有这样的底气，如此肆无忌惮。如今的法制社会，我们应该捍卫的是法律，在遇到事情时，拿起法律的武器来保护自己。而那个女司机则是靠着“法律执行人”的丈夫“弄死你全家”。想想也挺可笑的，士兵手里的剑是刺杀敌人的，医生手里的刀是济世救人的，官员手里的权利是维护治安的，而你则是来刷新我的三观的！## 那个扇了女司机的男司机以后会怎么样？在这个世界上，有人打心底里认为，只要有钱，便可以为所欲为，同样因为没钱，这世上的很多弱者在自己受了委屈之后，都会选择默不作声，任人宰割。即使是事件中的男司机，一时忍无可忍的，动手还击。可事后冷静下来，还是第一时间道歉了事。尽管错不在他，但我们也能体会到他内心的无奈。弱小的力量怎么能去和金钱，势力抗衡！《长安十二时辰》中有这样一个情节交代，永王（右相想要扶持的王子）因为为西域的小勃律使修建一个驿馆，在花萼楼上领功。被太子揭了老底，原来搞的暴力拆迁。而闻染的父亲闻无忌，虽为烽燧堡战役的幸存者，但依旧不能抵抗这场所谓的暴力拆迁，他的协商和争论只是让他白白送了姓名！这件事件的男司机代表的不正是我们这些平凡的人，堂堂的七尺男儿，为了妻儿家人，在事发之后也不得不低下头，进行了道歉！谁叫对方有钱优有势，而自己却是个普通之人呢！## 那个开保时捷的女司机后来怎么样了？重庆市公安局已经成立了调查组，彻查相关情况，依法处理，重视群众反应。<center><img src="https://img-blog.csdnimg.cn/20190805175924660.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70"></center><p>政府的态度已经很明显了，但那只是政府的官方态度，具体后事如何，暂时是未知的。不过这让我想起来了最近热播的《长安十二时辰》。</p><p>其中发生的事件是：龙波携众人和阙乐霍多，对花萼楼麒麟臂进行偷梁换柱，意图送圣人西去，而“大案牍术”选择的张小敬对其穷追不舍，彻查此案。</p><p>事件的起因是：安西铁军第八团在烽燧堡巡查之际，遭遇敌兵，于是死守城墙，但是援军迟迟不来，最后得知援军早已撤离，而援军不至的缘由是当时的兵部尚书林九郎并未下令进行支援，于是敌意升级到了大唐的圣人。</p><p>不过圣人在这里是做了个冤大头为什么这么说呢？因为当时的底层官员上报的是大唐边境平静，并无敌军来犯，如果作为林九郎下令增兵烽燧堡，这无疑是在打圣人的脸，是拆穿大唐边境一片平和的谎言。那么圣人必会迁怒于他，他的右相之路恐怕就没那么顺利了吧…</p><p>曾经表面“繁荣”的大唐不和现在的我们一样，看似和平安定，岁月静好，实则波涛汹涌，多少不为人知的“黑暗料理”一个个在显露出来，接下来我们就静等重庆女司机的处理结果吧！</p><h2 id="该有的光明会来，因为有张小敬这样的长安不良帅"><a href="#该有的光明会来，因为有张小敬这样的长安不良帅" class="headerlink" title="该有的光明会来，因为有张小敬这样的长安不良帅"></a>该有的光明会来，因为有张小敬这样的长安不良帅</h2><center><img src="https://img-blog.csdnimg.cn/20190804105136566.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70"></center>一个好人，什么时候开始变坏？从他觉得孤立无援的那一刻起；一个老实人，什么时候开始冷漠，从他看透人心冷暖的那一秒始。可如果人人都如此，那社会上的好人就越来越少，坏人就越来越多。最后必然陷入整体崩溃中。所以，不要把这个世界让给那些坏人，也不要让好人在黑暗里孤独的抗争。十年饮冰难凉热血，面对丑恶，忍耐不是美德，愤怒才是。而愤怒，绝不是一两个人的事情，而是所有有正义感的人共同的事业。说到底，这世界并不完美，犹如表象繁荣的大唐，但却依旧值得我们去奋斗，就像张小敬一样，不退！！！你的善良，你的坚持，终会发光！---<center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="200px"></center><center>打开微信扫一扫，关注微信公众号【搜索与推荐Wiki】 </center><hr><center><font color="red">注：《推荐系统开发实战》已经在京东上线，感兴趣的朋友可以进行关注！</font></center><center><img src="https://img-blog.csdnimg.cn/20190708234949217.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="40%"></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;世道很好，只是被藏的很好，只有走在那些青石板上，我才能看到石砖墙瓦的流芳百年&lt;/p&gt;
&lt;p&gt;世道很坏，只是很少的存在，只有遇见那些孤立无援，我才能看到人心冷暖的肆无忌惮&lt;/p&gt;
    
    </summary>
    
      <category term="随手记" scheme="http://thinkgamer.cn/categories/%E9%9A%8F%E6%89%8B%E8%AE%B0/"/>
    
    
      <category term="随手记" scheme="http://thinkgamer.cn/tags/%E9%9A%8F%E6%89%8B%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>基于协同的Slope One算法原理介绍和实现</title>
    <link href="http://thinkgamer.cn/2019/08/02/RecSys/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E7%9A%84Slope%20One%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%AE%9E%E7%8E%B0/"/>
    <id>http://thinkgamer.cn/2019/08/02/RecSys/推荐算法/基于协同的Slope One算法原理介绍和实现/</id>
    <published>2019-08-02T08:45:53.000Z</published>
    <updated>2019-10-14T06:42:35.665Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>该篇文章主要介绍Slope One算法。Slope One 算法是由 Daniel Lemire 教授在 2005 年提出的一个 Item-Based 的协同过滤推荐算法。和其它类似算法相比, 它的最大优点在于算法很简单, 易于实现, 执行效率高, 同时推荐的准确性相对较高。 </p></blockquote><a id="more"></a><ul><li><a href="https://blog.csdn.net/Gamer_gyt/article/details/51346159" target="_blank" rel="external">协同过滤算法理解和Python实现</a></li><li><a href="https://thinkgamer.blog.csdn.net/article/details/51684716" target="_blank" rel="external">基于标签的推荐算法</a></li><li><a href="https://thinkgamer.blog.csdn.net/article/details/51694250" target="_blank" rel="external">基于图的推荐算法</a></li></ul><h1 id="经典的ItemCF的问题"><a href="#经典的ItemCF的问题" class="headerlink" title="经典的ItemCF的问题"></a>经典的ItemCF的问题</h1><p>经典的基于物品推荐，相似度矩阵计算无法实时更新，整个过程都是离线计算的，而且还有另一个问题，相似度计算时没有考虑相似度的置信问题。例如，两个物品，他们都被同一个用户喜欢了，且只被这一个用户喜欢了，那么余弦相似度计算的结果是 1，这个 1 在最后汇总计算推荐分数时，对结果的影响却最大。</p><p>Slope One 算法针对这些问题有很好的改进。不过 Slope One 算法专门针对评分矩阵，不适用于行为矩阵。</p><h1 id="Slope-One算法过程"><a href="#Slope-One算法过程" class="headerlink" title="Slope One算法过程"></a>Slope One算法过程</h1><p>Slope One 算法是基于不同物品之间的评分差的线性算法，预测用户对物品评分的个性化算法。</p><p>Slope算法主要分为3步</p><ol><li>计算物品之间的评分差的均值，记为物品间的评分偏差 (两物品同时被评分)<script type="math/tex; mode=display">R(i,j) = \frac{ \sum_{ u \in N(i)\bigcap N(j) } (r_{ui} - r_{uj}) }{ | N(i) \bigcap N(j) | }</script><blockquote><p>( r_ui - r_uj ) 表示评分的差,这里需要注意的是j相对i的评分偏差是 r_ui - r_uj ，如果是i相对j的评分偏差则是 r_uj - r _ui,两 者是互为相反数的关系。</p></blockquote></li></ol><p>其中：</p><ul><li>r_ui ：用户u对物品i的评分</li><li>r_uj ：用户u对物品j的评分</li><li>N(i) ：物品i评过分的用户</li><li>N(j) ：物品j评过分的用户</li><li>N(i) 交 N(j) ：表示同时对物品i 和物品j评过分的用户数。</li></ul><ol><li>根据物品间的评分偏差和用户的历史评分，预测用户对未评分的物品的评分。<script type="math/tex; mode=display">p_{uj} = \frac{ \sum_{i \in N(u)} |N(i) \bigcap N(j) |(r_{ui} - R(i,j))  }{ \sum_{i \in N(u)}|N(i) \bigcap N(j)| }</script>其中：</li></ol><ul><li>N(u) ：用户u评过分的物品</li></ul><ol><li>将预测评分进行排序，取Top N对应的物品推荐给用户</li></ol><h1 id="实例说明"><a href="#实例说明" class="headerlink" title="实例说明"></a>实例说明</h1><p>例如现在有一份评分数据，表示用户对电影的评分：</p><div class="table-container"><table><thead><tr><th>-</th><th>a</th><th>b</th><th>c</th><th>d</th><th>e</th></tr></thead><tbody><tr><td>U1</td><td>2</td><td>3</td><td>3</td><td>4</td><td></td></tr><tr><td>U2</td><td></td><td>4</td><td>2</td><td>3</td><td>3</td></tr><tr><td>U3</td><td>4</td><td>2</td><td>3</td><td></td><td>2</td></tr><tr><td>U4</td><td>3</td><td></td><td>5</td><td>4</td><td>3</td></tr></tbody></table></div><p>现在我们来预测预测每个用户对未评分电影的评分。</p><p>Step1: 计算物品之间的评分偏差，以U1为例：</p><script type="math/tex; mode=display">R(a,b) = \frac{ (2-3) + (4-2) }{ 2 } = 0.5</script><script type="math/tex; mode=display">R(a,c) = \frac{ (2-3) + (4-3) +(3-5) }{ 3 } = -0.67</script><script type="math/tex; mode=display">R(a,d) = \frac{ (2-4) + (3-4) }{ 2 } = -1.5</script><script type="math/tex; mode=display">R(a,e) = \frac{ (4-2) + (3-3) }{ 2 } = 1</script><p>同理可以计算出电影b，c，d，e与其他电影的评分偏差。</p><p>Step2: 计算用户对未评分物品的可能评分（为了方便计算，这里以U2为例）</p><p>由上表可知，用户U2 对电影a没有评分，这里计算用户U2对电影a的评分。</p><script type="math/tex; mode=display">p_{u_2,a} = \frac{2 *  (4-0.5) +3 * (2-(-0.67)) + 2 * (3-(-1.5) ) + 2 * (3-1))    }{ 2+3+2+2}  = 3.11</script><p>Step3: 评分排序</p><p>由于给定样例中，U2只对a没有评过分，所以这里不需要进行排序，正常的话，按分数进行倒排就行。</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>这里采用Python实现，在实现过程中并没有考虑算法的复杂度问题。</p><p>加载数据<br><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def loadData(self):</span><br><span class="line">    user_rate = &#123;</span><br><span class="line">        <span class="string">"U1"</span>: &#123;<span class="string">"a"</span>: <span class="number">2</span>, <span class="string">"b"</span>: <span class="number">3</span>, <span class="string">"c"</span>: <span class="number">3</span>, <span class="string">"d"</span>: <span class="number">4</span>&#125;,</span><br><span class="line">        <span class="string">"U2"</span>: &#123;<span class="string">"b"</span>: <span class="number">4</span>, <span class="string">"c"</span>: <span class="number">2</span>, <span class="string">"d"</span>: <span class="number">3</span>, <span class="string">"e"</span>: <span class="number">3</span>&#125;,</span><br><span class="line">        <span class="string">"U3"</span>: &#123;<span class="string">"a"</span>: <span class="number">4</span>, <span class="string">"b"</span>: <span class="number">2</span>, <span class="string">"c"</span>: <span class="number">3</span>, <span class="string">"e"</span>: <span class="number">2</span>&#125;,</span><br><span class="line">        <span class="string">"U4"</span>: &#123;<span class="string">"a"</span>: <span class="number">3</span>, <span class="string">"c"</span>: <span class="number">5</span>, <span class="string">"d"</span>: <span class="number">4</span>, <span class="string">"e"</span>: <span class="number">3</span>&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    item_rate = &#123;</span><br><span class="line">        <span class="string">"a"</span>: &#123;<span class="string">"U1"</span>: <span class="number">2</span>, <span class="string">"U3"</span>: <span class="number">4</span>, <span class="string">"U4"</span>: <span class="number">3</span>&#125;,</span><br><span class="line">        <span class="string">"b"</span>: &#123;<span class="string">"U1"</span>: <span class="number">3</span>, <span class="string">"U2"</span>: <span class="number">4</span>, <span class="string">"U3"</span>: <span class="number">2</span>&#125;,</span><br><span class="line">        <span class="string">"c"</span>: &#123;<span class="string">"U1"</span>: <span class="number">3</span>, <span class="string">"U2"</span>: <span class="number">2</span>, <span class="string">"U3"</span>: <span class="number">3</span>, <span class="string">"U4"</span>: <span class="number">5</span>&#125;,</span><br><span class="line">        <span class="string">"d"</span>: &#123;<span class="string">"U1"</span>: <span class="number">4</span>, <span class="string">"U2"</span>: <span class="number">3</span>, <span class="string">"U4"</span>: <span class="number">4</span>&#125;,</span><br><span class="line">        <span class="string">"e"</span>: &#123;<span class="string">"U2"</span>: <span class="number">3</span>, <span class="string">"U3"</span>: <span class="number">2</span>, <span class="string">"U4"</span>: <span class="number">3</span>&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> user_rate,item_rate</span><br></pre></td></tr></table></figure></p><p>计算物品之间的评分偏差<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def cal_item_avg_diff(self):</span><br><span class="line">    avgs_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> item1 <span class="keyword">in</span> self.item_rate.keys():</span><br><span class="line">        <span class="keyword">for</span> item2 <span class="keyword">in</span> self.item_rate.keys():</span><br><span class="line">            avg = 0.0</span><br><span class="line">            user_count = 0</span><br><span class="line">            <span class="keyword">if</span> item1 != item2:</span><br><span class="line">                <span class="keyword">for</span><span class="built_in"> user </span><span class="keyword">in</span> self.user_rate.keys():</span><br><span class="line">                    user_rate = self.user_rate[user]</span><br><span class="line">                    <span class="keyword">if</span> item1 <span class="keyword">in</span> user_rate.keys() <span class="keyword">and</span> item2 <span class="keyword">in</span> user_rate.keys():</span><br><span class="line">                        user_count += 1</span><br><span class="line">                        avg += user_rate[item1] - user_rate[item2]</span><br><span class="line">                avg = avg / user_count</span><br><span class="line">            avgs_dict.setdefault(item1,&#123;&#125;)</span><br><span class="line">            avgs_dict[item1][item2] = avg</span><br><span class="line">    return avgs_dict</span><br></pre></td></tr></table></figure></p><p>计算预估评分<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">item_both_rate_user</span><span class="params">(<span class="keyword">self</span>, item1, item2)</span></span><span class="symbol">:</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> <span class="keyword">self</span>.user_rate.keys()<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> item1 <span class="keyword">in</span> <span class="keyword">self</span>.user_rate[user].keys() <span class="keyword">and</span> item2 <span class="keyword">in</span> <span class="keyword">self</span>.user_rate[user].keys()<span class="symbol">:</span></span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(<span class="keyword">self</span>, user, item, avgs_dict)</span></span><span class="symbol">:</span></span><br><span class="line">    total = <span class="number">0</span>.<span class="number">0</span> <span class="comment"># 分子</span></span><br><span class="line">    count = <span class="number">0</span>   <span class="comment"># 分母</span></span><br><span class="line">    <span class="keyword">for</span> item1 <span class="keyword">in</span> <span class="keyword">self</span>.user_rate[user].keys()<span class="symbol">:</span></span><br><span class="line">        num = <span class="keyword">self</span>.item_both_rate_user(item, item1)</span><br><span class="line">        count += num</span><br><span class="line">        total += num * (<span class="keyword">self</span>.user_rate[user][item1] - avgs_dict[item][item1])</span><br><span class="line">    <span class="keyword">return</span> total/count</span><br></pre></td></tr></table></figure></p><p>主函数调用<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="attr">__name__</span> == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="attr">slope</span> = SlopeOne()</span><br><span class="line">    <span class="attr">avgs_dict</span> = slope.cal_item_avg_diff()</span><br><span class="line">    <span class="attr">result</span> = slope.predict(<span class="string">"U2"</span>, <span class="string">"a"</span>, avgs_dict)</span><br><span class="line">    print(<span class="string">"U2 对 a的预测评分为: %s"</span> % result)</span><br></pre></td></tr></table></figure></p><p>打印结果为：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">U2</span> 对 <span class="selector-tag">a</span>的预测评分为: 3<span class="selector-class">.111111111111111</span></span><br></pre></td></tr></table></figure></p><p>和上边我们计算的结果一致。</p><p>完整代码在：<a href="https://github.com/Thinkgamer/Machine-Learning-With-Python/tree/master/Recommend" target="_blank" rel="external">https://github.com/Thinkgamer/Machine-Learning-With-Python/tree/master/Recommend</a></p><h1 id="Slope-One的应用场景"><a href="#Slope-One的应用场景" class="headerlink" title="Slope One的应用场景"></a>Slope One的应用场景</h1><p>该算法适用于物品更新不频繁，数量相对较稳定并且物品数目明显小于用户数的场景。比较依赖用户的用户行为日志和物品偏好的相关内容。 </p><p>其优点： </p><ul><li>算法简单，易于实现，执行效率高； </li><li>可以发现用户潜在的兴趣爱好； </li></ul><p>其缺点： </p><ul><li>依赖用户行为，存在冷启动问题和稀疏性问题。</li></ul><hr><center><img src="http://img.blog.csdn.net/20171231111930492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvR2FtZXJfZ3l0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="200px"></center><center>打开微信扫一扫，关注微信公众号【搜索与推荐Wiki】 </center><hr><center><font color="red">注：《推荐系统开发实战》已经在京东上线，感兴趣的朋友可以进行关注！</font></center><center><img src="https://img-blog.csdnimg.cn/20190708234949217.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua2dhbWVyLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" width="40%"></center>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;该篇文章主要介绍Slope One算法。Slope One 算法是由 Daniel Lemire 教授在 2005 年提出的一个 Item-Based 的协同过滤推荐算法。和其它类似算法相比, 它的最大优点在于算法很简单, 易于实现, 执行效率高, 同时推荐的准确性相对较高。 &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术篇" scheme="http://thinkgamer.cn/categories/%E6%8A%80%E6%9C%AF%E7%AF%87/"/>
    
    
      <category term="推荐算法" scheme="http://thinkgamer.cn/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="Slope One" scheme="http://thinkgamer.cn/tags/Slope-One/"/>
    
  </entry>
  
</feed>
